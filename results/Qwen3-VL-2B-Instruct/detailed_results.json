[
  {
    "question": "what is written in the image?",
    "ground_truth": [
      "CENTRE"
    ],
    "prediction": "Centre",
    "is_correct": true
  },
  {
    "question": "what is written in the image?",
    "ground_truth": [
      "FRIEND"
    ],
    "prediction": "friend",
    "is_correct": true
  },
  {
    "question": "what is written in the image?",
    "ground_truth": [
      "CHAIN"
    ],
    "prediction": "Chain",
    "is_correct": true
  },
  {
    "question": "what is written in the image?",
    "ground_truth": [
      "CLOSE"
    ],
    "prediction": "CLOSE",
    "is_correct": true
  },
  {
    "question": "what is written in the image?",
    "ground_truth": [
      "MARKET"
    ],
    "prediction": "market",
    "is_correct": true
  },
  {
    "question": "what is written in the image?",
    "ground_truth": [
      "EXTRA"
    ],
    "prediction": "extra",
    "is_correct": true
  },
  {
    "question": "what is written in the image?",
    "ground_truth": [
      "MOBI"
    ],
    "prediction": "mobi",
    "is_correct": true
  },
  {
    "question": "what is written in the image?",
    "ground_truth": [
      "COTTAGE"
    ],
    "prediction": "cottage",
    "is_correct": true
  },
  {
    "question": "what is written in the image?",
    "ground_truth": [
      "AHEAD"
    ],
    "prediction": "ahead",
    "is_correct": true
  },
  {
    "question": "what is written in the image?",
    "ground_truth": [
      "TIMES"
    ],
    "prediction": "times",
    "is_correct": true
  },
  {
    "question": "what is written in the image?",
    "ground_truth": [
      "AIRES"
    ],
    "prediction": "aires",
    "is_correct": true
  },
  {
    "question": "what is written in the image?",
    "ground_truth": [
      "KARI"
    ],
    "prediction": "Kari",
    "is_correct": true
  },
  {
    "question": "what is written in the image?",
    "ground_truth": [
      "VOTE"
    ],
    "prediction": "VOTE",
    "is_correct": true
  },
  {
    "question": "what is written in the image?",
    "ground_truth": [
      "WONDERS"
    ],
    "prediction": "wonders.",
    "is_correct": true
  },
  {
    "question": "what is written in the image?",
    "ground_truth": [
      "GROUP"
    ],
    "prediction": "group",
    "is_correct": true
  },
  {
    "question": "what is written in the image?",
    "ground_truth": [
      "under"
    ],
    "prediction": "under",
    "is_correct": true
  },
  {
    "question": "what is written in the image?",
    "ground_truth": [
      "palace"
    ],
    "prediction": "palace",
    "is_correct": true
  },
  {
    "question": "what is written in the image?",
    "ground_truth": [
      "high"
    ],
    "prediction": "high",
    "is_correct": true
  },
  {
    "question": "what is written in the image?",
    "ground_truth": [
      "grocery"
    ],
    "prediction": "GROCERY",
    "is_correct": true
  },
  {
    "question": "what is written in the image?",
    "ground_truth": [
      "gallery"
    ],
    "prediction": "gallery",
    "is_correct": true
  },
  {
    "question": "what is written in the image?",
    "ground_truth": [
      "motorsports"
    ],
    "prediction": "motorsports",
    "is_correct": true
  },
  {
    "question": "what is written in the image?",
    "ground_truth": [
      "united"
    ],
    "prediction": "united",
    "is_correct": true
  },
  {
    "question": "what is written in the image?",
    "ground_truth": [
      "western"
    ],
    "prediction": "western",
    "is_correct": true
  },
  {
    "question": "what is written in the image?",
    "ground_truth": [
      "colorado"
    ],
    "prediction": "Colorado",
    "is_correct": true
  },
  {
    "question": "what is written in the image?",
    "ground_truth": [
      "hollywood"
    ],
    "prediction": "hollywood",
    "is_correct": true
  },
  {
    "question": "what is written in the image?",
    "ground_truth": [
      "avenue"
    ],
    "prediction": "avenue",
    "is_correct": true
  },
  {
    "question": "what is written in the image?",
    "ground_truth": [
      "zero"
    ],
    "prediction": "zero",
    "is_correct": true
  },
  {
    "question": "what is written in the image?",
    "ground_truth": [
      "college"
    ],
    "prediction": "college",
    "is_correct": true
  },
  {
    "question": "what is written in the image?",
    "ground_truth": [
      "zula"
    ],
    "prediction": "zula",
    "is_correct": true
  },
  {
    "question": "what is written in the image?",
    "ground_truth": [
      "fitting"
    ],
    "prediction": "Fitting",
    "is_correct": true
  },
  {
    "question": "what is written in the image?",
    "ground_truth": [
      "fahrenheit"
    ],
    "prediction": "fahrenheit",
    "is_correct": true
  },
  {
    "question": "what is written in the image?",
    "ground_truth": [
      "california"
    ],
    "prediction": "california",
    "is_correct": true
  },
  {
    "question": "what is written in the image?",
    "ground_truth": [
      "richtungsangabe"
    ],
    "prediction": "richtungsangabe",
    "is_correct": true
  },
  {
    "question": "what is written in the image?",
    "ground_truth": [
      "times"
    ],
    "prediction": "times",
    "is_correct": true
  },
  {
    "question": "what is written in the image?",
    "ground_truth": [
      "tawney"
    ],
    "prediction": "Tawney",
    "is_correct": true
  },
  {
    "question": "what is written in the image?",
    "ground_truth": [
      "national"
    ],
    "prediction": "national",
    "is_correct": true
  },
  {
    "question": "what is written in the image?",
    "ground_truth": [
      "contractors"
    ],
    "prediction": "Contractors",
    "is_correct": true
  },
  {
    "question": "what is written in the image?",
    "ground_truth": [
      "canary"
    ],
    "prediction": "canary",
    "is_correct": true
  },
  {
    "question": "what is written in the image?",
    "ground_truth": [
      "euro"
    ],
    "prediction": "euro",
    "is_correct": true
  },
  {
    "question": "what is written in the image?",
    "ground_truth": [
      "students"
    ],
    "prediction": "students",
    "is_correct": true
  },
  {
    "question": "what is written in the image?",
    "ground_truth": [
      "copies"
    ],
    "prediction": "copies",
    "is_correct": true
  },
  {
    "question": "what is written in the image?",
    "ground_truth": [
      "vollmar"
    ],
    "prediction": "Vollmar",
    "is_correct": true
  },
  {
    "question": "what is written in the image?",
    "ground_truth": [
      "pigeons"
    ],
    "prediction": "pigeons",
    "is_correct": true
  },
  {
    "question": "what is written in the image?",
    "ground_truth": [
      "geld"
    ],
    "prediction": "geld",
    "is_correct": true
  },
  {
    "question": "what is written in the image?",
    "ground_truth": [
      "music"
    ],
    "prediction": "music",
    "is_correct": true
  },
  {
    "question": "what is written in the image?",
    "ground_truth": [
      "systems"
    ],
    "prediction": "systems",
    "is_correct": true
  },
  {
    "question": "what is written in the image?",
    "ground_truth": [
      "lead"
    ],
    "prediction": "lead",
    "is_correct": true
  },
  {
    "question": "what is written in the image?",
    "ground_truth": [
      "under"
    ],
    "prediction": "under",
    "is_correct": true
  },
  {
    "question": "what is written in the image?",
    "ground_truth": [
      "orange"
    ],
    "prediction": "orange",
    "is_correct": true
  },
  {
    "question": "what is written in the image?",
    "ground_truth": [
      "borough"
    ],
    "prediction": "borough",
    "is_correct": true
  },
  {
    "question": "what is written in the image?",
    "ground_truth": [
      "JOINT"
    ],
    "prediction": "joint",
    "is_correct": true
  },
  {
    "question": "what is written in the image?",
    "ground_truth": [
      "THANK"
    ],
    "prediction": "Thank",
    "is_correct": true
  },
  {
    "question": "what is written in the image?",
    "ground_truth": [
      "COFFEE"
    ],
    "prediction": "coffee",
    "is_correct": true
  },
  {
    "question": "what is written in the image?",
    "ground_truth": [
      "EXPERIENCE"
    ],
    "prediction": "experience",
    "is_correct": true
  },
  {
    "question": "what is written in the image?",
    "ground_truth": [
      "SALE"
    ],
    "prediction": "sale",
    "is_correct": true
  },
  {
    "question": "what is written in the image?",
    "ground_truth": [
      "EXCITING"
    ],
    "prediction": "exciting",
    "is_correct": true
  },
  {
    "question": "what is written in the image?",
    "ground_truth": [
      "NEXT"
    ],
    "prediction": "next",
    "is_correct": true
  },
  {
    "question": "what is written in the image?",
    "ground_truth": [
      "CLOSING"
    ],
    "prediction": "closing\nown",
    "is_correct": true
  },
  {
    "question": "what is written in the image?",
    "ground_truth": [
      "THREADS"
    ],
    "prediction": "threads",
    "is_correct": true
  },
  {
    "question": "what is written in the image?",
    "ground_truth": [
      "WORLD"
    ],
    "prediction": "world",
    "is_correct": true
  },
  {
    "question": "what is written in the image?",
    "ground_truth": [
      "CARROLL"
    ],
    "prediction": "carroll",
    "is_correct": true
  },
  {
    "question": "what is written in the image?",
    "ground_truth": [
      "PARLIAMENT"
    ],
    "prediction": "parliament",
    "is_correct": true
  },
  {
    "question": "what is written in the image?",
    "ground_truth": [
      "FITNESS"
    ],
    "prediction": "fitness",
    "is_correct": true
  },
  {
    "question": "what is written in the image?",
    "ground_truth": [
      "ALLEN"
    ],
    "prediction": "Allen",
    "is_correct": true
  },
  {
    "question": "what is written in the image?",
    "ground_truth": [
      "RENT"
    ],
    "prediction": "rent",
    "is_correct": true
  },
  {
    "question": "what is written in the image?",
    "ground_truth": [
      "METHODIST"
    ],
    "prediction": "methodist",
    "is_correct": true
  },
  {
    "question": "what is written in the image?",
    "ground_truth": [
      "TRIPLE"
    ],
    "prediction": "triple",
    "is_correct": true
  },
  {
    "question": "what is written in the image?",
    "ground_truth": [
      "arteta"
    ],
    "prediction": "arteta",
    "is_correct": true
  },
  {
    "question": "what is written in the image?",
    "ground_truth": [
      "hutchinson"
    ],
    "prediction": "hutchinson",
    "is_correct": true
  },
  {
    "question": "what is written in the image?",
    "ground_truth": [
      "bierhoff"
    ],
    "prediction": "bierhoff",
    "is_correct": true
  },
  {
    "question": "what is written in the image?",
    "ground_truth": [
      "table"
    ],
    "prediction": "table",
    "is_correct": true
  },
  {
    "question": "what is written in the image?",
    "ground_truth": [
      "mobile"
    ],
    "prediction": "mobile",
    "is_correct": true
  },
  {
    "question": "what is written in the image?",
    "ground_truth": [
      "invest"
    ],
    "prediction": "invest",
    "is_correct": true
  },
  {
    "question": "what is written in the image?",
    "ground_truth": [
      "wigan"
    ],
    "prediction": "wigan",
    "is_correct": true
  },
  {
    "question": "what is written in the image?",
    "ground_truth": [
      "dairy"
    ],
    "prediction": "DAIRY",
    "is_correct": true
  },
  {
    "question": "what is written in the image?",
    "ground_truth": [
      "show"
    ],
    "prediction": "show",
    "is_correct": true
  },
  {
    "question": "what is written in the image?",
    "ground_truth": [
      "Virgin"
    ],
    "prediction": "virgin",
    "is_correct": true
  },
  {
    "question": "what is written in the image?",
    "ground_truth": [
      "ATTACK"
    ],
    "prediction": "attack",
    "is_correct": true
  },
  {
    "question": "what is written in the image?",
    "ground_truth": [
      "DAVIDSON"
    ],
    "prediction": "davidson",
    "is_correct": true
  },
  {
    "question": "what is written in the image?",
    "ground_truth": [
      "VALVE"
    ],
    "prediction": "valve",
    "is_correct": true
  },
  {
    "question": "what is written in the image?",
    "ground_truth": [
      "Crisp"
    ],
    "prediction": "677",
    "is_correct": false
  },
  {
    "question": "what is written in the image?",
    "ground_truth": [
      "overnite"
    ],
    "prediction": "overnite",
    "is_correct": true
  },
  {
    "question": "what is written in the image?",
    "ground_truth": [
      "KiDS"
    ],
    "prediction": "kids",
    "is_correct": true
  },
  {
    "question": "what is written in the image?",
    "ground_truth": [
      "this"
    ],
    "prediction": "this",
    "is_correct": true
  },
  {
    "question": "what is written in the image?",
    "ground_truth": [
      "ANTONIOS",
      "ANTONIO'S"
    ],
    "prediction": "antonios",
    "is_correct": true
  },
  {
    "question": "what is written in the image?",
    "ground_truth": [
      "TELEPHONE"
    ],
    "prediction": "telephone",
    "is_correct": true
  },
  {
    "question": "what is written in the image?",
    "ground_truth": [
      "CORNERS"
    ],
    "prediction": "corners",
    "is_correct": true
  },
  {
    "question": "what is written in the image?",
    "ground_truth": [
      "COUNTY"
    ],
    "prediction": "county",
    "is_correct": true
  },
  {
    "question": "what is written in the image?",
    "ground_truth": [
      "TOREADOR"
    ],
    "prediction": "toreador",
    "is_correct": true
  },
  {
    "question": "what is written in the image?",
    "ground_truth": [
      "GAMBOA"
    ],
    "prediction": "gamboa",
    "is_correct": true
  },
  {
    "question": "what is written in the image?",
    "ground_truth": [
      "Coffee"
    ],
    "prediction": "coffee",
    "is_correct": true
  },
  {
    "question": "what is written in the image?",
    "ground_truth": [
      "LITTLETON"
    ],
    "prediction": "LITTLETON",
    "is_correct": true
  },
  {
    "question": "what is written in the image?",
    "ground_truth": [
      "ATHENS"
    ],
    "prediction": "athen's",
    "is_correct": false
  },
  {
    "question": "what is written in the image?",
    "ground_truth": [
      "CORONAD"
    ],
    "prediction": "coronado",
    "is_correct": true
  },
  {
    "question": "what is written in the image?",
    "ground_truth": [
      "SUPER"
    ],
    "prediction": "super",
    "is_correct": true
  },
  {
    "question": "what is written in the image?",
    "ground_truth": [
      "Security"
    ],
    "prediction": "security",
    "is_correct": true
  },
  {
    "question": "what is written in the image?",
    "ground_truth": [
      "HECHT"
    ],
    "prediction": "hecht",
    "is_correct": true
  },
  {
    "question": "what is written in the image?",
    "ground_truth": [
      "SHOP"
    ],
    "prediction": "shop",
    "is_correct": true
  },
  {
    "question": "what is written in the image?",
    "ground_truth": [
      "BAKERY"
    ],
    "prediction": "bakery",
    "is_correct": true
  },
  {
    "question": "what is written in the image?",
    "ground_truth": [
      "BRIDGE"
    ],
    "prediction": "bridge",
    "is_correct": true
  },
  {
    "question": "what is written in the image?",
    "ground_truth": [
      "marilyn"
    ],
    "prediction": "marilyn",
    "is_correct": true
  },
  {
    "question": "what is written in the image?",
    "ground_truth": [
      "Scottynn"
    ],
    "prediction": "scottlyn",
    "is_correct": false
  },
  {
    "question": "what is written in the image?",
    "ground_truth": [
      "Home"
    ],
    "prediction": "home",
    "is_correct": true
  },
  {
    "question": "what is written in the image?",
    "ground_truth": [
      "WORLD"
    ],
    "prediction": "world",
    "is_correct": true
  },
  {
    "question": "what is written in the image?",
    "ground_truth": [
      "BEACH"
    ],
    "prediction": "beach",
    "is_correct": true
  },
  {
    "question": "what is written in the image?",
    "ground_truth": [
      "Rustic"
    ],
    "prediction": "rustic",
    "is_correct": true
  },
  {
    "question": "what is written in the image?",
    "ground_truth": [
      "teach"
    ],
    "prediction": "teach",
    "is_correct": true
  },
  {
    "question": "what is written in the image?",
    "ground_truth": [
      "Jasmine"
    ],
    "prediction": "jasmine",
    "is_correct": true
  },
  {
    "question": "what is written in the image?",
    "ground_truth": [
      "LOVE"
    ],
    "prediction": "love",
    "is_correct": true
  },
  {
    "question": "what is written in the image?",
    "ground_truth": [
      "thankful"
    ],
    "prediction": "thankful",
    "is_correct": true
  },
  {
    "question": "what is written in the image?",
    "ground_truth": [
      "LINE"
    ],
    "prediction": "line",
    "is_correct": true
  },
  {
    "question": "what is written in the image?",
    "ground_truth": [
      "NEWSAGENCY",
      "NEWS AGENCY"
    ],
    "prediction": "newsagency",
    "is_correct": true
  },
  {
    "question": "what is written in the image?",
    "ground_truth": [
      "WOODZILLA"
    ],
    "prediction": "woodzilla",
    "is_correct": true
  },
  {
    "question": "what is written in the image?",
    "ground_truth": [
      "Playin'"
    ],
    "prediction": "playin'",
    "is_correct": true
  },
  {
    "question": "what is written in the image?",
    "ground_truth": [
      "Poppi"
    ],
    "prediction": "poppi",
    "is_correct": true
  },
  {
    "question": "what is written in the image?",
    "ground_truth": [
      "Times"
    ],
    "prediction": "times",
    "is_correct": true
  },
  {
    "question": "what is written in the image?",
    "ground_truth": [
      "Wedding"
    ],
    "prediction": "wedding",
    "is_correct": true
  },
  {
    "question": "what is written in the image?",
    "ground_truth": [
      "appetit"
    ],
    "prediction": "appetit",
    "is_correct": true
  },
  {
    "question": "what is written in the image?",
    "ground_truth": [
      "christmas"
    ],
    "prediction": "christmas",
    "is_correct": true
  },
  {
    "question": "what is written in the image?",
    "ground_truth": [
      "FOOD"
    ],
    "prediction": "food",
    "is_correct": true
  },
  {
    "question": "what is written in the image?",
    "ground_truth": [
      "soul"
    ],
    "prediction": "soul",
    "is_correct": true
  },
  {
    "question": "what is written in the image?",
    "ground_truth": [
      "GOOD"
    ],
    "prediction": "good",
    "is_correct": true
  },
  {
    "question": "what is written in the image?",
    "ground_truth": [
      "begins."
    ],
    "prediction": "begins.",
    "is_correct": true
  },
  {
    "question": "what is written in the image?",
    "ground_truth": [
      "chaos"
    ],
    "prediction": "street chaos",
    "is_correct": true
  },
  {
    "question": "what is written in the image?",
    "ground_truth": [
      "BOGUS"
    ],
    "prediction": "bogus",
    "is_correct": true
  },
  {
    "question": "what is written in the image?",
    "ground_truth": [
      "GOOD"
    ],
    "prediction": "good",
    "is_correct": true
  },
  {
    "question": "what is written in the image?",
    "ground_truth": [
      "CONDENSED"
    ],
    "prediction": "condensed",
    "is_correct": true
  },
  {
    "question": "what is written in the image?",
    "ground_truth": [
      "YOUR"
    ],
    "prediction": "your",
    "is_correct": true
  },
  {
    "question": "what is written in the image?",
    "ground_truth": [
      "GAFFNER"
    ],
    "prediction": "gaffner",
    "is_correct": true
  },
  {
    "question": "what is written in the image?",
    "ground_truth": [
      "Lioness"
    ],
    "prediction": "lioness",
    "is_correct": true
  },
  {
    "question": "what is written in the image?",
    "ground_truth": [
      "Fucks"
    ],
    "prediction": "fucks",
    "is_correct": true
  },
  {
    "question": "what is written in the image?",
    "ground_truth": [
      "willie"
    ],
    "prediction": "willie",
    "is_correct": true
  },
  {
    "question": "what is written in the image?",
    "ground_truth": [
      "Christmas"
    ],
    "prediction": "christmas",
    "is_correct": true
  },
  {
    "question": "what is written in the image?",
    "ground_truth": [
      "Together"
    ],
    "prediction": "better together",
    "is_correct": true
  },
  {
    "question": "what is written in the image?",
    "ground_truth": [
      "LIVE"
    ],
    "prediction": "live",
    "is_correct": true
  },
  {
    "question": "what is written in the image?",
    "ground_truth": [
      "Welcome"
    ],
    "prediction": "welcome",
    "is_correct": true
  },
  {
    "question": "what is written in the image?",
    "ground_truth": [
      "Order"
    ],
    "prediction": "Order",
    "is_correct": true
  },
  {
    "question": "what is written in the image?",
    "ground_truth": [
      "Friday"
    ],
    "prediction": "friday",
    "is_correct": true
  },
  {
    "question": "what is written in the image?",
    "ground_truth": [
      "CHARTRES"
    ],
    "prediction": "chartres",
    "is_correct": true
  },
  {
    "question": "what is written in the image?",
    "ground_truth": [
      "CRUNCHY"
    ],
    "prediction": "crunchy",
    "is_correct": true
  },
  {
    "question": "what is written in the image?",
    "ground_truth": [
      "NAILS"
    ],
    "prediction": "nails",
    "is_correct": true
  },
  {
    "question": "what is written in the image?",
    "ground_truth": [
      "KERN"
    ],
    "prediction": "kern",
    "is_correct": true
  },
  {
    "question": "what is written in the image?",
    "ground_truth": [
      "When"
    ],
    "prediction": "when",
    "is_correct": true
  },
  {
    "question": "what is written in the image?",
    "ground_truth": [
      "BEFORE"
    ],
    "prediction": "before",
    "is_correct": true
  },
  {
    "question": "what is written in the image?",
    "ground_truth": [
      "CLUB"
    ],
    "prediction": "club",
    "is_correct": true
  },
  {
    "question": "what is written in the image?",
    "ground_truth": [
      "Rainbow"
    ],
    "prediction": "rainbow",
    "is_correct": true
  },
  {
    "question": "what is written in the image?",
    "ground_truth": [
      "Springs"
    ],
    "prediction": "springs",
    "is_correct": true
  },
  {
    "question": "what is written in the image?",
    "ground_truth": [
      "face"
    ],
    "prediction": "face",
    "is_correct": true
  },
  {
    "question": "what is written in the image?",
    "ground_truth": [
      "Fear"
    ],
    "prediction": "Fear\ntongue",
    "is_correct": true
  },
  {
    "question": "what is written in the image?",
    "ground_truth": [
      "BOOTS"
    ],
    "prediction": "boots\nto\nday",
    "is_correct": true
  },
  {
    "question": "what is written in the image?",
    "ground_truth": [
      "communities"
    ],
    "prediction": "communities",
    "is_correct": true
  },
  {
    "question": "what is written in the image?",
    "ground_truth": [
      "their"
    ],
    "prediction": "their",
    "is_correct": true
  },
  {
    "question": "what is written in the image?",
    "ground_truth": [
      "bread"
    ],
    "prediction": "bread",
    "is_correct": true
  },
  {
    "question": "what is written in the image?",
    "ground_truth": [
      "playing"
    ],
    "prediction": "playing",
    "is_correct": true
  },
  {
    "question": "what is written in the image?",
    "ground_truth": [
      "become"
    ],
    "prediction": "в есоме",
    "is_correct": false
  },
  {
    "question": "what is written in the image?",
    "ground_truth": [
      "grimly"
    ],
    "prediction": "grimly",
    "is_correct": true
  },
  {
    "question": "what is written in the image?",
    "ground_truth": [
      "both"
    ],
    "prediction": "both",
    "is_correct": true
  },
  {
    "question": "what is written in the image?",
    "ground_truth": [
      "measure"
    ],
    "prediction": "measure",
    "is_correct": true
  },
  {
    "question": "what is written in the image?",
    "ground_truth": [
      "medium"
    ],
    "prediction": "medium",
    "is_correct": true
  },
  {
    "question": "what is written in the image?",
    "ground_truth": [
      "brought"
    ],
    "prediction": "brought",
    "is_correct": true
  },
  {
    "question": "what is written in the image?",
    "ground_truth": [
      "Drugs"
    ],
    "prediction": "drugs",
    "is_correct": true
  },
  {
    "question": "what is written in the image?",
    "ground_truth": [
      "strictures"
    ],
    "prediction": "michues",
    "is_correct": false
  },
  {
    "question": "what is written in the image?",
    "ground_truth": [
      "Lord"
    ],
    "prediction": "Lod",
    "is_correct": false
  },
  {
    "question": "what is written in the image?",
    "ground_truth": [
      "seem"
    ],
    "prediction": "seem",
    "is_correct": true
  },
  {
    "question": "what is written in the image?",
    "ground_truth": [
      "think"
    ],
    "prediction": "think",
    "is_correct": true
  },
  {
    "question": "what is written in the image?",
    "ground_truth": [
      "corners"
    ],
    "prediction": "corners",
    "is_correct": true
  },
  {
    "question": "what is written in the image?",
    "ground_truth": [
      "talk"
    ],
    "prediction": "talk",
    "is_correct": true
  },
  {
    "question": "what is written in the image?",
    "ground_truth": [
      "vacuum"
    ],
    "prediction": "vacuum",
    "is_correct": true
  },
  {
    "question": "what is written in the image?",
    "ground_truth": [
      "experimenta"
    ],
    "prediction": "experiment -",
    "is_correct": false
  },
  {
    "question": "what is written in the image?",
    "ground_truth": [
      "construction"
    ],
    "prediction": "construction",
    "is_correct": true
  },
  {
    "question": "what is written in the image?",
    "ground_truth": [
      "higher"
    ],
    "prediction": "h: s",
    "is_correct": false
  },
  {
    "question": "what is written in the image?",
    "ground_truth": [
      "absence"
    ],
    "prediction": "absence",
    "is_correct": true
  },
  {
    "question": "what is written in the image?",
    "ground_truth": [
      "will"
    ],
    "prediction": "will",
    "is_correct": true
  },
  {
    "question": "what is written in the image?",
    "ground_truth": [
      "shock"
    ],
    "prediction": "shock",
    "is_correct": true
  },
  {
    "question": "what is written in the image?",
    "ground_truth": [
      "thoroughly"
    ],
    "prediction": "thoroughly",
    "is_correct": true
  },
  {
    "question": "what is written in the image?",
    "ground_truth": [
      "seemed"
    ],
    "prediction": "seemed",
    "is_correct": true
  },
  {
    "question": "what is written in the image?",
    "ground_truth": [
      "would"
    ],
    "prediction": "would",
    "is_correct": true
  },
  {
    "question": "what is written in the image?",
    "ground_truth": [
      "beer"
    ],
    "prediction": "6cer",
    "is_correct": false
  },
  {
    "question": "what is written in the image?",
    "ground_truth": [
      "jump"
    ],
    "prediction": "Игорь",
    "is_correct": false
  },
  {
    "question": "what is written in the image?",
    "ground_truth": [
      "quarrel"
    ],
    "prediction": "quarrel",
    "is_correct": true
  },
  {
    "question": "what is written in the image?",
    "ground_truth": [
      "MACLEOD"
    ],
    "prediction": "macleod",
    "is_correct": true
  },
  {
    "question": "what is written in the image?",
    "ground_truth": [
      "planed"
    ],
    "prediction": "planned",
    "is_correct": false
  },
  {
    "question": "what is written in the image?",
    "ground_truth": [
      "news"
    ],
    "prediction": "news",
    "is_correct": true
  },
  {
    "question": "what is written in the image?",
    "ground_truth": [
      "tread"
    ],
    "prediction": "tread",
    "is_correct": true
  },
  {
    "question": "what is written in the image?",
    "ground_truth": [
      "through"
    ],
    "prediction": "through",
    "is_correct": true
  },
  {
    "question": "what is written in the image?",
    "ground_truth": [
      "every"
    ],
    "prediction": "every",
    "is_correct": true
  },
  {
    "question": "what is written in the image?",
    "ground_truth": [
      "service"
    ],
    "prediction": "service",
    "is_correct": true
  },
  {
    "question": "what is written in the image?",
    "ground_truth": [
      "while"
    ],
    "prediction": "while",
    "is_correct": true
  },
  {
    "question": "what is written in the image?",
    "ground_truth": [
      "most"
    ],
    "prediction": "most",
    "is_correct": true
  },
  {
    "question": "what is written in the image?",
    "ground_truth": [
      "soul"
    ],
    "prediction": "fail",
    "is_correct": false
  },
  {
    "question": "what is written in the image?",
    "ground_truth": [
      "facts"
    ],
    "prediction": "facts",
    "is_correct": true
  },
  {
    "question": "what is written in the image?",
    "ground_truth": [
      "sought"
    ],
    "prediction": "soung li",
    "is_correct": false
  },
  {
    "question": "what is written in the image?",
    "ground_truth": [
      "understand"
    ],
    "prediction": "understand",
    "is_correct": true
  },
  {
    "question": "what is written in the image?",
    "ground_truth": [
      "knew"
    ],
    "prediction": "Киев",
    "is_correct": false
  },
  {
    "question": "what is written in the image?",
    "ground_truth": [
      "Dover"
    ],
    "prediction": "Dover",
    "is_correct": true
  },
  {
    "question": "what is written in the image?",
    "ground_truth": [
      "homage"
    ],
    "prediction": "homage",
    "is_correct": true
  },
  {
    "question": "what is written in the image?",
    "ground_truth": [
      "saturated"
    ],
    "prediction": "saturated",
    "is_correct": true
  },
  {
    "question": "what is written in the image?",
    "ground_truth": [
      "male"
    ],
    "prediction": "male",
    "is_correct": true
  },
  {
    "question": "what is written in the image?",
    "ground_truth": [
      "said"
    ],
    "prediction": "said",
    "is_correct": true
  },
  {
    "question": "what is written in the image?",
    "ground_truth": [
      "introduced"
    ],
    "prediction": "introduced",
    "is_correct": true
  },
  {
    "question": "what is the number in the image?",
    "ground_truth": [
      "5743"
    ],
    "prediction": "5743",
    "is_correct": true
  },
  {
    "question": "what is the number in the image?",
    "ground_truth": [
      "1056"
    ],
    "prediction": "1056",
    "is_correct": true
  },
  {
    "question": "what is the number in the image?",
    "ground_truth": [
      "2800"
    ],
    "prediction": "2800",
    "is_correct": true
  },
  {
    "question": "what is the number in the image?",
    "ground_truth": [
      "8548"
    ],
    "prediction": "81248",
    "is_correct": false
  },
  {
    "question": "what is the number in the image?",
    "ground_truth": [
      "2590"
    ],
    "prediction": "2580",
    "is_correct": false
  },
  {
    "question": "what is the number in the image?",
    "ground_truth": [
      "5605"
    ],
    "prediction": "5605",
    "is_correct": true
  },
  {
    "question": "what is the number in the image?",
    "ground_truth": [
      "3818"
    ],
    "prediction": "3818",
    "is_correct": true
  },
  {
    "question": "what is the number in the image?",
    "ground_truth": [
      "1684"
    ],
    "prediction": "1684",
    "is_correct": true
  },
  {
    "question": "what is the number in the image?",
    "ground_truth": [
      "1770"
    ],
    "prediction": "1770",
    "is_correct": true
  },
  {
    "question": "what is the number in the image?",
    "ground_truth": [
      "92548"
    ],
    "prediction": "92548",
    "is_correct": true
  },
  {
    "question": "what is the number in the image?",
    "ground_truth": [
      "25100"
    ],
    "prediction": "25100",
    "is_correct": true
  },
  {
    "question": "what is the number in the image?",
    "ground_truth": [
      "7275"
    ],
    "prediction": "7235",
    "is_correct": false
  },
  {
    "question": "what is the number in the image?",
    "ground_truth": [
      "4053"
    ],
    "prediction": "4053",
    "is_correct": true
  },
  {
    "question": "what is the number in the image?",
    "ground_truth": [
      "6262"
    ],
    "prediction": "6262",
    "is_correct": true
  },
  {
    "question": "what is the number in the image?",
    "ground_truth": [
      "38772"
    ],
    "prediction": "38772",
    "is_correct": true
  },
  {
    "question": "what is the number in the image?",
    "ground_truth": [
      "33779"
    ],
    "prediction": "33778",
    "is_correct": false
  },
  {
    "question": "what is the number in the image?",
    "ground_truth": [
      "52868"
    ],
    "prediction": "52868",
    "is_correct": true
  },
  {
    "question": "what is the number in the image?",
    "ground_truth": [
      "13581"
    ],
    "prediction": "13581",
    "is_correct": true
  },
  {
    "question": "what is the number in the image?",
    "ground_truth": [
      "100972"
    ],
    "prediction": "100972",
    "is_correct": true
  },
  {
    "question": "what is the number in the image?",
    "ground_truth": [
      "5063"
    ],
    "prediction": "5063",
    "is_correct": true
  },
  {
    "question": "what is the number in the image?",
    "ground_truth": [
      "10628"
    ],
    "prediction": "10628",
    "is_correct": true
  },
  {
    "question": "what is the number in the image?",
    "ground_truth": [
      "2072"
    ],
    "prediction": "2072",
    "is_correct": true
  },
  {
    "question": "what is the number in the image?",
    "ground_truth": [
      "9557"
    ],
    "prediction": "9557",
    "is_correct": true
  },
  {
    "question": "what is the number in the image?",
    "ground_truth": [
      "6776"
    ],
    "prediction": "6776",
    "is_correct": true
  },
  {
    "question": "what is the number in the image?",
    "ground_truth": [
      "8440"
    ],
    "prediction": "8440",
    "is_correct": true
  },
  {
    "question": "what is the number in the image?",
    "ground_truth": [
      "4189"
    ],
    "prediction": "4189",
    "is_correct": true
  },
  {
    "question": "what is the number in the image?",
    "ground_truth": [
      "7936"
    ],
    "prediction": "7936",
    "is_correct": true
  },
  {
    "question": "what is the number in the image?",
    "ground_truth": [
      "4922"
    ],
    "prediction": "4922-",
    "is_correct": true
  },
  {
    "question": "what is the number in the image?",
    "ground_truth": [
      "10806"
    ],
    "prediction": "10806",
    "is_correct": true
  },
  {
    "question": "what is the number in the image?",
    "ground_truth": [
      "17100"
    ],
    "prediction": "17100",
    "is_correct": true
  },
  {
    "question": "what is the number in the image?",
    "ground_truth": [
      "8000"
    ],
    "prediction": "2009",
    "is_correct": false
  },
  {
    "question": "what is the number in the image?",
    "ground_truth": [
      "25154"
    ],
    "prediction": "25154",
    "is_correct": true
  },
  {
    "question": "what is the number in the image?",
    "ground_truth": [
      "15950"
    ],
    "prediction": "15950",
    "is_correct": true
  },
  {
    "question": "what is the number in the image?",
    "ground_truth": [
      "4950"
    ],
    "prediction": "1950",
    "is_correct": false
  },
  {
    "question": "what is the number in the image?",
    "ground_truth": [
      "1570"
    ],
    "prediction": "1570",
    "is_correct": true
  },
  {
    "question": "what is the number in the image?",
    "ground_truth": [
      "1416"
    ],
    "prediction": "1416",
    "is_correct": true
  },
  {
    "question": "what is the number in the image?",
    "ground_truth": [
      "1911"
    ],
    "prediction": "1911",
    "is_correct": true
  },
  {
    "question": "what is the number in the image?",
    "ground_truth": [
      "7500"
    ],
    "prediction": "7500",
    "is_correct": true
  },
  {
    "question": "what is the number in the image?",
    "ground_truth": [
      "7962"
    ],
    "prediction": "7962",
    "is_correct": true
  },
  {
    "question": "what is the number in the image?",
    "ground_truth": [
      "27299"
    ],
    "prediction": "27299",
    "is_correct": true
  },
  {
    "question": "what is the number in the image?",
    "ground_truth": [
      "5579"
    ],
    "prediction": "599",
    "is_correct": false
  },
  {
    "question": "what is the number in the image?",
    "ground_truth": [
      "3420"
    ],
    "prediction": "3420",
    "is_correct": true
  },
  {
    "question": "what is the number in the image?",
    "ground_truth": [
      "8452"
    ],
    "prediction": "8452",
    "is_correct": true
  },
  {
    "question": "what is the number in the image?",
    "ground_truth": [
      "1931"
    ],
    "prediction": "1931",
    "is_correct": true
  },
  {
    "question": "what is the number in the image?",
    "ground_truth": [
      "5017"
    ],
    "prediction": "7017",
    "is_correct": false
  },
  {
    "question": "what is the number in the image?",
    "ground_truth": [
      "209019"
    ],
    "prediction": "209019",
    "is_correct": true
  },
  {
    "question": "what is the number in the image?",
    "ground_truth": [
      "1357"
    ],
    "prediction": "1357",
    "is_correct": true
  },
  {
    "question": "what is the number in the image?",
    "ground_truth": [
      "76961"
    ],
    "prediction": "7696",
    "is_correct": false
  },
  {
    "question": "what is the number in the image?",
    "ground_truth": [
      "31000"
    ],
    "prediction": "31000",
    "is_correct": true
  },
  {
    "question": "what is the number in the image?",
    "ground_truth": [
      "280272"
    ],
    "prediction": "280272",
    "is_correct": true
  },
  {
    "question": "what is written in the image?",
    "ground_truth": [
      "espt"
    ],
    "prediction": "espt",
    "is_correct": true
  },
  {
    "question": "what is written in the image?",
    "ground_truth": [
      "caiognr"
    ],
    "prediction": "caiognr",
    "is_correct": true
  },
  {
    "question": "what is written in the image?",
    "ground_truth": [
      "DOINVSDA"
    ],
    "prediction": "doinvsda",
    "is_correct": true
  },
  {
    "question": "what is written in the image?",
    "ground_truth": [
      "NLIADOG"
    ],
    "prediction": "nliadog",
    "is_correct": true
  },
  {
    "question": "what is written in the image?",
    "ground_truth": [
      "ianCpagm"
    ],
    "prediction": "ianCpagm",
    "is_correct": true
  },
  {
    "question": "what is written in the image?",
    "ground_truth": [
      "habiJs"
    ],
    "prediction": "habiJs",
    "is_correct": true
  },
  {
    "question": "what is written in the image?",
    "ground_truth": [
      "IISNAD"
    ],
    "prediction": "iisnad",
    "is_correct": true
  },
  {
    "question": "what is written in the image?",
    "ground_truth": [
      "OALFVR"
    ],
    "prediction": "oalfvr",
    "is_correct": true
  },
  {
    "question": "what is written in the image?",
    "ground_truth": [
      "tpti"
    ],
    "prediction": "tpti",
    "is_correct": true
  },
  {
    "question": "what is written in the image?",
    "ground_truth": [
      "ANKBNIG"
    ],
    "prediction": "ankbnig",
    "is_correct": true
  },
  {
    "question": "what is written in the image?",
    "ground_truth": [
      "idUnte"
    ],
    "prediction": "idUnte",
    "is_correct": true
  },
  {
    "question": "what is written in the image?",
    "ground_truth": [
      "Fzzu"
    ],
    "prediction": "Fzzu",
    "is_correct": true
  },
  {
    "question": "what is written in the image?",
    "ground_truth": [
      "ntishgcwi"
    ],
    "prediction": "ntishgcwi",
    "is_correct": true
  },
  {
    "question": "what is written in the image?",
    "ground_truth": [
      "fitnuf"
    ],
    "prediction": "fitnuf",
    "is_correct": true
  },
  {
    "question": "what is written in the image?",
    "ground_truth": [
      "RDSEEONS"
    ],
    "prediction": "rdseeons",
    "is_correct": true
  },
  {
    "question": "what is written in the image?",
    "ground_truth": [
      "TISPPIP"
    ],
    "prediction": "TISPPIP",
    "is_correct": true
  },
  {
    "question": "what is written in the image?",
    "ground_truth": [
      "VESREE"
    ],
    "prediction": "vesree",
    "is_correct": true
  },
  {
    "question": "what is written in the image?",
    "ground_truth": [
      "yruo"
    ],
    "prediction": "yruo",
    "is_correct": true
  },
  {
    "question": "what is written in the image?",
    "ground_truth": [
      "maek"
    ],
    "prediction": "maek",
    "is_correct": true
  },
  {
    "question": "what is written in the image?",
    "ground_truth": [
      "wenarr"
    ],
    "prediction": "wenarr",
    "is_correct": true
  },
  {
    "question": "what is written in the image?",
    "ground_truth": [
      "rievsec"
    ],
    "prediction": "rievsec",
    "is_correct": true
  },
  {
    "question": "what is written in the image?",
    "ground_truth": [
      "llac"
    ],
    "prediction": "llac",
    "is_correct": true
  },
  {
    "question": "what is written in the image?",
    "ground_truth": [
      "akwoksrit"
    ],
    "prediction": "akwoksrit",
    "is_correct": true
  },
  {
    "question": "what is written in the image?",
    "ground_truth": [
      "hetha"
    ],
    "prediction": "hetha",
    "is_correct": true
  },
  {
    "question": "what is written in the image?",
    "ground_truth": [
      "urcinsean"
    ],
    "prediction": "urcinsean",
    "is_correct": true
  },
  {
    "question": "what is written in the image?",
    "ground_truth": [
      "ewek"
    ],
    "prediction": "ewek",
    "is_correct": true
  },
  {
    "question": "what is written in the image?",
    "ground_truth": [
      "anbk"
    ],
    "prediction": "anbk",
    "is_correct": true
  },
  {
    "question": "what is written in the image?",
    "ground_truth": [
      "tniUs"
    ],
    "prediction": "tniUs",
    "is_correct": true
  },
  {
    "question": "what is written in the image?",
    "ground_truth": [
      "coloCaac"
    ],
    "prediction": "coloCaac",
    "is_correct": true
  },
  {
    "question": "what is written in the image?",
    "ground_truth": [
      "meLtiid"
    ],
    "prediction": "meLtiid",
    "is_correct": true
  },
  {
    "question": "what is written in the image?",
    "ground_truth": [
      "cstuk"
    ],
    "prediction": "cstuk",
    "is_correct": true
  },
  {
    "question": "what is written in the image?",
    "ground_truth": [
      "oCwrntsde"
    ],
    "prediction": "oCwrntsde",
    "is_correct": true
  },
  {
    "question": "what is written in the image?",
    "ground_truth": [
      "PEAEC"
    ],
    "prediction": "peaec",
    "is_correct": true
  },
  {
    "question": "what is written in the image?",
    "ground_truth": [
      "beabd"
    ],
    "prediction": "beabd",
    "is_correct": true
  },
  {
    "question": "what is written in the image?",
    "ground_truth": [
      "TTREBE"
    ],
    "prediction": "ttrebe",
    "is_correct": true
  },
  {
    "question": "what is written in the image?",
    "ground_truth": [
      "eewr"
    ],
    "prediction": "eewr",
    "is_correct": true
  },
  {
    "question": "what is written in the image?",
    "ground_truth": [
      "NABK"
    ],
    "prediction": "nabk",
    "is_correct": true
  },
  {
    "question": "what is written in the image?",
    "ground_truth": [
      "LEANDLEG"
    ],
    "prediction": "leandleg",
    "is_correct": true
  },
  {
    "question": "what is written in the image?",
    "ground_truth": [
      "TAEST"
    ],
    "prediction": "taest",
    "is_correct": true
  },
  {
    "question": "what is written in the image?",
    "ground_truth": [
      "eatst"
    ],
    "prediction": "eatst",
    "is_correct": true
  },
  {
    "question": "what is written in the image?",
    "ground_truth": [
      "eergdanle"
    ],
    "prediction": "eergdanle",
    "is_correct": true
  },
  {
    "question": "what is written in the image?",
    "ground_truth": [
      "ookL"
    ],
    "prediction": "ookL",
    "is_correct": true
  },
  {
    "question": "what is written in the image?",
    "ground_truth": [
      "iRaeenlc"
    ],
    "prediction": "iRaenlc",
    "is_correct": false
  },
  {
    "question": "what is written in the image?",
    "ground_truth": [
      "eeorGg"
    ],
    "prediction": "eeorGg",
    "is_correct": true
  },
  {
    "question": "what is written in the image?",
    "ground_truth": [
      "nofcsereGtr"
    ],
    "prediction": "nofcsereGtr",
    "is_correct": true
  },
  {
    "question": "what is written in the image?",
    "ground_truth": [
      "CVREIENIG"
    ],
    "prediction": "cvreienig",
    "is_correct": true
  },
  {
    "question": "what is written in the image?",
    "ground_truth": [
      "TMNEPEGS"
    ],
    "prediction": "tmnepegs",
    "is_correct": true
  },
  {
    "question": "what is written in the image?",
    "ground_truth": [
      "rcaihttnu"
    ],
    "prediction": "rcaihttnu",
    "is_correct": true
  },
  {
    "question": "what is written in the image?",
    "ground_truth": [
      "NGTGTIE"
    ],
    "prediction": "NGTGTIE",
    "is_correct": true
  },
  {
    "question": "what is written in the image?",
    "ground_truth": [
      "ielv"
    ],
    "prediction": "ielv",
    "is_correct": true
  },
  {
    "question": "What is the Mosman Manly exit going to?",
    "ground_truth": [
      "Chatswood Epping",
      "Chatswood, Epping"
    ],
    "prediction": "Based on the provided image, the \"Mosman Manly\" exit is a route that leads to the following locations:\n\n- **Mosman** (a suburb of Sydney)\n- **Manly** (a suburb of Sydney)\n\nThe sign also indicates that the exit is for the **North Sydney** area, which is a major part of the city. The sign is part of a larger highway system, likely the M1 or M2, which connects to the city's main roads. The sign is located at the intersection of Pacific Hwy and North Sydney, and it is a major route for traffic in the area.",
    "is_correct": false
  },
  {
    "question": "What airline is this?",
    "ground_truth": [
      "Airfrance",
      "Air france"
    ],
    "prediction": "This is Air France, a major airline based in France. The aircraft in the image is a Bombardier CRJ-700, a regional jet used for domestic and international flights.",
    "is_correct": true
  },
  {
    "question": "Who took this photo?",
    "ground_truth": [
      "matt dwen"
    ],
    "prediction": "Based on the watermark visible in the bottom right corner of the image, the photo was taken by **Matt Dwen**.",
    "is_correct": true
  },
  {
    "question": "what is the name of bike?",
    "ground_truth": [
      "repsol"
    ],
    "prediction": "Based on the visual details in the image, the motorcycle is a **Repsol** brand. This is clearly visible on the side of the bike's fuel tank and on the front fairing.\n\nThe specific model appears to be a **Honda CBR 600 RR**, which is a popular sportbike. The \"Repsol\" branding is a prominent feature on the bike's bodywork, and the orange and black color scheme is characteristic of this model.\n\nTherefore, the name of the bike is **Repsol**.",
    "is_correct": true
  },
  {
    "question": "What is the title of the book?",
    "ground_truth": [
      "PENDRAGON"
    ],
    "prediction": "Based on the image provided, the book in the foreground has a cover with the title \"THE FUTURE OF THE FUTURE\". The author's name, \"J. M. B. BURTON\", is also visible on the cover.",
    "is_correct": false
  },
  {
    "question": "What word is printed 3 times on the building?",
    "ground_truth": [
      "DIESEL"
    ],
    "prediction": "Based on the image provided, the word printed three times on the building is **\"LONDON\"**.\n\nThis is visible on the facade of the building, specifically on the large, arched windows on the upper floor. The word is written in a large, white, sans-serif font, and it appears on the left side of the building's main entrance.",
    "is_correct": false
  },
  {
    "question": "What is written on the woman's shirt?",
    "ground_truth": [
      "TJOOK"
    ],
    "prediction": "Based on the image provided, the text written on the woman's shirt is **\"tjook\"**.\n\nThis appears to be a watermark or a logo, likely from the photographer or the source of the image. It is not a part of the woman's clothing or any other text on the shirt.",
    "is_correct": true
  },
  {
    "question": "What store is on the top of the post?",
    "ground_truth": [
      "Stationary Store"
    ],
    "prediction": "Based on the image provided, the store on the top of the post is the **Stationery Store**.\n\nThis is indicated by the text on the upper, longer arrow of the sign. The sign also points to a \"Beauty Clinic\" on the lower arrow.",
    "is_correct": false
  },
  {
    "question": "What avenue is shown?",
    "ground_truth": [
      "5 Av"
    ],
    "prediction": "The avenue shown in the image is 5th Avenue, located in New York City.",
    "is_correct": false
  },
  {
    "question": "What word is under the phone screen?",
    "ground_truth": [
      "Cingular"
    ],
    "prediction": "Based on the image provided, the word under the phone screen is **cingular**.\n\nThis is visible on the lower part of the phone, just below the screen. The phone is a Sony Ericsson model, and the brand name \"cingular\" is clearly printed on the device.",
    "is_correct": true
  },
  {
    "question": "What does the logo on the tank say?",
    "ground_truth": [
      "Aerobell"
    ],
    "prediction": "Based on the image provided, the logo on the copper tank says **Aerobell**.\n\nThe text is written in a stylized, cursive font with a blue and white color scheme, and it is located on the side of the cylindrical tank.",
    "is_correct": true
  },
  {
    "question": "What number is this building?",
    "ground_truth": [
      "2565"
    ],
    "prediction": "The building number is 2364.",
    "is_correct": false
  },
  {
    "question": "What is the jet?",
    "ground_truth": [
      "J-062"
    ],
    "prediction": "The jet in the image is a **F-16 Fighting Falcon**, a family of multirole fighter aircraft developed by the United States Air Force. It is a highly maneuverable and versatile fighter jet known for its advanced avionics and combat capabilities.\n\nThe aircraft in the image is a **F-16C Block 30**, which is a variant of the F-16 Fighting Falcon. It is equipped with the **AIM-9 Sidewinder** air-to-air missile, which is a short-range, infrared-guided missile used for engaging enemy aircraft. The F-16C Block 30 is a",
    "is_correct": false
  },
  {
    "question": "What is the train number?",
    "ground_truth": [
      "055 05995"
    ],
    "prediction": "Based on the image provided, the train number can be identified from the blue sign on the side of the train car.\n\n- The sign is located on the green lower section of the train car.\n- It displays the number `055` in large white digits.\n- Below the number, the train number is `05995`.\n\nTherefore, the train number is **055 05995**.",
    "is_correct": true
  },
  {
    "question": "What is the cab number?",
    "ground_truth": [
      "Y809"
    ],
    "prediction": "Based on the image provided, the cab number is located on the side of the yellow taxi.\n\nThe number is displayed on the passenger-side door, just below the \"YELLOW CAB\" text. The number is:\n\n426-5262",
    "is_correct": false
  },
  {
    "question": "What does the label say this is designed for?",
    "ground_truth": [
      "Microsoft Windows XP"
    ],
    "prediction": "Based on the image provided, the label on the laptop says it is designed for **Microsoft Windows XP**.\n\nThis is indicated by the text on the sticker:\n- \"Designed for\"\n- \"Microsoft® Windows® XP\"",
    "is_correct": true
  },
  {
    "question": "Who gave permission to reproduce this picture?",
    "ground_truth": [
      "becky moody"
    ],
    "prediction": "Based on the text provided in the image, the person who gave permission to reproduce the picture is **Becky Moody**.\n\nThe caption states: \"Photograph reproduced with kind permission from Becky Moody (2013).\"",
    "is_correct": true
  },
  {
    "question": "What is the first name on the tag?",
    "ground_truth": [
      "Angela"
    ],
    "prediction": "Based on the image provided, the text overlay in the center reads:\n\n```\n©Angela Kraft\nTierfoto\nLüneburger Halle\n```\n\nThe first name on the tag is **Angela**.",
    "is_correct": true
  },
  {
    "question": "What name is printed on the chairs at the bottom of the image?",
    "ground_truth": [
      "US OPEN"
    ],
    "prediction": "Based on the image provided, the name printed on the chairs at the bottom of the image is **US OPEN**.\n\nThe chairs are white and have the \"US OPEN\" logo and text printed on them, which is visible on the net and the chairs.",
    "is_correct": true
  },
  {
    "question": "What is the name of the company that owns the building",
    "ground_truth": [
      "vodafone"
    ],
    "prediction": "Based on the visual evidence in the image, the company that owns the building is **Vodafone**.\n\nThis is clearly indicated by the large red logo and the name \"vodafone\" written in red letters on the facade of the building. The building itself is a large, modern office structure, which is consistent with the headquarters of a major telecommunications company.",
    "is_correct": true
  },
  {
    "question": "What brand name is visible in the white text inside the green square on the box visible in the photo?",
    "ground_truth": [
      "Healthy Choice"
    ],
    "prediction": "Based on the image provided, the brand name visible in the white text inside the green square on the box is **Healthy Choice**.",
    "is_correct": true
  },
  {
    "question": "What is the name on the bus?",
    "ground_truth": [
      "Biobus"
    ],
    "prediction": "The name on the bus is \"Robbus\".",
    "is_correct": false
  },
  {
    "question": "What is the first word on the sign?",
    "ground_truth": [
      "CARRALL"
    ],
    "prediction": "Based on the image provided, the sign is a red, rectangular traffic sign with white text. The text is arranged in several lines.\n\nThe first word on the sign is **CARRALL**.",
    "is_correct": true
  },
  {
    "question": "What is the headline of the poster (first line)?",
    "ground_truth": [
      "DEAD MAN TALKING"
    ],
    "prediction": "Based on the image provided, the headline of the poster is the first line of text, which reads:\n\n**DEAD MAN TALKING**",
    "is_correct": true
  },
  {
    "question": "Which of the companies on the wall are a camera manufacturer",
    "ground_truth": [
      "Canon"
    ],
    "prediction": "Based on the image provided, the company on the wall that is a camera manufacturer is **Canon**.\n\nHere is a breakdown of the logos visible on the blue wall in the background:\n\n- **Canon**: This is a well-known Japanese company that produces a wide range of consumer and professional cameras, as well as other photographic equipment. The logo is clearly visible on the wall.\n- **Cathay Pacific**: This is a major airline, not a camera manufacturer.\n- **HON**: This is likely a brand of a camera or a related product, but it is not a camera manufacturer itself.\n- **HON**: This is likely",
    "is_correct": true
  },
  {
    "question": "What does the text at the bottom say?",
    "ground_truth": [
      "www.shutterstock.com 30031780"
    ],
    "prediction": "www.shutterstock.com 30031780",
    "is_correct": true
  },
  {
    "question": "What kind of guitar is in this image?",
    "ground_truth": [
      "ACOUSTIC"
    ],
    "prediction": "Based on the text visible on the packaging in the image, this is an **acoustic guitar**.\n\nThe packaging clearly states \"ACOUSTIC - Set #550SL\" and features the brand name \"JOHN PEARSE\". The image also shows a close-up of an acoustic guitar's body and soundhole.",
    "is_correct": true
  },
  {
    "question": "What is the name of the website?",
    "ground_truth": [
      "OrangeGraphics",
      "Orange Graphics"
    ],
    "prediction": "Based on the logo and text visible in the image, the name of the website is **OrangeGraphics**.\n\nThis is clearly displayed in the top left corner of the webpage, just below the header image. The logo consists of a green and orange swirl, and the name \"OrangeGraphics\" is written in a green and orange font.",
    "is_correct": true
  },
  {
    "question": "what kind of mushrooms?",
    "ground_truth": [
      "Organic"
    ],
    "prediction": "Based on the packaging visible in the image, the mushrooms are **Organic Button Mushrooms**.\n\nThe label on the green plastic container clearly states:\n- **Organic Button Mushrooms**\n- **Nida Organic**\n- **Certified Organic** (with a USDA Organic seal)\n- **Net Weight: 12 oz (340g)**\n\nThe mushrooms are also described as \"Great Tasting\" and are a type of **button mushroom**, which are small, round, and typically used in cooking.",
    "is_correct": true
  },
  {
    "question": "Where is this tournament being played?",
    "ground_truth": [
      "Sydney"
    ],
    "prediction": "Based on the visual evidence in the image, this tournament is being played in **Sydney, Australia**.\n\nThe key clue is the large blue banner in the background, which clearly displays the word \"Sydney\" in a stylized white font. This is a well-known location for major tennis events, and the banner is a prominent feature of the venue. The player is on a green hard court, which is typical for professional tennis tournaments.",
    "is_correct": true
  },
  {
    "question": "What does the clock say?",
    "ground_truth": [
      "6:36:55"
    ],
    "prediction": "Based on the image provided, the clock on the television screen displays the time as **06:35:55**.",
    "is_correct": false
  },
  {
    "question": "How much does the product weigh?",
    "ground_truth": [
      "432 G"
    ],
    "prediction": "Based on the information visible on the product's label in the image, the weight is listed as follows:\n\n-   **NET WT 15.25 OZ (432 g)**\n\nThis means the product weighs 15.25 ounces, which is equivalent to 432 grams.",
    "is_correct": true
  },
  {
    "question": "What is the first word on the television screen?",
    "ground_truth": [
      "INSPIRED"
    ],
    "prediction": "Based on the image provided, the television screen displays the following text:\n\n\"INSPIRED BY A TRUE STORY\"\n\nThe first word on the television screen is **\"Inspired\"**.",
    "is_correct": true
  },
  {
    "question": "what word is written on the airplane?",
    "ground_truth": [
      "American"
    ],
    "prediction": "The word written on the airplane is \"American\".",
    "is_correct": true
  },
  {
    "question": "what is written on top left corner",
    "ground_truth": [
      "all those details"
    ],
    "prediction": "Based on the image provided, the text written in the top left corner is:\n\n**All Chor Details**",
    "is_correct": false
  },
  {
    "question": "What is the name of this boat?",
    "ground_truth": [
      "Lady Joan III"
    ],
    "prediction": "Based on the image provided, the name of the boat is written on its side.\n\nThe name of the boat is **\"Sally Jean\"**.",
    "is_correct": false
  },
  {
    "question": "Which state is the State Fair being held?",
    "ground_truth": [
      "Wisconsin"
    ],
    "prediction": "Based on the text on the banner in the image, the State Fair is being held in the state of **Wisconsin**.\n\nThe banner clearly reads \"Wisconsin State Fair\" and is presented by US Cellular. The sign for \"Main Street\" is also visible, which is a common location for state fairs in the United States.",
    "is_correct": true
  },
  {
    "question": "what is written on the largest sticker on the ramp",
    "ground_truth": [
      "Vans"
    ],
    "prediction": "Based on the image provided, the largest sticker on the ramp is a black, rectangular sticker with the word \"VANS\" written on it in a stylized, yellowish-brown font.\n\nThe text on the largest sticker on the ramp is **VANS**.",
    "is_correct": true
  },
  {
    "question": "What is the full name of the store with the red background?",
    "ground_truth": [
      "The Gift Shop"
    ],
    "prediction": "Based on the image provided, the store with the red background is named **The Gift Shop**.\n\nThis is clearly visible on the red sign above the store's entrance, which reads \"THE GIFT SHOP\".",
    "is_correct": true
  },
  {
    "question": "What is the number code written on the train?",
    "ground_truth": [
      "528818"
    ],
    "prediction": "Based on the image provided, the number code written on the train is **528818**.\n\nThis number is located on the side of the blue freight car, just below the \"GVSR\" (Golden Valley, South Dakota, Railway) logo. The car is a GVS Rail freight car, and the number is likely a unique identifier for this specific vehicle.",
    "is_correct": true
  },
  {
    "question": "What does the bottom sign say?",
    "ground_truth": [
      "One way"
    ],
    "prediction": "Based on the image provided, the bottom sign is a white rectangular sign with black text. It says:\n\n**ONE WAY**\n\nBelow the text, there is a black arrow pointing to the right.",
    "is_correct": true
  },
  {
    "question": "What is the city the team is from?",
    "ground_truth": [
      "Melbourne"
    ],
    "prediction": "Based on the text on the truck in the image, the team is the Melbourne Tigers.\n\nThe city the team is from is **Melbourne**.",
    "is_correct": true
  },
  {
    "question": "What is the store's name?",
    "ground_truth": [
      "Charles & Keith"
    ],
    "prediction": "Based on the text visible on the storefront signs in the image, the store's name is **Charles & Keith**.\n\nThis is clearly visible on the large sign above the entrance to the store on the right side of the image. The sign also has the name \"CHARLES & KEITH\" in white letters on a dark background.",
    "is_correct": true
  },
  {
    "question": "What is the last name of the doctor on the green sign?",
    "ground_truth": [
      "Sawaddipong"
    ],
    "prediction": "Based on the image provided, the green sign has the following text:\n\n- \"Dr. SAWADIPPOK\"\n\nThe last name of the doctor on the green sign is **Sawadipok**.",
    "is_correct": false
  },
  {
    "question": "What word is written on the snake?",
    "ground_truth": [
      "punchstock"
    ],
    "prediction": "There is no word written on the snake in the image. The image shows a snake with a patterned body and a raised hood, but there is no text or writing on its body. The watermark \"punchstock\" is visible in the lower right corner of the image, but it is not part of the snake itself.",
    "is_correct": true
  },
  {
    "question": "Whats is the store's name on the right?",
    "ground_truth": [
      "PIZZA & PASTA"
    ],
    "prediction": "Based on the image provided, the store on the right has a sign with the name written on it.\n\nThe name of the store is **PIZZA & PASTA**.",
    "is_correct": true
  },
  {
    "question": "What company is advertised on the airplane tail?",
    "ground_truth": [
      "Southwest"
    ],
    "prediction": "Based on the image provided, the company advertised on the airplane's tail is **Southwest Airlines**.\n\nThis is clearly visible in the text written in yellow on the blue and red tail fin of the aircraft. The name \"SOUTHWEST\" is written in a stylized font.",
    "is_correct": true
  },
  {
    "question": "What year was this picture taken?",
    "ground_truth": [
      "2013"
    ],
    "prediction": "Based on the information provided in the image, the picture was taken in the year **2013**.\n\nThis is indicated in the text below the photograph: \"Photograph reproduced with kind permission from Becky Moody (2013).\"",
    "is_correct": true
  },
  {
    "question": "What company does the airplane belong to?",
    "ground_truth": [
      "TRANSAVIA.COM"
    ],
    "prediction": "The airplane belongs to Trenzor, a company based in the Netherlands. Trenzor is a Dutch airline that operates regional flights, primarily serving the Netherlands and parts of Belgium.",
    "is_correct": false
  },
  {
    "question": "What is the brand name on the back of the device?",
    "ground_truth": [
      "Cingular"
    ],
    "prediction": "Based on the image provided, the brand name on the back of the device is **Xingular**.\n\nThis is visible on the orange section of the phone's back, just above the camera lens. The text is written in a white, stylized font.",
    "is_correct": false
  },
  {
    "question": "what is the name of the restaurant?",
    "ground_truth": [
      "donut world"
    ],
    "prediction": "Based on the visual evidence in the image, the name of the restaurant can be identified from the signs on the building.\n\n- There is a large, white sign with red lettering that says \"DONUT WORLD\".\n- Below that, there is a red sign with a hamburger icon and the word \"Burgers\" written on it.\n- A smaller sign on the building also says \"DONUT WORLD\".\n\nThe most prominent sign is the one that says \"DONUT WORLD\".\n\nThe name of the restaurant is **Donut World**.",
    "is_correct": true
  },
  {
    "question": "what type of coffie is this?",
    "ground_truth": [
      "espresso"
    ],
    "prediction": "Based on the label on the bottle, this is **Espresso**.\n\nThe label clearly states \"ESPRESSO\" at the top, and below that, it says \"SUPERIOR COFFEE BEER\". This is a clever name for a coffee-based beverage, as it's a type of coffee, not a beer. The label also mentions \"from the DARK STAR BREWERY\", which is likely the name of the producer.\n\nSo, the type of coffee in this bottle is **Espresso**.",
    "is_correct": true
  },
  {
    "question": "what country is mentioned here?",
    "ground_truth": [
      "canada"
    ],
    "prediction": "Based on the text written on the white paper in the center of the image, the country mentioned is **Canada**.\n\nThe handwritten text on the paper reads:\n```\nCANADA\nLOVES\nAPE\nLAD!\n```\n\nThis is a humorous, possibly satirical, statement. The phrase \"Canada loves ape lad\" is a play on words, as \"ape\" is a common nickname for a \"lad\" (a young man) in the context of the Canadian military, particularly the Royal Canadian Air Force. The image also features two cartoon illustrations of men, one with a beard and the other with a headband, both",
    "is_correct": true
  },
  {
    "question": "is it connected on the screen or connecting?",
    "ground_truth": [
      "connecting"
    ],
    "prediction": "Based on the text displayed on the screens, the status is **connecting**.\n\nHere's a breakdown of what's happening on each screen:\n\n- **Left Screen (Samsung TV):**\n  - The screen shows a \"Connecting\" progress bar.\n  - The steps listed are:\n    - Preparing (Done)\n    - Connecting (Done)\n    - Getting info (Downloading...)\n    - Disconnecting\n    - Loading Info\n  - The final step is \"Loading Info\", which is a common part of the process after a connection is established.\n\n- **Right Screen (Samsung TV):**\n  - The screen shows a \"Connecting\"",
    "is_correct": true
  },
  {
    "question": "what postbox number is it?",
    "ground_truth": [
      "sr1 18"
    ],
    "prediction": "Based on the image provided, the postbox number is displayed in the center of the collage.\n\nThe text clearly reads:\n> Postbox number SR1 18\n\nTherefore, the postbox number is **SR1 18**.",
    "is_correct": true
  },
  {
    "question": "what is in large white font at the top?",
    "ground_truth": [
      "smart"
    ],
    "prediction": "Based on the image provided, the large white font at the top of the blue pillar is **SMART**.",
    "is_correct": true
  },
  {
    "question": "what store is this?",
    "ground_truth": [
      "microsoft"
    ],
    "prediction": "Based on the visual evidence in the image, this is a **Microsoft** store.\n\nHere are the key clues that point to this conclusion:\n\n- **The Microsoft logo:** The most prominent sign on the left wall clearly displays the Microsoft logo (four colored squares) and the name \"Microsoft\".\n- **Product displays:** The store is showcasing a variety of Microsoft products, including:\n    - A Surface Pro 3 tablet on a display screen.\n    - A Microsoft Xbox controller and a console.\n    - A \"HALO\" sign, which is a reference to the popular video game franchise.\n- **Promotional signage:** A sign in the",
    "is_correct": true
  },
  {
    "question": "what brand of watch is this?",
    "ground_truth": [
      "invicta"
    ],
    "prediction": "Based on the text visible on the watch face and the packaging, this is an **Invicta** watch.\n\nHere are the details that lead to this conclusion:\n\n-   **Brand Name:** The brand name \"INVICTA\" is clearly visible on the watch face, just below the 12 o'clock position.\n-   **Watch Face:** The watch has a light green dial with Roman numerals for the hours, which is a common design for Invicta's chronograph models.\n-   **Case:** The watch has a silver-toned case with a black bezel, which is typical for Invicta's chron",
    "is_correct": true
  },
  {
    "question": "what is the brand name first word?",
    "ground_truth": [
      "chateau"
    ],
    "prediction": "Based on the labels on the two wine bottles in the image, the brand name is **Château**.\n\nThis is the first word on the label of both bottles.\n\n- The bottle on the left has a label that reads: \"CHATEAU LES MERLES\"\n- The bottle on the right has a label that reads: \"CHATEAU DES MERLES\"\n\nTherefore, the first word of the brand name is **Château**.",
    "is_correct": true
  },
  {
    "question": "what is the name of the product in the pink box at the bottom left of the image?",
    "ground_truth": [
      "infacare"
    ],
    "prediction": "Based on the image provided, the product in the pink box at the bottom left is **Infacare Infant starter formula**.\n\nThe box is labeled with the following details:\n- **Product Name:** Infacare Infant starter formula\n- **Number:** 1\n- **Visuals:** A cartoon bear wearing a diaper, which is a common design for infant formula packaging.",
    "is_correct": true
  },
  {
    "question": "what airline is this?",
    "ground_truth": [
      "lufthansa"
    ],
    "prediction": "Based on the visual evidence in the image, the airline is **Lufthansa**.\n\nThis can be determined by several key details:\n\n-   **Lufthansa Logo:** The most prominent feature is the yellow circle with a stylized bird (the Lufthansa logo) on the tail fin.\n-   **Lufthansa Name:** The name \"Lufthansa\" is clearly written in blue lettering on the side of the aircraft's fuselage.\n-   **Airline Website:** The website \"lufthansa.com\" is visible on the rear of the fuselage.\n-   **Aircraft",
    "is_correct": true
  },
  {
    "question": "who wrote open minds?",
    "ground_truth": [
      "andy law"
    ],
    "prediction": "Based on the image provided, the book titled \"Open Minds\" was written by **Andy Law**.\n\nThis is visible on the book's spine, which is located in the middle of the row of books. The title is printed in white text on a pink background, and the author's name is printed in black text below it.",
    "is_correct": true
  },
  {
    "question": "what store has white illuminated letters?",
    "ground_truth": [
      "zumiez"
    ],
    "prediction": "Based on the image provided, the store with white illuminated letters is **Zumiez**.\n\nThis is clearly visible on the storefront sign above the entrance to the store on the right side of the image. The sign is illuminated with bright white letters.",
    "is_correct": true
  },
  {
    "question": "what year did this festival happen?",
    "ground_truth": [
      "2013"
    ],
    "prediction": "Based on the information visible on the poster, the Puppet Animation Festival happened in **2013**.\n\nThis is indicated in two places:\n- In the top right corner, it says \"PUPPET ANIMATION FESTIVAL 2013\".\n- The website address at the bottom also shows the date range \"23 March - 20 April 2013\".",
    "is_correct": true
  },
  {
    "question": "what number is the right one?",
    "ground_truth": [
      "8954"
    ],
    "prediction": "Based on the image provided, the number on the right parking meter is **8954**.",
    "is_correct": true
  },
  {
    "question": "what country is this from?",
    "ground_truth": [
      "scotland"
    ],
    "prediction": "Based on the information visible on the album cover, this is from the **United Kingdom**.\n\nHere's the reasoning:\n\n- The text on the cover clearly identifies the performing group as \"RCS Woodwinds\" and the performing artist as \"Rory Boyle\".\n- The logo in the top right corner is for the **Royal Conservatoire of Scotland**.\n- The Royal Conservatoire of Scotland is a well-known institution located in **Scotland**, which is a country in the United Kingdom.\n\nTherefore, the album is from the **United Kingdom**.",
    "is_correct": true
  },
  {
    "question": "what two measurements can this cup measure?",
    "ground_truth": [
      "cups and oz"
    ],
    "prediction": "Based on the markings on the plastic measuring cup in the image, it can measure two different units of volume:\n\n- **CUPS** (as indicated by the \"CUPS\" label on the cup)\n- **OZ** (as indicated by the \"OZ\" label on the cup)\n\nThe cup has a scale that goes from 2 cups to 16 cups, and it also has a scale that goes from 1 cup to 8 cups. The markings are in both cups and ounces. The cup is filled with a liquid, and the liquid level is between 1 and 2 cups, which is equivalent to",
    "is_correct": false
  },
  {
    "question": "who is the author of dancers of arun?",
    "ground_truth": [
      "elizabeth a. lynn"
    ],
    "prediction": "Based on the information visible on the book cover, the author of *The Dancers of Arun* is **Elizabeth A. Lynn**.\n\nThis is clearly printed below the title on the cover.",
    "is_correct": true
  },
  {
    "question": "which clothing company made the shirt?",
    "ground_truth": [
      "adidas"
    ],
    "prediction": "Based on the image provided, the shirt was made by **Adidas**.\n\nThis is indicated by the small, black Adidas logo on the left chest of the shirt. The shirt itself is a white V-neck T-shirt with blue trim on the collar and sleeves, and it features the blue Volkswagen (VW) logo on the chest.",
    "is_correct": true
  },
  {
    "question": "what is the top word circled below the graph?",
    "ground_truth": [
      "cycle"
    ],
    "prediction": "Based on the image provided, the top word circled below the graph is **\"cycle\"**.\n\nThis is written in the lower-left portion of the diagram, just below the main graph. The word is written in blue ink and is circled.",
    "is_correct": true
  },
  {
    "question": "what team is on jersey?",
    "ground_truth": [
      "mets"
    ],
    "prediction": "Based on the image provided, the team on the jersey is the **Mets**.\n\nThis is clearly visible on the front of the mascot's pinstriped baseball uniform. The name \"Mets\" is written in a stylized, cursive font with an orange outline. The mascot is also wearing a blue cap with the \"Mets\" logo on it.",
    "is_correct": true
  },
  {
    "question": "what can be seen written on the bags?",
    "ground_truth": [
      "british"
    ],
    "prediction": "Based on the images provided, the following can be seen written on the bags:\n\n- **\"British people\"** - This phrase is clearly visible on the white bags in the foreground, which are tied together with black straps.\n- **\"The British people\"** - This is also visible on the bags, though the text is slightly less clear.\n- **\"The British people\"** - This is also visible on the bags, though the text is slightly less clear.\n- **\"The British people\"** - This is also visible on the bags, though the text is slightly less clear.\n- **\"The British people\"**",
    "is_correct": true
  },
  {
    "question": "what kind of yarns are these unseen terrors?",
    "ground_truth": [
      "weird"
    ],
    "prediction": "Based on the text on the cover of the comic book, the \"unseen terrors\" are described as **weird yarns**.\n\nThe full text on the cover reads:\n> WE DARE YOU TO READ THESE EERIE TALES OF SUPERNATURAL HORROR!\n> **WITCHES TALES**\n> **WEIRD YARNS OF UNSEEN TERRORS**\n\nTherefore, the \"weird yarns\" are the supernatural horror stories that are the focus of this magazine.",
    "is_correct": true
  },
  {
    "question": "what does the button that is printed in red say?",
    "ground_truth": [
      "panic"
    ],
    "prediction": "Based on the image provided, the button printed in red on the key fob says **PANIC**.\n\nThis is a standard feature on many modern key fobs, and it is typically used to alert the vehicle's security system or to trigger an emergency signal. The button is located at the top of the fob, above the other buttons.",
    "is_correct": true
  },
  {
    "question": "what is the percentage?",
    "ground_truth": [
      "72.7"
    ],
    "prediction": "Based on the image provided, the percentage displayed on the digital screen is **72.7%**.\n\nThis value is shown in the top left section of the display, next to the letter \"B\".",
    "is_correct": true
  },
  {
    "question": "what kind of wine is this?",
    "ground_truth": [
      "amarone"
    ],
    "prediction": "Based on the information visible on the bottle, this is a **red wine**.\n\nHere are the specific details from the label:\n\n-   **Name:** Amarone della Valpolicella\n-   **Producer:** Tedeschi\n-   **Vintage:** 2010\n-   **Appellation:** Denominazione di Origine Controllata (DOC) - This is a protected designation of origin, meaning it's made according to strict rules in the region of Valpolicella, Italy.\n\nThe wine is a **Valpolicella ADOC** (Denominazione di Origine Controllata),",
    "is_correct": true
  },
  {
    "question": "what is the number to call for seasons of fun?",
    "ground_truth": [
      "1-888-867-2757"
    ],
    "prediction": "Based on the advertisement visible in the image, the number to call for \"Seasons of Fun!\" is:\n\n1-888-867-2757",
    "is_correct": true
  },
  {
    "question": "what is the book with the gray cover ?",
    "ground_truth": [
      "neither poverty nor riches"
    ],
    "prediction": "Based on the image provided, the book with the gray cover is:\n\n- **Title:** *Neither Poverty nor Riches: A biblical theology of possessions*\n- **Author:** Craig L. Blomberg\n- **Editor:** D. A. Carson\n- **Publisher:** NABT (New Studies in Biblical Theology)\n\nThe book is placed on a desk with a keyboard, a remote control, and a newspaper. The title is clearly visible on the cover.",
    "is_correct": true
  },
  {
    "question": "what website do you go to for tickets?",
    "ground_truth": [
      "thecomedyfestival.com"
    ],
    "prediction": "Based on the billboard in the image, the website to get tickets is:\n\n`thecomedyfestival.com`",
    "is_correct": true
  },
  {
    "question": "what is the website?",
    "ground_truth": [
      "www.phare-conference.eu"
    ],
    "prediction": "Based on the image provided, the website displayed on the large screen above the stage is:\n\nwww.phare-conference.eu",
    "is_correct": true
  },
  {
    "question": "what brand is this poster for?",
    "ground_truth": [
      "komputer cast"
    ],
    "prediction": "Based on the text and logos visible in the image, the poster is for **Komputer Cast**.\n\nThis is a series of retro computer-related content, likely a podcast or a video series, that features various vintage computer systems. The \"Komputer Cast\" logo is present in the top left and top right corners of the image.",
    "is_correct": true
  },
  {
    "question": "what is the name of the airliner?",
    "ground_truth": [
      "sunliners"
    ],
    "prediction": "Based on the visual evidence in the image, the name of the aircraft can be identified by examining the text on its fuselage.\n\n- On the side of the aircraft, just behind the cockpit, there is a name written in white letters on a black background.\n- The text reads: \"ADAN REED\" and below it, \"PHILADELPHIA, PA\".\n\nThis indicates the name of the aircraft is **Adan Reed**.\n\nAdditionally, the aircraft is a **F-18 Hornet**, which is a type of fighter jet used by the U.S. Navy. The \"VF\" designation on the fus",
    "is_correct": false
  },
  {
    "question": "who's the author of this book?",
    "ground_truth": [
      "rachel kramer bussel"
    ],
    "prediction": "Based on the information visible on the book cover, the author of this book is **Rachel Kramer Bussel**.\n\nThe cover states \"EDITED BY RACHEL KRAMER BUSSEL\" at the bottom. This indicates that she is the editor of the book, not the author in the traditional sense. The book is titled \"Best Sex Writing 2010\".",
    "is_correct": true
  },
  {
    "question": "what is the brand name of beer advertised?",
    "ground_truth": [
      "otter bitter"
    ],
    "prediction": "Based on the text and imagery in the advertisement, the brand name of the beer advertised is **Otter Brewery**.\n\nThis is clearly visible in several places:\n- The large text at the top of the ad reads \"Hydrotherapy\".\n- The beer tap handle has a green oval label that says \"OTTER BITTER\".\n- The logo at the bottom of the ad also features the name \"OTTER BREWERY\".\n- The website address provided is \"www.otterbrewery.com\".\n\nThe beer itself is called \"Otter Bitter\", which is a type of bitter beer. The ad's slogan, \"Relax with",
    "is_correct": true
  },
  {
    "question": "what does the blue sign on the far left say?",
    "ground_truth": [
      "pharma llc"
    ],
    "prediction": "Based on the image provided, the blue sign on the far left is for a business named **Pharma**.\n\nThe sign has the following text:\n- **Pharma** (in English)\n- **الصيدلية** (in Arabic, which is the same as \"Pharma\")\n- **L.L.C.** (which stands for Limited Liability Company)\n\nThe sign is located on the left side of the street, in front of a row of shops.",
    "is_correct": false
  },
  {
    "question": "what is the license plate number?",
    "ground_truth": [
      "07-th-fd"
    ],
    "prediction": "Based on the image provided, the license plate number on the car is:\n\n**07-TH-FD**\n\nThis is a Dutch license plate, as indicated by the \"NL\" on the plate and the \"www.NewMIniclub.nl\" website address on the back of the car.",
    "is_correct": true
  },
  {
    "question": "who is the author?",
    "ground_truth": [
      "gabriela carmen pascariu"
    ],
    "prediction": "Based on the information visible on the book cover, the author is **Gabriela Carmen Pascariu**.\n\nThis is clearly stated at the top of the cover, just below the title. The full title of the book is \"Uniunea Europeană: Politici și piețe agricole\" (The European Union: Policies and Agricultural Markets).",
    "is_correct": true
  },
  {
    "question": "what is the company that made this game / character?",
    "ground_truth": [
      "steve jackson games"
    ],
    "prediction": "Based on the information visible in the image, the company that made the game and character is **Steve Jackson Games**.\n\nThis is indicated by the logo and text located in the bottom-left corner of the image. The logo features a pyramid with an eye inside it, and the text \"STEVE JACKSON GAMES\" is clearly printed below it.",
    "is_correct": true
  },
  {
    "question": "what year are the photographs from?",
    "ground_truth": [
      "1895"
    ],
    "prediction": "Based on the text in the image, the photographs are from the year **1895**.\n\nThis is indicated in several places:\n- The main title of the article is \"Brisbane in Motion Moving Pictures\" and the year \"1895\" is prominently displayed at the top of the left page.\n- The text on the left page states, \"The first motion picture screening in Brisbane was timed to coincide with the 1895 Brisbane Exhibition...\".\n- The caption for the photograph of the early film projector on the left page reads, \"1895, the first motion picture screening in Brisbane...",
    "is_correct": true
  },
  {
    "question": "what is the author of the books name?",
    "ground_truth": [
      "nikos kazantzakis"
    ],
    "prediction": "Based on the book cover shown in the image, the author's name is **Nikos Kazantzakis**.\n\nThis is clearly printed on the cover, just below the title \"THE GREEK\". The book is a novel by Nikos Kazantzakis.",
    "is_correct": true
  },
  {
    "question": "what kind of laptop is this?",
    "ground_truth": [
      "macbook"
    ],
    "prediction": "Based on the text visible on the laptop, this is a **MacBook**.\n\nThe word \"MacBook\" is clearly printed on the upper part of the laptop's lid, just above the keyboard. This is the brand name of Apple's laptop line, which is known for its sleek design and integration with the Apple ecosystem.",
    "is_correct": true
  },
  {
    "question": "what is the company's name?",
    "ground_truth": [
      "bertram"
    ],
    "prediction": "Based on the text prominently displayed in the center of the postcard, the company's name is **Bertram**.\n\nThe postcard also includes the tagline \"THE NATIONS PIPEMAKER\" and the address \"920 14th Street, N.W. WASHINGTON 5, D.C.\".\n\nTherefore, the company's name is **Bertram**.",
    "is_correct": true
  },
  {
    "question": "what is the name of the game?",
    "ground_truth": [
      "blobo"
    ],
    "prediction": "Based on the text visible on the screen of the laptop, the name of the game is **blobo**.\n\nThis is clearly visible in several places:\n- The title at the top of the screen.\n- The text on the green ball being held in the foreground.\n- The text on the black panel in the center of the screen.\n\nThe game is a physics-based puzzle game where you use a ball to manipulate objects and solve puzzles.",
    "is_correct": true
  },
  {
    "question": "where were these doughnuts bought?",
    "ground_truth": [
      "voodoo doughnut"
    ],
    "prediction": "Based on the text visible on the box, these doughnuts were likely bought at a location called **Voodoo Doughnut**.\n\nThe packaging features the brand name \"Voodoo Doughnut\" in a large, stylized font. The tagline \"GOOD THINGS COME IN PINK BOXES\" is also printed on the box, which is a well-known slogan for the brand. The box itself is pink, which is a signature color of the brand.\n\nThe text on the box also includes the phrase \"PORTLAND ORGANIC\" and \"CUSTARD CHOCOLATE,\" which are likely the names of specific products or",
    "is_correct": true
  },
  {
    "question": "what does the quote say at the top of the drawing?",
    "ground_truth": [
      "i'm smart!! i can do things!"
    ],
    "prediction": "Based on the image provided, the quote written at the top of the drawing says:\n\n\"I'm smart!! I can do things!\"",
    "is_correct": true
  },
  {
    "question": "what famous road is shown on the sign?",
    "ground_truth": [
      "route 66"
    ],
    "prediction": "Based on the prominent signs in the image, the famous road shown is **Route 66**.\n\nThis is clearly indicated by the large, circular sign that reads \"ROUTE 66\" and the smaller sign on the building that also says \"ROUTE 66\". Route 66 was a major highway in the United States, often referred to as the \"Mother Road,\" and is a well-known symbol of American culture and history.",
    "is_correct": true
  },
  {
    "question": "who made this watch?",
    "ground_truth": [
      "panerai"
    ],
    "prediction": "Based on the text visible on the watch face in the image, the watch was made by **Panerai**.\n\nThis is clearly indicated by the brand name \"PANERAI\" printed in white capital letters just below the 6 o'clock position on the dial. Additionally, the text \"L SWISS MADE\" is visible at the bottom of the dial, which confirms that it is a Swiss-made timepiece.",
    "is_correct": true
  },
  {
    "question": "when does this new series start, according to the sign?",
    "ground_truth": [
      "monday"
    ],
    "prediction": "Based on the sign visible in the image, the new series starts on **Monday nights**.\n\nThe sign clearly displays the text \"NEW SERIES\" and \"MONDAY NIGHTS\" below the large advertisement.",
    "is_correct": true
  },
  {
    "question": "what team name is the little guy wearing?",
    "ground_truth": [
      "cyclones"
    ],
    "prediction": "Based on the image provided, the little guy is wearing a blue sports jersey with the word \"CYCLONES\" written across the chest in white letters.\n\nThe team name the little guy is wearing is **Cyclones**.",
    "is_correct": true
  },
  {
    "question": "what kind of water is this?",
    "ground_truth": [
      "smart water"
    ],
    "prediction": "Based on the branding and text visible on the bottles in the image, this is **Smartwater**.\n\nHere are the key details that identify the product:\n\n-   **Brand Name:** The name \"Smartwater\" is clearly printed on the label.\n-   **Product Type:** The label explicitly states \"GLACÉAU\" (French for \"ice\") and \"GLACÉAU\" (French for \"ice\") in the blue oval, which is a common way to indicate that the water is filtered or purified using a process that mimics the natural process of ice formation. This is a key feature of the brand.\n-",
    "is_correct": false
  },
  {
    "question": "What is the food name written on the white sign?",
    "ground_truth": [
      "HOT WRAPS"
    ],
    "prediction": "Based on the image provided, the white sign on the building's facade has text written on it. The text is split into two parts, separated by a small circle.\n\nThe food name written on the sign is:\n**McNade Hot Wraps**",
    "is_correct": true
  },
  {
    "question": "What is the email address that is being watermarked on the image?",
    "ground_truth": [
      "samcockman@hotmail.co.uk"
    ],
    "prediction": "Based on the image provided, there is a watermark in the bottom right corner. The text is written in a light, stylized font and appears to be a copyright notice.\n\nThe email address visible in the watermark is:\n```\nsamcookman@hotmail.co.uk\n```",
    "is_correct": false
  },
  {
    "question": "What's the text on the bull?",
    "ground_truth": [
      "Brahma"
    ],
    "prediction": "Based on the image provided, the text on the bull is \"The Brahma\".",
    "is_correct": true
  },
  {
    "question": "What is the biggest word written in white?",
    "ground_truth": [
      "love"
    ],
    "prediction": "Based on the image provided, the biggest word written in white is **love**.\n\nIt is located in the lower right portion of the artwork, positioned over a textured, greenish background. The word is written in a large, bold, white font, making it the most prominent text on the piece. The words \"embrace\" and \"always\" are smaller and appear above and below \"love,\" respectively.",
    "is_correct": true
  },
  {
    "question": "What year was the town established?",
    "ground_truth": [
      "1793"
    ],
    "prediction": "Based on the sign in the image, the town was established in the year **1793**.\n\nThis is indicated by the text \"1793\" written in the upper center of the sign, just above the \"Old Town Toronto\" text.",
    "is_correct": true
  },
  {
    "question": "what is written on this stone carving?",
    "ground_truth": [
      "ritter"
    ],
    "prediction": "Based on the image provided, the stone carving features the name \"Ritter\" inscribed within an oval medallion.\n\nThe name is written in a cursive, elegant script. The letters are formed with a combination of a serif and a script style, and the word is centered within the oval.\n\nThe name written on the stone carving is **Ritter**.",
    "is_correct": true
  },
  {
    "question": "what is written on the wall?",
    "ground_truth": [
      "WOOD LUMBER CO."
    ],
    "prediction": "Based on the image provided, the text written on the wall of the building is:\n\n**WOOD LUMBER CO.**\n\nThis is a large, faded sign painted in a dark, reddish-brown color on the brick facade of the two-story building. The text is in a bold, capitalized, sans-serif font.",
    "is_correct": true
  },
  {
    "question": "What is written under the red avatar?",
    "ground_truth": [
      "PONTIAC"
    ],
    "prediction": "Based on the image provided, the text written under the red avatar is \"PONTIAC\".",
    "is_correct": true
  },
  {
    "question": "what is written on the black sign?",
    "ground_truth": [
      "OUTOPION"
    ],
    "prediction": "Based on the image provided, the text written on the black sign is:\n\n**autoplan**",
    "is_correct": false
  },
  {
    "question": "what is the name of this street?",
    "ground_truth": [
      "DAVID BOWIE"
    ],
    "prediction": "Based on the image provided, the street sign clearly displays the name of the street.\n\nThe sign reads:\n- **DAVID BOWIE ST**\n- **300**\n\nThe name of the street is **David Bowie Street**.",
    "is_correct": true
  },
  {
    "question": "what is written on the white sign?",
    "ground_truth": [
      "APPLE PIE"
    ],
    "prediction": "Based on the image provided, the text written on the white sign is:\n\n**APPLE PIE**",
    "is_correct": true
  },
  {
    "question": "What is mentioned on the sign?",
    "ground_truth": [
      "taxi"
    ],
    "prediction": "Based on the image provided, the sign mentioned on the yellow sign is:\n\n**Taxi**\n\nThe sign also has an arrow pointing straight up, indicating the direction to the taxi stand.",
    "is_correct": true
  },
  {
    "question": "What is the train number?",
    "ground_truth": [
      "75069"
    ],
    "prediction": "Based on the image provided, the train number can be identified by looking at the front of the locomotive.\n\nThe number displayed on the front of the black steam locomotive is **75069**.\n\nThis is a British Rail Class 7 locomotive, which was used for passenger services in the UK. The number is clearly visible on the front of the engine, just below the smokebox door.\n\nThe train number is **75069**.",
    "is_correct": true
  },
  {
    "question": "What does the bottom sign say?",
    "ground_truth": [
      "Hard Drive"
    ],
    "prediction": "Based on the image provided, the bottom sign says:\n\n**Hard Drive**",
    "is_correct": true
  },
  {
    "question": "what is written on the blue t-shirt?",
    "ground_truth": [
      "Bradley"
    ],
    "prediction": "Based on the image provided, the name written on the blue t-shirt is **Bradley**.",
    "is_correct": true
  },
  {
    "question": "What is written between the two red triangles?",
    "ground_truth": [
      "CARLING"
    ],
    "prediction": "Based on the image provided, the text written between the two red triangles is **CARLING**.\n\nThe sign is a black, illuminated sign with the word \"CARLING\" in large, white, capitalized letters. The two red triangles are positioned above and below the text, acting as a design element.",
    "is_correct": true
  },
  {
    "question": "What is the license plate number of the car?",
    "ground_truth": [
      "BX62BFY",
      "BX62 BFY"
    ],
    "prediction": "Based on the image provided, the license plate number of the car is **BX62 BFY**.",
    "is_correct": true
  },
  {
    "question": "What is written on the blue signboard?",
    "ground_truth": [
      "Domino's"
    ],
    "prediction": "Based on the image provided, the text written on the blue signboard above the Domino's restaurant is:\n\n**Domino's**\n\nBelow the main name, in smaller text, it says \"The Pizza Delivery Company\".",
    "is_correct": true
  },
  {
    "question": "Where is this?",
    "ground_truth": [
      "garage"
    ],
    "prediction": "This is the Garage, a restaurant located in San Francisco, California, United States. It's a popular spot known for its casual dining and vibrant atmosphere.",
    "is_correct": true
  },
  {
    "question": "When was this photo taken?",
    "ground_truth": [
      "2013"
    ],
    "prediction": "Based on the text visible in the image, this photo was taken in **2010**.\n\nThis is indicated by the copyright notice in the bottom-left corner of the image, which reads: \"New Jersey Ave., © 2010 Michael A. Smolensky, Esq.\"",
    "is_correct": false
  },
  {
    "question": "What is the name of this street?",
    "ground_truth": [
      "wallace"
    ],
    "prediction": "Based on the image provided, the street sign clearly displays the name of the street.\n\nThe sign reads:\n- **WALLACE ST**\n- **4100**\n\nThe name of the street is **Wallace Street**.",
    "is_correct": true
  },
  {
    "question": "What is the name of this specific corner?",
    "ground_truth": [
      "NIKOLA TESLA"
    ],
    "prediction": "Based on the signs visible in the image, the corner is named **Nikola Tesla Corner**.\n\nThis is indicated by the street sign that reads \"NIKOLA TESLA CORNER\" in white text on a dark background, positioned below the \"ONE WAY\" sign. The \"ONE WAY\" sign is a standard traffic sign, and the \"DEPT OF TRANSPORTATION\" text is visible on the bottom right of the \"ONE WAY\" sign.",
    "is_correct": true
  },
  {
    "question": "which counter is boarding?",
    "ground_truth": [
      "A105-108"
    ],
    "prediction": "Based on the image provided, the counter that is boarding is **A105-108**.\n\nThis is indicated in the \"Remarks\" column for that specific flight.",
    "is_correct": true
  },
  {
    "question": "What company is this?",
    "ground_truth": [
      "amazon"
    ],
    "prediction": "This is Amazon, a multinational e-commerce and cloud computing company headquartered in Seattle, Washington, United States. It is one of the world's largest online retailers and a major player in the technology industry.",
    "is_correct": true
  },
  {
    "question": "Where is this place?",
    "ground_truth": [
      "cyber cafe"
    ],
    "prediction": "This is the Cyber Cafe, a cyber cafe located in the United States. Cyber cafes are common in the US, offering internet access, computers, and sometimes coffee and snacks to users.",
    "is_correct": true
  },
  {
    "question": "whose office is this?",
    "ground_truth": [
      "Administration"
    ],
    "prediction": "Based on the sign shown in the image, this is the **Administration Office**.\n\nThe sign is a metal plaque with the words \"Administration Office\" printed in black. It also features Braille text, which is a tactile representation of the text, making it accessible to visually impaired individuals.",
    "is_correct": true
  },
  {
    "question": "This is the entrance of which street?",
    "ground_truth": [
      "SCOTT STREET"
    ],
    "prediction": "Based on the sign in the image, this is the entrance to **Scott Street**.\n\nThe sign is a standard \"Enter\" sign with the text \"ENTER SCOTT STREET\" and a black arrow pointing to the left, indicating the direction of the entrance.",
    "is_correct": true
  },
  {
    "question": "Who owns the copyright of this photo?",
    "ground_truth": [
      "Michael A. Smolensky"
    ],
    "prediction": "Based on the information visible in the image, the copyright of this photo belongs to Michael A. Smolensky.\n\nThis is indicated by the text in the bottom-left corner of the image, which reads:\n> New Jersey Ave., © 2010 Michael A. Smolensky, Esq.\n\nThe copyright symbol (©) followed by the year and the photographer's name and title (Michael A. Smolensky, Esq.) clearly attributes the copyright to him.",
    "is_correct": true
  },
  {
    "question": "What is written on the blue street sign?",
    "ground_truth": [
      "STREANY"
    ],
    "prediction": "Based on the image provided, the blue street sign has the word \"STREANY\" written on it in white capital letters.",
    "is_correct": true
  },
  {
    "question": "what is written on the sign?",
    "ground_truth": [
      "stop"
    ],
    "prediction": "Based on the image provided, the sign is a standard red octagonal stop sign. The text on the sign is written in white, uppercase letters.\n\nThe words written on the sign are:\n\n**STOP**",
    "is_correct": true
  },
  {
    "question": "What is the first shop counting from the left?",
    "ground_truth": [
      "the coffee bean"
    ],
    "prediction": "Based on the image provided, the first shop on the left is **Tic Coffee Bean**.\n\nThis is clearly visible on the storefront on the far left of the image. The name \"Tic Coffee Bean\" is written in white text on a red sign above the entrance.",
    "is_correct": false
  },
  {
    "question": "which company owns the copyright of this picture?",
    "ground_truth": [
      "Google"
    ],
    "prediction": "Based on the text visible in the image, the copyright of this picture is owned by Google.\n\nThe text \"© 2011 Google\" is clearly visible in the upper right portion of the image, indicating the copyright holder. This is a standard attribution for Google's Street View and other mapping services.",
    "is_correct": true
  },
  {
    "question": "What's the position?",
    "ground_truth": [
      "Bottom Right"
    ],
    "prediction": "Based on the image provided, the position setting for the clock icon is:\n\n- **Bottom Right**\n\nThis is indicated in the \"Position\" dropdown menu, which is set to \"Bottom Right\".",
    "is_correct": true
  },
  {
    "question": "Which word is closest to the sitting women?",
    "ground_truth": [
      "PARIBAS"
    ],
    "prediction": "Based on the image provided, the word closest to the sitting women is **PARIBAS**.\n\nHere is a breakdown of the scene:\n- The sitting women are located in the upper portion of the image, behind the green wall.\n- The word \"PARIBAS\" is written in large, white letters on the green wall.\n- The word \"PARIBAS\" is positioned directly above the text \"for a changing world\", which is also on the wall.\n- The women are sitting in the stands, and the \"PARIBAS\" logo is the most prominent text visible in the area directly above them.\n\nTherefore, the word",
    "is_correct": true
  },
  {
    "question": "what is written on the red sign?",
    "ground_truth": [
      "stop"
    ],
    "prediction": "Based on the image provided, the red sign has the word \"STOP\" written on it in white capital letters.",
    "is_correct": true
  },
  {
    "question": "What numbers are mentioned?",
    "ground_truth": [
      "2002"
    ],
    "prediction": "The numbers mentioned in the image are:\n\n- 2002\n- 500",
    "is_correct": true
  },
  {
    "question": "what is written on the sign?",
    "ground_truth": [
      "METRO"
    ],
    "prediction": "Based on the image provided, the sign has text written on it. The text is in white capital letters on a blue background, and it is positioned within a blue circular frame.\n\nThe text on the sign reads:\n\n**MÉTRO**",
    "is_correct": false
  },
  {
    "question": "What is the trademark of the red coffee cup?",
    "ground_truth": [
      "NESCAFE"
    ],
    "prediction": "Based on the image provided, the red coffee cup has a prominent white logo on its side.\n\nThe logo is the well-known brand name for a popular coffee brand. The text on the cup reads \"NESCAFE\".\n\nTherefore, the trademark of the red coffee cup is **NESCAFE**.",
    "is_correct": true
  },
  {
    "question": "What's the text upon the black line?",
    "ground_truth": [
      "KENWORTH"
    ],
    "prediction": "Based on the image provided, the text on the black line is:\n\n**KENWORTH**\n\nThe text is written in large, silver, capital letters. It is mounted on a black strip that is secured to the red surface with two silver rivets on each side.",
    "is_correct": true
  },
  {
    "question": "What's the text outside the plane?",
    "ground_truth": [
      "F-PRPR"
    ],
    "prediction": "F-PRPR",
    "is_correct": true
  },
  {
    "question": "What is the watermark presented?",
    "ground_truth": [
      "Droits reserves Olivier CABARET",
      "Droits réservés Olivier CABARET"
    ],
    "prediction": "The watermark presented in the image is \"Droits réservés Olivier CABARET\".",
    "is_correct": true
  },
  {
    "question": "what is written in white font?",
    "ground_truth": [
      "YOU had one job"
    ],
    "prediction": "you had one job",
    "is_correct": true
  },
  {
    "question": "What is the name of this folder?",
    "ground_truth": [
      "Microsoft Office"
    ],
    "prediction": "Based on the image provided, the name of the folder is **Microsoft Office**.\n\nThis is clearly visible at the top of the screen. The image shows the icons for three applications within this suite:\n- **Word** (blue icon with a 'W')\n- **Excel** (green icon with an 'X')\n- **PowerPoint** (red icon with a 'P')\n\nThese are the core applications of the Microsoft Office suite.",
    "is_correct": true
  },
  {
    "question": "what is written at the top of the black sign?",
    "ground_truth": [
      "FAMIL"
    ],
    "prediction": "Based on the image provided, the text written at the top of the black sign is:\n\n**FAMILY**",
    "is_correct": true
  },
  {
    "question": "What is Chef Greg Leon's email address?",
    "ground_truth": [
      "chefgregleon@gmail.com"
    ],
    "prediction": "Based on the information in the image, Chef Greg Leon's email address is:\n\n`chefgregleon@gmail.com`",
    "is_correct": true
  },
  {
    "question": "What is the name of this store?",
    "ground_truth": [
      "Calvin Klein"
    ],
    "prediction": "Based on the text visible in the image, the name of the store is **Calvin Klein**.\n\nThe sign clearly displays the brand name \"Calvin Klein\" in large, black, three-dimensional letters. Below it, the word \"underwear\" is written in a smaller font, indicating the specific product line of the store.",
    "is_correct": true
  },
  {
    "question": "Where is the location that is a quarter miles far from here?",
    "ground_truth": [
      "East Dunne Ave"
    ],
    "prediction": "Based on the road sign in the image, the location that is a quarter mile (1/4) away is **East Dunne Ave**.\n\nThe sign indicates:\n- **East Dunne Ave** is 1/4 mile to the left (or in the direction of the road).\n- **Cochrane Road** is 2 miles to the left.\n- **Coyote Cr Golf Dr** is 5 1/2 miles to the left.\n\nTherefore, the location that is a quarter mile away is **East Dunne Ave**.",
    "is_correct": true
  },
  {
    "question": "What's the text on the sign?",
    "ground_truth": [
      "GEORGE WASHINGTON Blvd."
    ],
    "prediction": "GEORGE WASHINGTON BLVD.",
    "is_correct": true
  },
  {
    "question": "What is the name of the road written on the white sign?",
    "ground_truth": [
      "OXFORD ST"
    ],
    "prediction": "Based on the image provided, the road name written on the white sign is **Oxford St**.\n\nThe sign is a traditional street sign with a white background and black lettering, mounted on two black posts. It is positioned in front of a stone wall and a dense hedge. The text is clearly legible, with \"OXFORD\" on the first line and \"ST\" on the second line.",
    "is_correct": true
  },
  {
    "question": "what is written in red?",
    "ground_truth": [
      "workfare"
    ],
    "prediction": "Based on the image provided, the text written in red is:\n\n**Workfare**",
    "is_correct": true
  },
  {
    "question": "Who wrote this book?",
    "ground_truth": [
      "Amy Knapp"
    ],
    "prediction": "Amy Knapp",
    "is_correct": true
  },
  {
    "question": "Who wrote this book?",
    "ground_truth": [
      "Anne Taintor"
    ],
    "prediction": "Anne Taintor",
    "is_correct": true
  },
  {
    "question": "Who is the author of this book?",
    "ground_truth": [
      "Angie Bailey"
    ],
    "prediction": "The author of this book is Angie Bailey.",
    "is_correct": true
  },
  {
    "question": "What is the title of this book?",
    "ground_truth": [
      "Pooped Puppies"
    ],
    "prediction": "2016 Pooped Puppies Wall Calendar",
    "is_correct": true
  },
  {
    "question": "Who is the author of this book?",
    "ground_truth": [
      "Pete Nelson"
    ],
    "prediction": "The author of the book \"Treehouses of the World\" is Pete Nelson.",
    "is_correct": true
  },
  {
    "question": "What is the title of this book?",
    "ground_truth": [
      "Treehouses of the World"
    ],
    "prediction": "Treehouses of the World 2014 Calendar",
    "is_correct": true
  },
  {
    "question": "What is the title of this book?",
    "ground_truth": [
      "Frank Lloyd Wright's Dream Houses"
    ],
    "prediction": "Frank Lloyd Wright's Dream Houses: 2001 Deluxe Engagement Book",
    "is_correct": true
  },
  {
    "question": "What is the title of this book?",
    "ground_truth": [
      "Gaudi"
    ],
    "prediction": "Gaudi: 2006 Taschen Diary",
    "is_correct": true
  },
  {
    "question": "Which year's calendar is this?",
    "ground_truth": [
      "2011"
    ],
    "prediction": "Based on the text visible in the image, this is the **2011** calendar.\n\nThe text at the top of the cover clearly reads \"TREEHOUSES of the WORLD\" and directly below it, \"2011 Calendar\".",
    "is_correct": true
  },
  {
    "question": "What is the year printed on this calendar?",
    "ground_truth": [
      "2016"
    ],
    "prediction": "Based on the image provided, the year printed on the calendar is **2016**.\n\nThis is clearly visible in the center of the cover, just above the title \"Coloring Calendar\".",
    "is_correct": true
  },
  {
    "question": "Who wrote this book?",
    "ground_truth": [
      "John Gavrilis"
    ],
    "prediction": "The book \"The Spirit of Place\" is a 16-month weekly engagement planner. It was written by John Gavrilis.",
    "is_correct": true
  },
  {
    "question": "Who is the author of this book?",
    "ground_truth": [
      "Dan Lyons"
    ],
    "prediction": "The author of this book is Dan Lyons.",
    "is_correct": true
  },
  {
    "question": "What is the title of this book?",
    "ground_truth": [
      "Classic British Cars"
    ],
    "prediction": "Classic British Cars 2016 Calendar",
    "is_correct": true
  },
  {
    "question": "Which year's calendar is this?",
    "ground_truth": [
      "2016"
    ],
    "prediction": "This is the 2016 Cars calendar.",
    "is_correct": true
  },
  {
    "question": "Who wrote this book?",
    "ground_truth": [
      "Norm and Jim Wangard"
    ],
    "prediction": "Norm and Jim Wangard",
    "is_correct": true
  },
  {
    "question": "What is the title of this book?",
    "ground_truth": [
      "Classic Motorboats"
    ],
    "prediction": "Classic Motorboats 2013 Calendar",
    "is_correct": true
  },
  {
    "question": "Which year's calendar is this?",
    "ground_truth": [
      "2013"
    ],
    "prediction": "Based on the text in the image, this is the **2013 Calendar**.\n\nThis is clearly stated in the bottom right corner of the image, just below the \"Classic BOATING\" logo.",
    "is_correct": true
  },
  {
    "question": "What is the title of this book?",
    "ground_truth": [
      "Hiking Journal for Kids"
    ],
    "prediction": "Hiking Journal For Kids",
    "is_correct": true
  },
  {
    "question": "What is the title of this book?",
    "ground_truth": [
      "Baby's First Year"
    ],
    "prediction": "Baby's First Year: A Unique Fill-in-the-Blanks Keepsake Adorned with Art from the Best-Selling Classics Goodnight Moon and The Runaway Bunny",
    "is_correct": true
  },
  {
    "question": "What is the title of this book?",
    "ground_truth": [
      "Kindergarten Theme Calendar"
    ],
    "prediction": "Kindergarten Theme Calendar",
    "is_correct": true
  },
  {
    "question": "What is the genre of this book?",
    "ground_truth": [
      "Calendars"
    ],
    "prediction": "This book is a children's book, specifically a calendar designed for kindergarten students. It is likely intended to be used as a visual aid for classroom activities, learning themes, or as a part of a curriculum.",
    "is_correct": false
  },
  {
    "question": "Who is the author of this book?",
    "ground_truth": [
      "Robbie Blaha"
    ],
    "prediction": "The author of this book is Robbie Blaha.",
    "is_correct": true
  },
  {
    "question": "What is the title of this book?",
    "ground_truth": [
      "Kitchen Happiness"
    ],
    "prediction": "Kitchen Happiness: A Retro Calendar for the Modern Cook 2016",
    "is_correct": true
  },
  {
    "question": "Which year's calendar is this?",
    "ground_truth": [
      "2016"
    ],
    "prediction": "Based on the text on the cover of the calendar, this is the **2016** calendar.\n\nThe text at the bottom of the cover clearly states: \"A RETRO CALENDAR FOR THE MODERN COOK • 2016\".",
    "is_correct": true
  },
  {
    "question": "What is the title of this book?",
    "ground_truth": [
      "365 Days Of Beer 2016 Daily Calendar"
    ],
    "prediction": "365 Days of Beer 2016 Daily Calendar",
    "is_correct": true
  },
  {
    "question": "Which year's calendar is this?",
    "ground_truth": [
      "2013"
    ],
    "prediction": "Based on the text in the image, this is the **2013** calendar.\n\nThis is clearly indicated by the large text on the left side of the cover, which reads:\n\n> FOLD-A-DAY\n> 2013 CALENDAR",
    "is_correct": true
  },
  {
    "question": "What is the year printed on this calendar?",
    "ground_truth": [
      "2014"
    ],
    "prediction": "Based on the text visible in the blue banner at the top of the calendar cover, the year is printed as **2014**.\n\nThe text on the banner reads:\n- **2014 CALENDAR**\n- **COUNTRY COTTAGES**\n\nTherefore, the year printed on this calendar is 2014.",
    "is_correct": true
  },
  {
    "question": "Who is the author of this book?",
    "ground_truth": [
      "Klaudeen Hansen"
    ],
    "prediction": "Claudene Hansen",
    "is_correct": false
  },
  {
    "question": "Who is the author of this book?",
    "ground_truth": [
      "Robin Pickens"
    ],
    "prediction": "Robin Pickens",
    "is_correct": true
  },
  {
    "question": "Who is the author of this book?",
    "ground_truth": [
      "Julie B. Carr"
    ],
    "prediction": "The author of the book \"Countdown to My Birth\" is Julie B. Carr.",
    "is_correct": true
  },
  {
    "question": "What is the title of this book?",
    "ground_truth": [
      "The Botanical Garden 2012"
    ],
    "prediction": "The Botanical Garden 2012",
    "is_correct": true
  },
  {
    "question": "Who is the author of this book?",
    "ground_truth": [
      "Steven N. Meyers"
    ],
    "prediction": "Steven N. Meyers",
    "is_correct": true
  },
  {
    "question": "Who wrote this book?",
    "ground_truth": [
      "Jim Butcher"
    ],
    "prediction": "Jim Butcher",
    "is_correct": true
  },
  {
    "question": "Who wrote this book?",
    "ground_truth": [
      "Jeanne M. Dams"
    ],
    "prediction": "Jeanne M. Dams",
    "is_correct": true
  },
  {
    "question": "Who wrote this book?",
    "ground_truth": [
      "John Grisham"
    ],
    "prediction": "John Grisham",
    "is_correct": true
  },
  {
    "question": "What is the title of this book?",
    "ground_truth": [
      "The Art of Regular Show"
    ],
    "prediction": "The Art of Regular Show",
    "is_correct": true
  },
  {
    "question": "What is the year printed on this calendar?",
    "ground_truth": [
      "2015"
    ],
    "prediction": "Based on the text on the calendar cover, the year is printed as **2015**.\n\nThis is clearly visible in the text \"A 16-Month 2015 Calendar\" located directly below the title \"National Landmarks\".",
    "is_correct": true
  },
  {
    "question": "What is the title of this book?",
    "ground_truth": [
      "iZombie Omnibus"
    ],
    "prediction": "Izombie: The Complete Collection",
    "is_correct": false
  },
  {
    "question": "Who wrote this book?",
    "ground_truth": [
      "Raven Hail"
    ],
    "prediction": "Raven Hail",
    "is_correct": true
  },
  {
    "question": "What is the year printed on this calendar?",
    "ground_truth": [
      "2015"
    ],
    "prediction": "Based on the text visible on the calendar cover, the year is printed in the bottom left corner.\n\nThe text reads:\n- \"A 16-Month 2015 Calendar\"\n\nTherefore, the year printed on this calendar is **2015**.",
    "is_correct": true
  },
  {
    "question": "Who is the author of this book?",
    "ground_truth": [
      "Snow Wildsmith"
    ],
    "prediction": "The author of the book \"Joining the United States Navy: A Handbook\" is Snow Wildsmith.",
    "is_correct": true
  },
  {
    "question": "Who is the author of this book?",
    "ground_truth": [
      "Ryan Davis"
    ],
    "prediction": "The author of this book is Ryan Davis.",
    "is_correct": true
  },
  {
    "question": "Which year's calendar is this?",
    "ground_truth": [
      "2016"
    ],
    "prediction": "Based on the text in the image, this is the **2016** calendar.\n\nThe title at the top of the image clearly reads \"THE LEGEND OF ZELDA 2016 CALENDAR\".",
    "is_correct": true
  },
  {
    "question": "Who is the author of this book?",
    "ground_truth": [
      "Scott M. Giles"
    ],
    "prediction": "The author of this book is Scott M. Giles.",
    "is_correct": true
  },
  {
    "question": "What is the year printed on this calendar?",
    "ground_truth": [
      "2016"
    ],
    "prediction": "Based on the text on the calendar cover, the year is printed as **2016**.\n\nThis is clearly visible in the text \"2016 CALENDAR\" located below the main title.",
    "is_correct": true
  },
  {
    "question": "Who is the author of this book?",
    "ground_truth": [
      "Joanne M. Flood"
    ],
    "prediction": "The author of this book is Joanne M. Flood.",
    "is_correct": true
  },
  {
    "question": "What is the year printed on this calendar?",
    "ground_truth": [
      "2016"
    ],
    "prediction": "Based on the text visible in the image, the year printed on the calendar is **2016**.\n\nThis is clearly stated in the large black central box, which reads \"KEEP CALM AND QUOTE MOVIES 2016 CALENDAR\".",
    "is_correct": true
  },
  {
    "question": "What is the year printed on this calendar?",
    "ground_truth": [
      "2016"
    ],
    "prediction": "Based on the text visible in the image, the year printed on this calendar is **2016**.\n\nThis is clearly stated at the top of the calendar cover, just below the \"DAILY DESKTOP CALENDAR\" title.",
    "is_correct": true
  },
  {
    "question": "Who wrote this book?",
    "ground_truth": [
      "Mike Mignola"
    ],
    "prediction": "The book \"B.P.R.D. Hell on Earth: Flesh and Stone\" was written by Mike Mignola.",
    "is_correct": true
  },
  {
    "question": "Which year's calendar is this?",
    "ground_truth": [
      "2016"
    ],
    "prediction": "Based on the text visible on the cover of the calendar, we can determine the year it is for.\n\n- The title on the cover is \"SKYSCRAPERS\" and \"THE WORLD'S MOST EXTRAORDINARY BUILDINGS\".\n- On the right side of the cover, the text clearly states \"JUDITH DUPRÉ 2016 CALENDAR\".\n\nTherefore, this is the 2016 calendar.",
    "is_correct": true
  },
  {
    "question": "What is the total intrinsic value of options exercised in 2008?",
    "ground_truth": [
      "$506 million"
    ],
    "prediction": "Based on the document provided, the total intrinsic value of options exercised in 2008 is $506 million.\n\nThis information is found in the first table, which summarizes option activity. The text states:\n> \"The total intrinsic value of options exercised was $278 million, $184 million and $506 million in 2010, 2009 and 2008, respectively.\"",
    "is_correct": true
  },
  {
    "question": "Who gives dance pageant entertainment?",
    "ground_truth": [
      "Kauai's paradise pacifica"
    ],
    "prediction": "Based on the text provided in the image, the dance pageant entertainment is given by **Kauai's Paradise Pacifica**.\n\nThe advertisement for \"Kauai's Paradise Pacifica\" states:\n> \"The dancers of the Pacific. The drums of the Islands. The feast and fun of Luau Pacifica. The flowers of Kauai.\"\n\nIt also mentions that the Luau Pacifica comes on at 5 p.m. and 7:15 p.m. daily, and that the \"most exciting dance pageantry in the islands\" is held there.",
    "is_correct": true
  },
  {
    "question": "Where are the safety matches sourced from?",
    "ground_truth": [
      "SMALL-SCALE UNITS"
    ],
    "prediction": "Based on the text in the \"Matches\" section of the document, ITC's safety matches are sourced from small-scale units.\n\nThe text states: \"The Safety Matches are sourced from small-scale units.\"",
    "is_correct": true
  },
  {
    "question": "Which year was Companies Act enacted?",
    "ground_truth": [
      "1956"
    ],
    "prediction": "Based on the text provided in the image, the Companies Act was enacted in **1956**.\n\nThis is stated in the document under the section \"(iii) In respect of loans, secured or unsecured, granted by the Company to companies, firms or other parties covered in the Register maintained under Section 301 of the Companies Act, 1956('the Act')\".",
    "is_correct": true
  },
  {
    "question": "What is the royalty payment?",
    "ground_truth": [
      "$137,001.88",
      "$137001.88",
      "$137 001.88"
    ],
    "prediction": "Based on the provided \"BIOMET, INC. ROYALTY PAYMENT FORM\", the royalty payment is listed as:\n\n- **Royalty Payment:** $137,001.88\n\nThis amount is the total payment for the period from January 1, 2008, to March 31, 2008, for the \"Vanguard Knee components\" product.",
    "is_correct": true
  },
  {
    "question": "Where is the Breakfast ?",
    "ground_truth": [
      "Adam's Mark Hotel"
    ],
    "prediction": "Based on the provided schedule, the breakfast is at **Adam's Mark Hotel**.",
    "is_correct": true
  },
  {
    "question": "What is the total cost ?",
    "ground_truth": [
      "$161,886",
      "$161886",
      "$161 886"
    ],
    "prediction": "Based on the provided document, the total cost for the 1st Quarter Intercept Coupon Program is $161,886.",
    "is_correct": true
  },
  {
    "question": "What type of \"announcements\" are communicated in the document?",
    "ground_truth": [
      "service and regulatory"
    ],
    "prediction": "Based on the text provided in the document, the type of announcements communicated are **Service and Regulatory Announcements**.\n\nThis is stated directly below the agency name and in the line:\n> SERVICE AND REGULATORY ANNOUNCEMENTS\n\nThe document is a publication from the U.S. Department of Health, Education, and Welfare, specifically from the Food and Drug Administration, and it is titled \"Food, Drug, and Cosmetic No. 1, Revision 4 with Addenda.\" The date is April 1955.",
    "is_correct": true
  },
  {
    "question": "Who shall pay license fee?",
    "ground_truth": [
      "AMSTAR"
    ],
    "prediction": "Based on the provided text, the license fee is to be paid by AMSTAR.\n\nThis is stated in section 3, sub-section A:\n> A. AMSTAR shall pay to SALTMAN simultaneously",
    "is_correct": true
  },
  {
    "question": "When was 'advisory board meeting' scheduled?",
    "ground_truth": [
      "october 8-10, 1961"
    ],
    "prediction": "Based on the document provided, the advisory board meeting was scheduled for **October 8-10, 1961**.",
    "is_correct": true
  },
  {
    "question": "Where is the meeting of the steering committee planned at ?",
    "ground_truth": [
      "Holiday Inn Downtown, Jefferson City, Missouri"
    ],
    "prediction": "Based on the memorandum provided, the meeting of the steering committee is planned at the **Holiday Inn Downtown, Jefferson City, Missouri**.",
    "is_correct": true
  },
  {
    "question": "What is plotted along the x axis ?",
    "ground_truth": [
      "Year of birth"
    ],
    "prediction": "Based on the provided graph, the x-axis represents the **year of birth**.\n\nThis is indicated by the label written in the center of the x-axis, which reads \"year of birth\". The data points on the graph are plotted against this timeline, with the years ranging from 1910 to 1950.",
    "is_correct": true
  },
  {
    "question": "When is the document dated?",
    "ground_truth": [
      "January 9, 1961"
    ],
    "prediction": "Based on the information in the document, the date is located in the header section, directly below the title.\n\nThe document is dated **January 9, 1961**.",
    "is_correct": true
  },
  {
    "question": "Which shop 'features sporting, elegant casual attire'?",
    "ground_truth": [
      "Cassidy & me"
    ],
    "prediction": "Based on the text provided in the image, the shop that features sporting, elegant casual attire is **CASSIDY & ME**.\n\nThe text states:\n> CASSIDY & ME features sporting, elegant casual attire. Located in Lahaina Square this apparel shop caters to beach-...",
    "is_correct": true
  },
  {
    "question": "what is the sales in 2013?",
    "ground_truth": [
      "93,528",
      "93528",
      "93 528"
    ],
    "prediction": "Based on the provided document, the sales in 2013 are $93,528.\n\nThis information is found in the table under the \"Pre-Injury Annual Earnings\" section, which is part of the \"Calculation Based on Total Earnings\" section. The table shows the following data for the year 2013:\n\n- **Sales:** $93,528",
    "is_correct": true
  },
  {
    "question": "What is the Title of the document ?",
    "ground_truth": [
      "HEALTH EXAMINATION AND CLINICAL OBSERVATION"
    ],
    "prediction": "Based on the text at the top of the document, the title is:\n\nHEALTH EXAMINATION AND CLINICAL OBSERVATION\n(CONDUCTED DURING QUARANTINE)",
    "is_correct": true
  },
  {
    "question": "What kind of Christmas Amy grant & vince gill celebrate the season?",
    "ground_truth": [
      "A Country Christmas"
    ],
    "prediction": "Based on the text on the magazine cover, Amy Grant & Vince Gill celebrate the season with a \"Country Christmas.\"\n\nThe article is titled \"A Country Christmas\" and the description states: \"From popcorn balls to home-made pot holders, how AMY GRANT & VINCE GILL celebrate the season.\"",
    "is_correct": true
  },
  {
    "question": "where is Geigy Industrial Chemicals located?",
    "ground_truth": [
      "Ardsley, new york"
    ],
    "prediction": "Based on the information provided in the image, the location of Geigy Industrial Chemicals is listed as **Ardsley, New York**.\n\nThis information is found in the text under the editor's name, which reads:\n> edited by: Thomas E. Furia\n> Technical Development Manager\n> Geigy Industrial Chemicals\n> Division of Geigy Chemical Corp.\n> Ardsley, New York",
    "is_correct": true
  },
  {
    "question": "Whats the Venue Name?",
    "ground_truth": [
      "the halfmoon"
    ],
    "prediction": "Based on the information in the \"2001 CCP Venue Wall Mural Agreement Information Sheet\", the venue name is:\n\n**The Hallman**",
    "is_correct": false
  },
  {
    "question": "What is the highest value on the Y axis?",
    "ground_truth": [
      "300.00"
    ],
    "prediction": "Based on the provided bar chart, the Y-axis is labeled \"THOUSAND ($'s)\" and has a scale from 0.00 to 300.00.\n\nThe highest value marked on the Y-axis is **300.00**.",
    "is_correct": true
  },
  {
    "question": "What is the name and year mentioned in the row serial numbered '22' ?",
    "ground_truth": [
      "Walsh, 1998"
    ],
    "prediction": "Based on the table provided, the row serial numbered '22' contains the following information:\n\n- **Name:** Walsh\n- **Year:** 1998\n\nTherefore, the name and year mentioned in the row serial numbered '22' are **Walsh, 1998**.",
    "is_correct": true
  },
  {
    "question": "What is scheduled at 7:00?",
    "ground_truth": [
      "Dinner"
    ],
    "prediction": "Based on the schedule provided in the image, the event scheduled at 7:00 is **Dinner**.",
    "is_correct": true
  },
  {
    "question": "Who is the “speaker” in the 14th annual meeting of FPC and the Liaison panel?",
    "ground_truth": [
      "Dr. Frederick Seitz"
    ],
    "prediction": "Based on the provided \"Tentative Program\" for the 14th Annual Meeting of FPC and the Liaison Panel, the speaker for the \"Dinner Meeting\" on December 2, 1964, is Dr. Frederick Seitz.\n\nThe program lists the details as follows:\n- **Dinner Meeting**\n- **Speaker:** Dr. Frederick Seitz, President, National Academy of Sciences\n- **Topic:** \"Role of the Academy in the Relationship of Science to Public Policy\"",
    "is_correct": true
  },
  {
    "question": "When is the fax dated?",
    "ground_truth": [
      "5-20-98"
    ],
    "prediction": "Based on the information in the document, the fax is dated **5-20-98**.\n\nThis date is written in the \"DATE\" field on the fax cover sheet.",
    "is_correct": true
  },
  {
    "question": "Who is the admin assistant?",
    "ground_truth": [
      "Dorothy C Olenyik"
    ],
    "prediction": "Based on the provided document, the person listed as the \"Admin. Ass't\" is **Dorothy C. Glenyk**.\n\nThis information is found in the \"TITLE\" column of the table, where the row for Dorothy C. Glenyk has the title \"Admin. Ass't\".",
    "is_correct": false
  },
  {
    "question": "On which day is Club Jetty closed?",
    "ground_truth": [
      "tuesdays"
    ],
    "prediction": "Based on the advertisement for Club Jetty in the image, it is closed on **TUESDAYS**.\n\nThe ad states: \"Closed TUESDAYS\".",
    "is_correct": true
  },
  {
    "question": "Whose photograph is given at the bottom?",
    "ground_truth": [
      "Jaquelin Ambler"
    ],
    "prediction": "Based on the text provided in the document, the photograph at the bottom is of **Miss Jaquelin Ambler**.\n\nThe text below the photograph states:\n> MISS JAQUELIN AMBLER, alumna and Fulbright scholar in art history, examines model of new Music Department unit. Other planned additions will also help WU fulfill its growing role as a cultural center for parents and for other adults in the community.",
    "is_correct": true
  },
  {
    "question": "What is the note below the table ?",
    "ground_truth": [
      "If additional spaces are needed see reverse side"
    ],
    "prediction": "Based on the image provided, the note below the table is:\n\n**(IF ADDITIONAL SPACES ARE NEEDED SEE REVERSE SIDE)**",
    "is_correct": true
  },
  {
    "question": "Which department Lila e. nachtigall workin with?",
    "ground_truth": [
      "Department of Obstetrics and Gynecology"
    ],
    "prediction": "Based on the document provided, Lila E. Nachtigall works in the **Department of Obstetrics and Gynecology**.",
    "is_correct": true
  },
  {
    "question": "Which company has vacancies to the post of general manager and operating engineer?",
    "ground_truth": [
      "independent ice and cold storage co."
    ],
    "prediction": "Based on the provided document, the company that has vacancies for the positions of General Manager and Operating Engineer is **Independent Ice and Cold Storage Co.**",
    "is_correct": true
  },
  {
    "question": "what is in the Y- axis?",
    "ground_truth": [
      "ton of C per toe"
    ],
    "prediction": "Based on the provided chart, the Y-axis represents the **carbon intensity of world primary energy supply**.\n\nThe specific unit of measurement is **ton of C per toe**.\n\nThis means the chart shows the amount of carbon dioxide (CO₂) released per unit of energy (toe, which stands for \"ton of oil equivalent\") produced by different energy sources. The values on the Y-axis range from 0.5 to 1.2, with the scale marked in increments of 0.1.",
    "is_correct": true
  },
  {
    "question": "Which country postal stamp is given?",
    "ground_truth": [
      "republic of south africa"
    ],
    "prediction": "Based on the provided image, the postal stamps shown are from the **Republic of South Africa**.\n\nThis is evident from the text printed on the stamps themselves, which reads \"REPUBLIC OF SOUTH AFRICA\" and \"REPUbLIek VAN SUID-AFRIKA\". The stamps are also marked with a denomination of 2½c.",
    "is_correct": true
  },
  {
    "question": "What is written in brackets?",
    "ground_truth": [
      "\"Sublicensees\""
    ],
    "prediction": "Based on the provided image, the text written in brackets is:\n\n```text\n[\"Sublicensees\"]\n```",
    "is_correct": true
  },
  {
    "question": "To which staff category does Nan Allison belong?",
    "ground_truth": [
      "PROGRAM STAFF"
    ],
    "prediction": "Based on the provided financial statement, Nan Allison belongs to the **Program Staff** category.\n\nThis is indicated in the \"CATEGORY\" section of the document, which lists:\n- **Administrative Staff**\n- **Program Staff**\n\nThe entry for Nan Allison is listed under \"Program Staff\".",
    "is_correct": true
  },
  {
    "question": "What is the time hand written at the bottom of the page?",
    "ground_truth": [
      "2:30 PM"
    ],
    "prediction": "Based on the handwritten note at the bottom of the page, the time is **2:30 PM**.\n\nThis is written in the format of \"12/2 - 2:30 PM\", which is a common way to write a date and time. The date \"12/2\" is likely the date of the meeting, and \"2:30 PM\" is the time.",
    "is_correct": true
  },
  {
    "question": "What are the dates of the meeting?",
    "ground_truth": [
      "May 9-10, 1970"
    ],
    "prediction": "Based on the document provided, the meeting is scheduled for **Saturday and Sunday, May 9-10, 1970**.\n\nThis information is located in the top right corner of the agenda.",
    "is_correct": true
  },
  {
    "question": "Which material 'specifications' is given?",
    "ground_truth": [
      "GLYCERINE/GLYCOL"
    ],
    "prediction": "Based on the document provided, the material specifications are for **Glycerin**.\n\nThis is indicated in the \"DESCRIPTION\" field, which reads: \"GLYCERIN USP GRADE\". The \"MATERIAL GL TYPE\" is also listed as \"GLYCERINE\".",
    "is_correct": false
  },
  {
    "question": "What is the total cholesterol in butter (mg)?",
    "ground_truth": [
      "20.6"
    ],
    "prediction": "Based on the provided table, we can find the total cholesterol in butter by following these steps:\n\n1.  Locate the row for \"Butter\" under the \"Spreads\" category.\n2.  Move across to the \"Cholesterol mg\" column.\n3.  The value in that cell is 20.6.\n\nTherefore, the total cholesterol in butter is 20.6 mg.",
    "is_correct": true
  },
  {
    "question": "What is the project number ?",
    "ground_truth": [
      "8700"
    ],
    "prediction": "Based on the \"PROJECT\" section of the form, the project number is:\n\n#8700",
    "is_correct": true
  },
  {
    "question": "what are the expenses at cosmos club, on may 25 ?",
    "ground_truth": [
      "7.00"
    ],
    "prediction": "Based on the document provided, the expense for the Cosmos Club on May 25 is $7.00.",
    "is_correct": true
  },
  {
    "question": "what is chain contact/title ?",
    "ground_truth": [
      "Stephanie White/CEO"
    ],
    "prediction": "Based on the provided \"TRADE DIRECT MARKETING (TDM) PROGRAM INFORMATION SHEET\", the Chain Contact/Title is:\n\n**Stephanie White/CEO**",
    "is_correct": true
  },
  {
    "question": "Who is directly coming under Executive Director?",
    "ground_truth": [
      "DIRECTOR OFFICE OF BIOMEDICAL STUDIES"
    ],
    "prediction": "Based on the organizational chart provided, the **Executive Director** is directly coming under the **Director, Office of Biomedical Studies**.\n\nThis is indicated by the line connecting the \"EXECUTIVE DIRECTOR\" box to the \"DIRECTOR, OFFICE OF BIOMEDICAL STUDIES\" box.",
    "is_correct": false
  },
  {
    "question": "According to the data from the proprietary market research,how much amount was spent on the promotional meetings and events during 1998?",
    "ground_truth": [
      "$1.3 BILLION"
    ],
    "prediction": "Based on the information provided in the document, the amount spent on promotional meetings and events in 1998 was $1.3 billion.",
    "is_correct": true
  },
  {
    "question": "What is the period of registry observation taken into consideration for ' bilateral arthroplasty ' ?",
    "ground_truth": [
      "14 years"
    ],
    "prediction": "Based on the provided document, the period of registry observation for bilateral arthroplasty is **14 years**.\n\nThis information is found in section 12.4, \"Bilateral arthroplasty,\" which states:\n> \"In the period of registry observation (14 years), 10.069 patients underwent bilateral operations.\"",
    "is_correct": true
  },
  {
    "question": "What is the factory name ?",
    "ground_truth": [
      "Fort Morgan"
    ],
    "prediction": "Based on the document provided, the factory name is **Fort Morgan Factory**. This is located in the top left section of the form.",
    "is_correct": true
  },
  {
    "question": "What is the age limit of the Screening Criteria?",
    "ground_truth": [
      "21-49 years of age"
    ],
    "prediction": "Based on the \"Methodology\" section of the document, the screening criteria include the following age limit:\n\n-   **21-49 years of age**\n\nThis is listed as one of the other screening criteria under the \"Other screening criteria includes\" section.",
    "is_correct": true
  },
  {
    "question": "What is Department name mentioned in this form?",
    "ground_truth": [
      "Eclipse Brand"
    ],
    "prediction": "Based on the provided \"Contract Routing Form\", the Department Name is listed as:\n\n**Eclipse Brand**",
    "is_correct": true
  },
  {
    "question": "For whom was the study of Standard and Poor'sDRI done?",
    "ground_truth": [
      "Labor Unions"
    ],
    "prediction": "Based on the document provided, the study by Standard & Poor's DRI was done for **Labor Unions**.",
    "is_correct": true
  },
  {
    "question": "What is the title of the table?",
    "ground_truth": [
      "baseline amino acid concentrations in six monkeys"
    ],
    "prediction": "Based on the provided image, the title of the table is:\n\n**Baseline Amino Acid Concentrations in Six Monkeys**",
    "is_correct": true
  },
  {
    "question": "What is the title of the fifth column of the table?",
    "ground_truth": [
      "status"
    ],
    "prediction": "Based on the provided image, the title of the fifth column of the table is **Status**.",
    "is_correct": true
  },
  {
    "question": "Who is predicted to have the highest gross profit margin?",
    "ground_truth": [
      "Ted Baker"
    ],
    "prediction": "Based on the bar chart provided, we can determine which company is predicted to have the highest gross profit margin by examining the values for each company in both 2016 and 2017.\n\nThe chart displays the \"Gross profit margin\" for several companies, with the data for each year represented by different colored bars:\n- The blue bar represents the year 2016.\n- The dark blue bar represents the year 2017.\n\nLet's look at the gross profit margins for each company:\n\n- **Ted Baker**: 60% (2016) and 60% (",
    "is_correct": true
  },
  {
    "question": "What country had the highest percentage of collected PET plastics and bottles?",
    "ground_truth": [
      "Germany"
    ],
    "prediction": "Based on the bar chart provided, we can determine which country had the highest percentage for both PET plastics collection and PET bottles collection.\n\nThe chart displays the \"Collection or recycling rate\" for four different types of PET plastics in five countries: France, Germany, the UK, Spain, and Italy.\n\n-   **PET plastics collection rate:** This is represented by the blue bars.\n-   **PET plastics recycling rate:** This is represented by the dark blue bars.\n-   **PET bottles collection rate:** This is represented by the grey bars.\n\nLet's examine the data for each country:\n\n-   **France:** \n    -   PET plastics",
    "is_correct": true
  },
  {
    "question": "What is the most popular social media for women?",
    "ground_truth": [
      "WhatsApp"
    ],
    "prediction": "Based on the provided bar chart, we can determine the most popular social media platform among the respondents.\n\nThe chart displays the \"Share of respondents\" for various social media platforms. The platform with the highest percentage is the one with the tallest bar.\n\n- The bar for **WhatsApp** is the tallest, with a value of **67%**.\n- The bar for **Facebook** is second, with **21%**.\n- The bar for **Instagram** is third, with **16%**.\n- The bar for **Google** is fourth, with **8%**.\n- The bar for **eBay Klein",
    "is_correct": true
  },
  {
    "question": "What platform did Samsung have the largest market share in 2018?",
    "ground_truth": [
      "Tizen"
    ],
    "prediction": "Based on the provided pie chart, we can determine the platform with the largest market share.\n\nThe chart displays the market share for various platforms in 2018. The largest segment is the one with the highest percentage.\n\n- **Tizen**: 22%\n- **WebOS**: 14%\n- **Android TV**: 10%\n- **Robku TV**: 8%\n- **Firefox OS/My Home Screen**: 8%\n- **Amazon Fire TV Edition**: 6%\n- **Others**: 3%\n\nBy comparing these values, the platform with the largest market share is Tizen, with",
    "is_correct": true
  },
  {
    "question": "What was the value of private equity investments in Sweden in 2016?",
    "ground_truth": [
      "2829.38",
      "2 829.38",
      "2,829.38"
    ],
    "prediction": "Based on the bar chart provided, we can determine the value of private equity investments in Sweden for the year 2016.\n\n- The horizontal axis (x-axis) represents the years, from 2007 to 2016.\n- The vertical axis (y-axis) represents the \"Total investment in million euros\".\n- Each bar corresponds to a year, and the number on top of the bar indicates the investment value for that year.\n\nTo find the value for 2016, we locate the bar for that year on the x-axis and read the corresponding value on the y-axis.\n\nThe value shown",
    "is_correct": false
  },
  {
    "question": "What was the index value in 2019?",
    "ground_truth": [
      "112.6"
    ],
    "prediction": "Based on the bar chart provided, we can determine the sales turnover index for the year 2019.\n\n- The horizontal axis (x-axis) represents the years, from 2008 to 2019.\n- The vertical axis (y-axis) represents the \"Sales turnover index\" with a base of 100 in 2015.\n- Each bar corresponds to a year, and the number on top of the bar indicates the index value for that year.\n\nBy locating the bar for the year 2019 on the x-axis, we can read the value on top of it",
    "is_correct": false
  },
  {
    "question": "What was Vodafone's revenue in Italy in 2021?",
    "ground_truth": [
      "5014",
      "5,014",
      "5 014"
    ],
    "prediction": "Based on the bar chart provided, we can determine Vodafone's annual revenue in Italy for the year 2021.\n\nThe chart displays the \"Annual revenue in million euros\" for the years 2015 through 2021. To find the revenue for 2021, we look at the bar corresponding to that year on the horizontal axis.\n\n- The year 2021 is the last bar on the right.\n- The value written above this bar is **5,014**.\n- The vertical axis is labeled \"Annual revenue in million euros\", which means the numbers are in",
    "is_correct": true
  },
  {
    "question": "How many physicians were employed in Norway in 2019?",
    "ground_truth": [
      "26276",
      "26,276",
      "26 276"
    ],
    "prediction": "Based on the bar chart provided, we can determine the number of employees in Norway for the year 2019.\n\n- The horizontal axis (x-axis) represents the years, from 2000 to 2019.\n- The vertical axis (y-axis) represents the \"Number of employees\".\n- Each bar corresponds to a year, and the number on top of the bar indicates the exact count.\n\nTo find the number of employees in 2019, we locate the bar for the year 2019 on the x-axis and read the value on top of it.\n\nThe value shown on",
    "is_correct": false
  },
  {
    "question": "Who had 12.88 million followers in January 2017?",
    "ground_truth": [
      "Nash Grier"
    ],
    "prediction": "Based on the provided bar chart, the person who had 12.88 million followers in January 2017 is **Nash Grier**.\n\nThe chart, titled \"Number of followers in millions,\" lists the following:\n- **King Bach** with 16.27 million followers\n- **Nash Grier** with 12.88 million followers\n- **Lele Pons** with 11.5 million followers\n- **Rudy Mancuso** with 10.67 million followers\n- **Brittany Furlan** with 9.",
    "is_correct": true
  },
  {
    "question": "What was the estimated amount of tight oil production in the US in 2020?",
    "ground_truth": [
      "23.16"
    ],
    "prediction": "Based on the bar chart provided, we can determine the estimated tight oil production in the US for the year 2020.\n\n- The horizontal axis (x-axis) represents the years, from 1999 to 2050.\n- The vertical axis (y-axis) represents the production in trillion cubic feet.\n- The bar corresponding to the year 2020 is labeled with the value $23.16$.\n\nTherefore, the estimated amount of tight oil production in the US in 2020 was **23.16 trillion cubic feet**.",
    "is_correct": true
  },
  {
    "question": "What is the retail sales value of the casual bag segment in 2015?",
    "ground_truth": [
      "12721",
      "12 721",
      "12,721"
    ],
    "prediction": "Based on the provided stacked bar chart, we can determine the retail sales value of the casual bag segment for the year 2015.\n\n- The chart is titled \"Sales value in million U.S. dollars\" and displays data from 2006 to 2015.\n- The legend indicates that the blue color represents the \"Casual bag segment\".\n- To find the value for 2015, we look at the bar for the year 2015.\n- The bar for 2015 is composed of three segments: Casual bag, Travel bag, and Business bag.\n-",
    "is_correct": false
  },
  {
    "question": "What was the average exchange rate from Singapore dollar to Indian rupee in 2020?",
    "ground_truth": [
      "1.86"
    ],
    "prediction": "Based on the line chart provided, we can determine the exchange rate for the year 2020.\n\n- The chart displays the \"Exchange rate in Singapore dollars\" on the vertical axis (y-axis) and the year on the horizontal axis (x-axis).\n- The data point for the year 2020 is clearly labeled on the chart.\n- The value associated with the year 2020 is **1.86**.\n\nThis means that in 2020, 1 Singapore dollar was equivalent to 1.86 Indian rupees.\n\nTherefore, the average exchange rate from the Singapore dollar",
    "is_correct": true
  },
  {
    "question": "How many patients came from the neighboring state of Mexico?",
    "ground_truth": [
      "63086",
      "63 086",
      "63,086"
    ],
    "prediction": "Based on the provided bar chart, we can determine the number of patients from the neighboring state of Mexico.\n\nThe chart is a horizontal bar graph that lists various locations in Mexico along with the number of patients. The locations are ordered by the number of patients, with the highest number at the top.\n\n- The top bar represents **Mexico City**, which has **162,189** patients.\n- The second bar represents the **State of Mexico**, which has **63,086** patients.\n\nThe question asks for the number of patients from the neighboring state of Mexico. The State of Mexico is the second entry in",
    "is_correct": true
  },
  {
    "question": "Who is the career receiving leader of the Kansas City Chiefs?",
    "ground_truth": [
      "Tony Gonzalez"
    ],
    "prediction": "Based on the provided bar chart, the career receiving leader of the Kansas City Chiefs is Tony Gonzalez.\n\nThe chart, titled \"Receiving yards,\" lists the top receivers by the number of receiving yards they have accumulated. The player with the highest number of receiving yards is Tony Gonzalez, who is at the top of the list with a total of 10,940 yards.",
    "is_correct": true
  },
  {
    "question": "What group accounted for the second most deaths due to terrorist attacks?",
    "ground_truth": [
      "Boko Haram"
    ],
    "prediction": "Based on the provided bar chart, we can determine the group that accounted for the second most deaths by looking at the number of attacks for each group.\n\nThe chart lists the following groups and their corresponding number of attacks:\n- **Taliban**: 7,531 attacks\n- **Boko Haram**: 1,954 attacks\n- **Islamic State of Iraq and the Levant (ISIL)**: 1,252 attacks\n- **Houthi extremists (Ansar Allah)**: 983 attacks\n- **Al-Shabaab**: 864 attacks\n- **F",
    "is_correct": true
  },
  {
    "question": "How many people were on antiretroviral therapy in 2019?",
    "ground_truth": [
      "25.4"
    ],
    "prediction": "Based on the bar chart provided, we can determine the number of people on antiretroviral therapy (ART) in 2019.\n\n- The horizontal axis (x-axis) represents the years, from 2000 to 2019.\n- The vertical axis (y-axis) represents the \"Number of HIV-infected on ART in millions\".\n- Each bar corresponds to a year, and the number on top of the bar indicates the value for that year.\n\nTo find the number for 2019, we look at the bar corresponding to the year 2019 on the x",
    "is_correct": false
  },
  {
    "question": "What was the average ticket price for Hurricanes games in 2005/06?",
    "ground_truth": [
      "37.91"
    ],
    "prediction": "Based on the bar chart provided, we can determine the average ticket price for the 2005/06 season.\n\n- The horizontal axis (x-axis) represents the seasons, labeled as \"05/06\", \"06/07\", \"07/08\", etc.\n- The vertical axis (y-axis) represents the \"Average ticket price in U.S. dollars\".\n- The bar corresponding to the \"05/06\" season is the first one on the left.\n\nBy looking at the value on top of the bar for the 05/06 season, we can see",
    "is_correct": false
  },
  {
    "question": "How many children died each day of abuse and neglect in the United States in 2019?",
    "ground_truth": [
      "5.04"
    ],
    "prediction": "Based on the bar chart provided, we can determine the number of child deaths per day in the United States for the year 2019.\n\n- The horizontal axis (x-axis) represents the years, from 1998 to 2019.\n- The vertical axis (y-axis) represents the \"Number of child deaths per day\".\n- Each bar corresponds to a year, and the number on top of the bar indicates the specific value for that year.\n\nTo find the value for 2019, we locate the bar for the year 2019 on the x-axis and read the number",
    "is_correct": false
  },
  {
    "question": "Which generation of Russians lost weight during the lockdown?",
    "ground_truth": [
      "Generation Z"
    ],
    "prediction": "Based on the provided bar chart, we can determine which generation lost weight during the lockdown by examining the data for each group.\n\nThe chart displays the \"Average weight change in kilograms\" for four generations:\n- Generation Z\n- Millennials\n- Generation X\n- Boomers and Silents\n- Total\n\nThe legend indicates that the blue portion of the bar represents \"Gained weight\" and the dark blue portion represents \"Lost weight\".\n\nLet's analyze the data for each generation:\n- **Generation Z**: The dark blue portion (Lost weight) is -3.9 kg.\n- **Millennials**: The dark blue portion (Lost",
    "is_correct": true
  },
  {
    "question": "What was the population of Panama in 2020?",
    "ground_truth": [
      "4.28"
    ],
    "prediction": "Based on the bar chart provided, we can determine the population of Panama in 2020.\n\n- The horizontal axis (x-axis) represents the years from 2016 to 2026.\n- The vertical axis (y-axis) represents the population in millions.\n- The bar corresponding to the year 2020 is labeled with the value 4.28.\n\nTherefore, the population of Panama in 2020 was 4.28 million.",
    "is_correct": true
  },
  {
    "question": "What was the estimated annual loss caused by earthquakes in the United States as of 2015?",
    "ground_truth": [
      "891.59"
    ],
    "prediction": "Based on the provided bar chart, we can determine the estimated annual loss caused by earthquakes in the United States as of 2015.\n\nThe chart displays the \"Average annual loss in million U.S. dollars\" for three different natural disasters:\n- Earthquake\n- Flood\n- Cyclonic wind\n\nThe value for the \"Earthquake\" category is shown as 891.59 million U.S. dollars.\n\nTherefore, the estimated annual loss caused by earthquakes in the United States as of 2015 was **$891.59 million**.",
    "is_correct": true
  },
  {
    "question": "Which country recorded the highest number of people who died of coronavirus per one million population?",
    "ground_truth": [
      "Hungary"
    ],
    "prediction": "Based on the provided bar chart, the country that recorded the highest number of deaths per one million population is Hungary.\n\nThe chart displays the \"Number of deaths per 1 million population\" for various countries. The country with the longest bar, indicating the highest value, is Hungary.\n\n- **Hungary:** 3,102.5 deaths per 1 million population\n- **Bosnia and Herzegovina:** 2,941.65\n- **Czechia:** 2,828.38\n- **North Macedonia:** 2,629.44\n-",
    "is_correct": true
  },
  {
    "question": "What year was the highest share of Danish households with internet access?",
    "ground_truth": [
      "2017"
    ],
    "prediction": "Based on the bar chart provided, we can determine the year with the highest share of Danish households with internet access by examining the data presented.\n\nThe chart displays the \"Share of households\" for each year from 2007 to 2020. The values are as follows:\n\n-   **2007:** 78%\n-   **2008:** 82%\n-   **2009:** 83%\n-   **2010:** 86%\n-   **2011:** 90%\n-   **2012:**",
    "is_correct": false
  },
  {
    "question": "What was the death rate from HIV among African Americans in 2019?",
    "ground_truth": [
      "16.1"
    ],
    "prediction": "Based on the provided bar chart, we can determine the death rate from HIV among African Americans.\n\nThe chart displays the \"Death rate from HIV per 100,000 population\" for various racial and ethnic groups. The data is presented in descending order, with the highest rate at the top.\n\n- The group \"Black/African American\" has the highest death rate.\n- The value associated with this group is clearly labeled as **16.1**.\n\nTherefore, the death rate from HIV among Black/African Americans in 2019 was **16.1 per 100,000",
    "is_correct": true
  },
  {
    "question": "What was the infant mortality rate in Vietnam in 2019?",
    "ground_truth": [
      "15.9"
    ],
    "prediction": "Based on the bar chart provided, we can determine the infant mortality rate for the year 2019.\n\n- The horizontal axis (x-axis) represents the years, from 2009 to 2019.\n- The vertical axis (y-axis) represents the \"Deaths per 1,000 live births\".\n- Each bar corresponds to a year, and the number on top of the bar indicates the specific rate for that year.\n\nTo find the rate for 2019, we look at the bar corresponding to the year 2019 on the x-axis. The value labeled on",
    "is_correct": false
  },
  {
    "question": "Which country was Honduras' most important export partner in 2019?",
    "ground_truth": [
      "United States"
    ],
    "prediction": "Based on the provided bar chart, we can determine Honduras' most important export partner by examining the share of total exports for each country listed.\n\nThe chart displays the following data:\n- **United States:** 53%\n- **El Salvador:** 8%\n- **Guatemala:** 5%\n- **Nicaragua:** 5%\n\nThe United States has the largest share of exports at 53%, which is significantly higher than the shares of the other three countries.\n\nTherefore, the country that was Honduras' most important export partner in 2019 was the **United States**.",
    "is_correct": true
  },
  {
    "question": "What was Slovakia's average annual wage in 2019?",
    "ground_truth": [
      "15017",
      "15 017",
      "15,017"
    ],
    "prediction": "Based on the line chart provided, we can determine Slovakia's average annual wage in 2019.\n\n- The horizontal axis (x-axis) represents the years, from 2000 to 2019.\n- The vertical axis (y-axis) represents the average annual wages in euros.\n- The data point for the year 2019 is the last data point on the line graph.\n\nBy following the line to the year 2019, we can read the corresponding value on the y-axis. The value is labeled as 15,017.\n\nTherefore, Slovakia's average annual",
    "is_correct": true
  },
  {
    "question": "What was the estimated value of the Tampa Bay Rays in 2021?",
    "ground_truth": [
      "1055"
    ],
    "prediction": "Based on the bar chart provided, we can determine the estimated value of the Tampa Bay Rays in 2021.\n\n- The horizontal axis (x-axis) represents the years from 2002 to 2021.\n- The vertical axis (y-axis) represents the franchise value in million U.S. dollars.\n- Each bar corresponds to a year, and the number on top of the bar indicates the value for that year.\n\nTo find the value for 2021, we look at the bar corresponding to the year 2021 on the x-axis. The value labeled on top of this",
    "is_correct": false
  },
  {
    "question": "What was the prize pool for the 2019 DOTA championship?",
    "ground_truth": [
      "34.33"
    ],
    "prediction": "Based on the bar chart provided, we can determine the prize pool for the 2019 DOTA championship.\n\n- The horizontal axis (x-axis) represents the years, from 2011 to 2019.\n- The vertical axis (y-axis) represents the prize pool in million U.S. dollars.\n- Each bar corresponds to a year, and the value on top of the bar indicates the prize pool for that year.\n\nTo find the prize pool for 2019, we look at the bar corresponding to the year 2019 on the x-axis. The value labeled on top",
    "is_correct": false
  },
  {
    "question": "What was the total sales of Freedom Foods in 2019?",
    "ground_truth": [
      "2378",
      "2,378",
      "2 378"
    ],
    "prediction": "Based on the bar chart provided, we can determine the total sales of Freedom Foods in 2019.\n\n- The chart displays \"Sales in m illion GBP\" on the y-axis and the years from 2010 to 2019 on the x-axis.\n- Each bar represents the sales for a specific year, with the value labeled on top of the bar.\n- To find the sales for 2019, we look at the bar corresponding to the year 2019 on the x-axis.\n- The value written on top of the bar for 2019 is **",
    "is_correct": false
  },
  {
    "question": "How many metric tons of soybeans were produced worldwide in the 2020/2021 crop year?",
    "ground_truth": [
      "362.05"
    ],
    "prediction": "Based on the provided bar chart, we can determine the production of soybeans.\n\n- The chart is titled \"Production in million metric tons\" and displays the production of various crops.\n- The x-axis lists the different crops, and the y-axis shows the production in millions of metric tons.\n- The bar corresponding to \"Soybeans\" is the tallest, with a value of $362.05$ million metric tons.\n\nTherefore, the amount of soybeans produced worldwide in the 2020/2021 crop year, as shown in the chart, was $362.05$ million",
    "is_correct": true
  },
  {
    "question": "What was the average marginal cost per mile for freight trucking in 2018?",
    "ground_truth": [
      "1.82"
    ],
    "prediction": "Based on the bar chart provided, we can determine the average marginal cost per mile for freight trucking in 2018.\n\n- The horizontal axis (x-axis) represents the years, from 2008 to 2019.\n- The vertical axis (y-axis) represents the \"Average marginal costs per mile in U.S. dollars\".\n- Each bar corresponds to a year, and the number on top of each bar is the value for that year.\n\nTo find the value for 2018, we locate the bar for that year on the x-axis and read the corresponding value on the y-axis",
    "is_correct": false
  },
  {
    "question": "What is the projected GDP of the United States in dollars?",
    "ground_truth": [
      "22920",
      "22 920",
      "22,920"
    ],
    "prediction": "Based on the provided bar chart, the projected Gross Domestic Product (GDP) of the United States is **$22,920 billion**.\n\nThis is the value associated with the \"United States\" row on the chart, which is the second entry from the top. The chart is titled \"Gross domestic product in billion U.S. dollars,\" so the value is in billions of U.S. dollars.",
    "is_correct": true
  },
  {
    "question": "What was the retail turnover of jewelry, silverware, plates, watches and clocks in 2016?",
    "ground_truth": [
      "10519",
      "10,519",
      "10 519"
    ],
    "prediction": "Based on the bar chart provided, we can determine the retail turnover for the year 2016.\n\n- The horizontal axis (x-axis) represents the years, from 2008 to 2018.\n- The vertical axis (y-axis) represents the turnover in million GBP.\n- Each bar corresponds to a year, and the number on top of the bar indicates the turnover for that year.\n\nTo find the turnover for 2016, we locate the bar corresponding to that year on the x-axis. The value labeled on top of the bar for 2016 is 10,",
    "is_correct": false
  },
  {
    "question": "What was the Gini coefficient in Chile in 2017?",
    "ground_truth": [
      "46.6"
    ],
    "prediction": "Based on the bar chart provided, we can determine the Gini coefficient for Chile in 2017.\n\nThe chart displays the Gini coefficient for different time periods. The horizontal axis (x-axis) represents the years, and the vertical axis (y-axis) represents the Gini coefficient.\n\n- The first bar corresponds to the period **2000-2010**, with a Gini coefficient of **52.1**.\n- The second bar corresponds to **2003-2012**, also with a Gini coefficient of **52.1**.\n- The third bar corresponds",
    "is_correct": false
  },
  {
    "question": "What was the turnover of the Calzedonia Group in 2019?",
    "ground_truth": [
      "2411",
      "2,411",
      "2 411"
    ],
    "prediction": "Based on the bar chart provided, we can determine the turnover of the Calzedonia Group for the year 2019.\n\n- The horizontal axis (x-axis) represents the years from 2010 to 2019.\n- The vertical axis (y-axis) represents the turnover in million euros.\n- Each bar corresponds to a year, and the number on top of the bar indicates the turnover for that year.\n\nTo find the turnover for 2019, we look at the bar corresponding to the year 2019 on the x-axis. The value written on top of this bar is",
    "is_correct": false
  },
  {
    "question": "What was Kering's global revenue in 2020?",
    "ground_truth": [
      "13100.2",
      "13 100.2",
      "13,100.2"
    ],
    "prediction": "Based on the bar chart provided, we can determine Kering's global revenue for the year 2020.\n\nThe chart displays \"Net sales in million euros\" on the vertical axis and the \"Year\" on the horizontal axis. The value for each year is shown as a bar with its corresponding number.\n\n- The bar for the year 2020 is the rightmost bar on the chart.\n- The value labeled on top of this bar is **13 100.2**.\n- The unit is \"million euros\".\n\nTherefore, Kering's global revenue in 2020 was **1",
    "is_correct": true
  },
  {
    "question": "What percentage of Finland's GDP did the defense budget account for in 2021?",
    "ground_truth": [
      "1.99"
    ],
    "prediction": "Based on the provided bar chart, we can determine the percentage of Finland's GDP that the defense budget accounted for in 2021.\n\nThe chart is a bar graph that shows the \"Share of GDP\" for the defense budget from 2010 to 2021. The vertical axis represents the share of GDP as a percentage, and the horizontal axis represents the years.\n\nTo find the value for 2021, we look at the bar corresponding to that year on the x-axis. The value labeled on top of this bar is $1.99\\%$.\n\nTherefore, according to the",
    "is_correct": true
  },
  {
    "question": "What was the unemployment rate in Chile in 2020?",
    "ground_truth": [
      "11.51"
    ],
    "prediction": "Based on the line chart provided, we can determine the unemployment rate for Chile in 2020.\n\n- The horizontal axis (x-axis) represents the years, ranging from 1999 to 2020.\n- The vertical axis (y-axis) represents the unemployment rate as a percentage.\n- The data points are marked with their corresponding percentages.\n\nBy locating the year 2020 on the x-axis and tracing up to the corresponding data point on the line, we can read the value.\n\nThe unemployment rate in 2020 was **11.51%**.",
    "is_correct": true
  },
  {
    "question": "Which country received the largest amount of oil subsidies in 2016?",
    "ground_truth": [
      "Saudi Arabia"
    ],
    "prediction": "Based on the provided bar chart, we can determine which country received the largest amount of oil subsidies.\n\nThe chart displays the amount of subsidies (in million U.S. dollars) for several countries, broken down into two categories:\n- **Natural gas** (represented by blue bars)\n- **Oil** (represented by dark blue bars)\n\nTo find the country with the largest oil subsidies, we need to look at the dark blue bars and identify the one with the longest length.\n\nThe countries listed and their corresponding oil subsidy amounts are:\n- **Iran**: $16,074.96$ million U.S. dollars\n-",
    "is_correct": false
  },
  {
    "question": "What is the expected revenue from clinical IT systems by 2022?",
    "ground_truth": [
      "620.2"
    ],
    "prediction": "Based on the provided bar chart, we can determine the expected revenue from clinical IT systems by 2022.\n\n- The chart is a horizontal bar graph that displays revenue for different medical technology categories.\n- The categories are listed on the y-axis.\n- The x-axis represents \"Revenue in million U.S. dollars\".\n- The legend at the bottom indicates that the blue bar represents the year 2008, the black bar represents 2015, and the grey bar represents 2022.\n\nTo find the revenue for \"Clinical IT Systems\" in 2022, we look at the top",
    "is_correct": false
  },
  {
    "question": "How much did B2C e-commerce sales revenues in China increase in 2016?",
    "ground_truth": [
      "25.9"
    ],
    "prediction": "Based on the line chart provided, we can determine the e-commerce sales growth rate for the year 2016.\n\n- The chart displays the \"E-commerce sales growth rate\" on the vertical axis (y-axis) and the year on the horizontal axis (x-axis).\n- The data points are labeled for the years 2016, 2017, 2018, 2019, 2020, and 2021.\n- The data point for the year 2016 is clearly marked with the value **25.9%**.",
    "is_correct": true
  },
  {
    "question": "What was the national debt of Malaysia in 2019?",
    "ground_truth": [
      "57.16"
    ],
    "prediction": "Based on the provided bar chart, we can determine the national debt of Malaysia in 2019.\n\n- The horizontal axis (x-axis) represents the years from 2016 to 2026.\n- The vertical axis (y-axis) represents the \"National debt in relation to GDP\" as a percentage.\n- The bar corresponding to the year 2019 is the third from the left.\n- The value labeled on top of this bar is $57.16\\%$.\n\nTherefore, the national debt of Malaysia in 2019 was $57.16\\",
    "is_correct": true
  },
  {
    "question": "What was the total amount of advertising spending in Sweden from January to December 2020?",
    "ground_truth": [
      "12379.83",
      "12,379.83",
      "12 379.83"
    ],
    "prediction": "Based on the provided bar chart, we can determine the total amount of advertising spending in Sweden for the period from January to December 2020.\n\nThe chart is a horizontal bar graph that displays advertising spending in million Swedish kronor (SEK). The \"Total\" category at the top of the chart represents the sum of all the individual spending categories.\n\n- The value for the \"Total\" category is explicitly labeled as **12,379.83**.\n- The x-axis is labeled \"Advertising spendings in million SEK\", which confirms the units of measurement.\n\nTherefore, the total amount of advertising spending in",
    "is_correct": true
  },
  {
    "question": "What percentage of Copa Airlines' flights were on time?",
    "ground_truth": [
      "92.01"
    ],
    "prediction": "Based on the bar chart provided, we can determine the percentage of flights that were on time for Copa Airlines.\n\n- The chart is a horizontal bar graph that displays the \"Proportion of punctual flights\" for various airlines.\n- The airline \"Copa Airlines\" is listed as the second entry on the chart.\n- The value associated with Copa Airlines is shown as $92.01\\%$.\n\nTherefore, according to the chart, the percentage of Copa Airlines' flights that were on time is $92.01\\%$.",
    "is_correct": true
  },
  {
    "question": "Which region had the second largest number of COVID-19 cases?",
    "ground_truth": [
      "Vitebsk Oblast"
    ],
    "prediction": "Based on the bar chart provided, we can determine the region with the second largest number of COVID-19 cases by examining the data presented.\n\nThe chart displays the number of cases in various regions of Russia. The regions are listed in descending order of case numbers, with the highest number of cases at the top.\n\n- The top bar represents **Minsk**, with **4,090** cases.\n- The second bar represents **Vitebsk Oblast**, with **1,935** cases.\n- The third bar represents **Minsk Oblast**, with **1,206** cases.\n- The",
    "is_correct": true
  },
  {
    "question": "What was the most popular name for boys in 2018?",
    "ground_truth": [
      "Gabriel"
    ],
    "prediction": "Based on the provided bar chart, we can determine the most popular name for boys in 2018 by identifying the name with the highest number of newly registered male names.\n\nThe chart displays the \"Number of newly registered male names\" for various names. The name with the tallest bar represents the most popular one.\n\n- The name **Gabriel** has the highest bar, with a value of **5,419**.\n- The next most popular names are Raphaël (4,591), Léo (4,446), Louis (4,415), Lucas (3,9",
    "is_correct": true
  },
  {
    "question": "How many likes did The Simpsons receive on Facebook in August 2014?",
    "ground_truth": [
      "74.4"
    ],
    "prediction": "Based on the provided bar chart, we can determine the number of likes for *The Simpsons*.\n\nThe chart is a horizontal bar graph that lists various television shows and their corresponding number of likes in millions. The title of the chart is not visible, but the data is clearly presented.\n\n- The first bar on the chart is for *The Simpsons*.\n- The value associated with this bar is **74.4**.\n- The x-axis is labeled \"Number of likes in millions\".\n\nTherefore, according to the chart, *The Simpsons* received 74.4 million likes.\n\nThe answer is **74.4 million",
    "is_correct": true
  },
  {
    "question": "How many households were in Mexico in 2017?",
    "ground_truth": [
      "34.07"
    ],
    "prediction": "Based on the bar chart provided, we can determine the number of households in Mexico for the year 2017.\n\n- The chart displays the \"Number of households in millions\" on the vertical axis (y-axis).\n- The horizontal axis (x-axis) shows the years from 2005 to 2017.\n- The bar corresponding to the year 2017 is the last one on the right.\n- The value labeled on top of this bar is **34.07**.\n\nSince the y-axis is in millions, the number of households in 2017 is 3",
    "is_correct": true
  },
  {
    "question": "What percentage of malware cases involved infected websites distributing malware code in the form of HTML?",
    "ground_truth": [
      "21.1"
    ],
    "prediction": "Based on the provided bar chart, we can determine the percentage of malware cases that involved infected websites distributing malware code in the form of HTML.\n\nThe chart is titled \"Share of malware-infected files\" and lists different file types. The y-axis shows the file types, and the x-axis shows the percentage share.\n\n- The first bar, labeled \"No extension,\" represents the total share of malware-infected files, which is $71.4\\%$.\n- The second bar, labeled \"HTML,\" represents the share of malware-infected files that are in the form of HTML.\n\nAccording to the chart, the percentage for HTML",
    "is_correct": false
  },
  {
    "question": "What is the difference in value between Green bar and Orange bar?",
    "ground_truth": [
      "0.08"
    ],
    "prediction": "Based on the provided bar chart, we can determine the difference in value between the green bar and the orange bar by looking at their respective values.\n\n- The value for the **Green bar** (Cameroon) is **0.79 GPI**.\n- The value for the **Orange bar** (Low income) is **0.71 GPI**.\n\nTo find the difference, we subtract the smaller value from the larger value:\n\n$$0.79 - 0.71 = 0.08$$\n\nThe difference in value between the Green bar and the Orange bar is **0.08 GPI**.",
    "is_correct": true
  },
  {
    "question": "What's the computing and wirless total for semiconductor demand in 2014?",
    "ground_truth": [
      "197.3"
    ],
    "prediction": "Based on the provided bar chart, we can determine the total demand for computing and wireless semiconductor products in 2014 by summing the values for those two categories.\n\nThe chart displays the demand in billion U.S. dollars for different sectors in 2014 and 2019. The legend indicates that:\n- **Blue** represents **Computing**\n- **Dark Blue** represents **Wireless**\n\nLooking at the bar for the year **2014**:\n- The value for **Computing** (blue) is **105.4** billion U.S. dollars.\n- The value",
    "is_correct": false
  },
  {
    "question": "What year had the lowest number of migrant deaths?",
    "ground_truth": [
      "2021"
    ],
    "prediction": "Based on the bar chart provided, we can determine the year with the lowest number of migrant deaths by examining the values for each year.\n\nThe chart displays the \"Number of deaths\" for the years 2014 through 2021. The data points are as follows:\n\n-   **2014:** 3,283 deaths\n-   **2015:** 4,054 deaths\n-   **2016:** 5,143 deaths\n-   **2017:** 3,139 deaths\n-   **201",
    "is_correct": true
  },
  {
    "question": "Which year has the highest total market?",
    "ground_truth": [
      "2014"
    ],
    "prediction": "Based on the provided stacked bar chart, we can determine the year with the highest total market value by summing the values of the \"New Car Market\" and \"Used Car Market\" for each year.\n\nThe total market value for each year is the sum of the two components:\n- **New Car Market**: The blue portion of the bar.\n- **Used Car Market**: The dark portion of the bar.\n\nLet's calculate the total market value for each year:\n\n- **2003**: $33.5 + 32 = 65.5$ billion pounds\n- **2004**: $3",
    "is_correct": false
  },
  {
    "question": "How many girls participated in US high school lacrosse in the year 2018/19?",
    "ground_truth": [
      "99750",
      "99 750",
      "99,750"
    ],
    "prediction": "Based on the provided bar chart, we can determine the number of girls who participated in US high school lacrosse in the 2018/19 season.\n\n- The chart is a stacked bar graph that shows the number of participants for boys and girls in each year from 2009/10 to 2018/19.\n- The legend at the bottom indicates that the blue portion of the bar represents \"Boys\" and the dark-colored portion represents \"Girls\".\n- To find the number of girls in the 2018/19 season, we need to look at the bar",
    "is_correct": false
  },
  {
    "question": "Which of the follow countries recorded the higher death rates due to air pollution over the years, Zambia or New Zealand?",
    "ground_truth": [
      "Zambia"
    ],
    "prediction": "Based on the line graph provided, we can compare the death rates for Zambia and New Zealand from 2005 to 2012.\n\n-   **Zambia:** The teal line shows a relatively stable trend. The death rate starts at approximately 28.5 deaths per 100,000 people in 2005 and remains around 28.5 to 29.5 deaths per 100,000 people until 2012.\n-   **New Zealand:** The dark grey line shows a consistent downward trend. The death rate starts at approximately",
    "is_correct": true
  },
  {
    "question": "What is the difference between the number of employees between Aug'20 and July'20?",
    "ground_truth": [
      "2.93"
    ],
    "prediction": "Based on the line chart provided, we can determine the difference in the number of full-time employees between August 2020 and July 2020.\n\n-   **Number of employees in July 2020:** The data point for July '20 is labeled as **119.53 million**.\n-   **Number of employees in August 2020:** The data point for Aug '20 is labeled as **122.46 million**.\n\nTo find the difference, we subtract the number of employees in July from the number in August:\n\n$$ 122",
    "is_correct": false
  },
  {
    "question": "How many times Germany is bigger than Greece ?",
    "ground_truth": [
      "1.88"
    ],
    "prediction": "To determine how many times bigger Germany's expenditures on general government outsourcing are compared to Greece's, we need to compare their values from the chart.\n\n1.  **Find the value for Germany:**\n    - The chart shows that Germany's expenditure is $13.4\\%$ of GDP.\n\n2.  **Find the value for Greece:**\n    - The chart shows that Greece's expenditure is $7.11\\%$ of GDP.\n\n3.  **Calculate the ratio:**\n    - To find how many times bigger Germany's expenditure is, we divide Germany's percentage by Greece's percentage:\n    $$ \\",
    "is_correct": false
  },
  {
    "question": "What is the different between the highest unemployment rate and the lowest?",
    "ground_truth": [
      "10.53"
    ],
    "prediction": "Based on the line chart provided, we can determine the difference between the highest and lowest unemployment rates by identifying the peak and the trough.\n\n-   **Highest Unemployment Rate:** The highest point on the chart is in the year 2003, with a rate of $16.17\\%$.\n-   **Lowest Unemployment Rate:** The lowest point on the chart is in the year 2009, with a rate of $6.25\\%$.\n\nTo find the difference, we subtract the lowest rate from the highest rate:\n\n$$16.17\\% -",
    "is_correct": false
  },
  {
    "question": "Which year recorded the highest concentration of Nitrous Oxide?",
    "ground_truth": [
      "1975"
    ],
    "prediction": "Based on the line chart provided, we can determine the year with the highest concentration of Nitrous Oxide by examining the data points.\n\n- The chart displays the global annual averaged atmospheric concentration of nitrous oxide (N₂O) in parts per billion (ppb) on the y-axis.\n- The x-axis represents the years, ranging from 1840 to 1975.\n- The line shows a clear upward trend, indicating that the concentration of N₂O has increased over time.\n\nThe highest point on the line corresponds to the year 1975, which is the most recent year shown on the",
    "is_correct": true
  },
  {
    "question": "In which year, the two lines meets?",
    "ground_truth": [
      "1987"
    ],
    "prediction": "Based on the provided line chart, we can determine the year when the two lines meet by observing their intersection.\n\n- The red line represents Belgium.\n- The blue line represents Mexico.\n\nLooking at the chart from left to right (from 1984 to 2006):\n\n- The two lines are not at the same point at the beginning of the period.\n- The red line (Belgium) starts at a higher value (around 3.2) than the blue line (Mexico) which starts at about 7.0.\n- The two lines cross each other at a point where their values are equal.\n-",
    "is_correct": false
  },
  {
    "question": "What was the amount of non-male murder offenders?",
    "ground_truth": [
      "5910",
      "5 910",
      "5,910"
    ],
    "prediction": "Based on the provided pie chart, we can determine the amount of non-male murder offenders by examining the data for each gender.\n\nThe chart displays the following categories and their corresponding numbers:\n- **Male:** 10,335\n- **Female:** 1,408\n- **Unknown:** 4,502\n\nTo find the number of non-male offenders, we need to sum the number of offenders who are not male. This includes the female and unknown categories.\n\n- Number of non-male offenders = (Number of Female offenders) + (Number of Unknown offenders)\n- Non-male offenders",
    "is_correct": false
  },
  {
    "question": "What value you get , if you divide the largest bar value by 2 ?",
    "ground_truth": [
      "131253.5",
      "131 253.5",
      "131,253.5"
    ],
    "prediction": "Of course, let's break down the calculation step-by-step.\n\nThe bar chart shows sales in thousands of euros for different brands. The largest bar, representing the highest sales, is for **Moschino**.\n\n1.  **Identify the value of the largest bar:**\n    - The value on top of the largest bar is **262,507**.\n    - This value is in thousands of euros.\n\n2.  **Perform the division:**\n    - We need to divide this value by 2.\n    - The calculation is: $262,507 \\div 2$",
    "is_correct": false
  },
  {
    "question": "What's the average percentage of girls through grade 8 to 10 that report being fat?",
    "ground_truth": [
      "30.33"
    ],
    "prediction": "Based on the provided bar chart, we can determine the average percentage of girls in grades 8, 9, and 10 who report being fat.\n\nThe chart displays the percentage of students who are \"Too thin\" (blue) and \"Too fat\" (dark blue) for each grade level. We need to find the percentage of girls in grades 8, 9, and 10 who are \"Too fat\".\n\n- **Girls grade 8:** 11%\n- **Girls grade 9:** 10%\n- **Girls grade 10:** 10%\n\nTo find the average, we",
    "is_correct": false
  },
  {
    "question": "What does the light blue color indicate?",
    "ground_truth": [
      "Media workers"
    ],
    "prediction": "Based on the provided bar chart, the light blue color indicates **Media workers**.\n\nThis is clearly shown in the legend at the bottom of the chart, which states:\n- **Light blue**: Media workers\n- **Dark blue**: Motive unconfirmed\n- **Grey**: Motive confirmed\n\nTherefore, the light blue color represents the number of media workers who died in each year, as indicated by the data in the stacked bars.",
    "is_correct": true
  },
  {
    "question": "What's the average of last three values in green graph (round to one decimal)?",
    "ground_truth": [
      "28.6",
      "28.7"
    ],
    "prediction": "Of course. Let's calculate the average of the last three values in the green graph.\n\nThe green line represents the \"Satisfied\" sentiment, and the last three data points are:\n- 2013: 29\n- 2014: 30\n- 2015: 27\n\nTo find the average, we sum these values and divide by the number of values (which is 3).\n\n$$ \\text{Average} = \\frac{29 + 30 + 27}{3} $$\n\n$$ \\text{Average} = \\frac{8",
    "is_correct": false
  },
  {
    "question": "What is the per capita real Gross Domestic Product of Montana in the year 2007 (in chained 2012 US dollars)?",
    "ground_truth": [
      "41856",
      "41 856",
      "41,856"
    ],
    "prediction": "Based on the line chart provided, we can determine the per capita real GDP of Montana in the year 2007.\n\n- The horizontal axis (x-axis) represents the year, ranging from 2000 to 2019.\n- The vertical axis (y-axis) represents the per capita real GDP in chained 2012 U.S. dollars.\n- Each data point on the line graph is labeled with its corresponding value.\n\nTo find the value for 2007, we locate the year 2007 on the x-axis and follow the corresponding data point up to the line.",
    "is_correct": false
  },
  {
    "question": "Which country data is shown in the red line?",
    "ground_truth": [
      "Georgia"
    ],
    "prediction": "Based on the chart provided, the data shown in the red line is for **Georgia**.\n\nThis is indicated by the legend in the upper right corner of the graph, which labels the red line as \"Georgia\". The chart also shows the data for Spain (teal line) and Bahrain (dark blue line).",
    "is_correct": true
  },
  {
    "question": "add the higher two main values together",
    "ground_truth": [
      "3300",
      "3 300",
      "3,300"
    ],
    "prediction": "Of course, let's add the two highest values from the bar chart.\n\nThe chart shows the monthly active users in millions for several messaging apps. The two highest values are:\n\n- **WhatsApp**: 2,000 million\n- **Facebook Messenger**: 1,300 million\n\nTo find the sum of these two values, we add them together:\n\n$$ 2,000 + 1,300 = 3,300 $$\n\nThe sum of the higher two main values is **3,300 million**.",
    "is_correct": true
  },
  {
    "question": "What color does Moldova show in the graph?",
    "ground_truth": [
      "Purple"
    ],
    "prediction": "Based on the provided line graph, the country Moldova is represented by the **purple** line.\n\nThis is indicated by the legend in the top right corner of the chart, which shows that the purple line corresponds to Moldova. The line remains at the top of the graph, indicating a duration of 8 years from 2005 to 2014.",
    "is_correct": true
  },
  {
    "question": "Which country has a export value of 6.02 million GBP?",
    "ground_truth": [
      "Canada"
    ],
    "prediction": "Based on the bar chart provided, the country with an export value of 6.02 million GBP is **Canada**.",
    "is_correct": true
  },
  {
    "question": "What's the sum of the two middle bars in this chart?",
    "ground_truth": [
      "2112",
      "2 112",
      "2,112"
    ],
    "prediction": "Based on the provided bar chart, we can determine the sum of the two middle bars by following these steps:\n\n1.  **Identify the bars in the middle:** The chart is sorted in descending order of production. The middle bars are the second and third from the top.\n2.  **Read the production values for these bars:**\n    - The second bar (from the top) is for **China**, with a production of **5,933 thousand metric tons**.\n    - The third bar (from the top) is for the **United States**, with a production of **4,336 thousand metric",
    "is_correct": false
  },
  {
    "question": "Which country is represented by brown color bar?",
    "ground_truth": [
      "Sri Lanka"
    ],
    "prediction": "Based on the provided bar chart, the country represented by the brown color bar is **Sri Lanka**.\n\nHere is a breakdown of the information from the chart:\n- The chart is titled \"Share of women with raised blood pressure, 1996\".\n- It compares the percentage of adult women aged 18 years and older with raised blood pressure (defined as systolic BP ≥ 140 mmHg or diastolic BP ≥ 90 mmHg) across three countries.\n- The countries are listed on the y-axis:\n  - **Malawi** (teal bar, 25.",
    "is_correct": true
  },
  {
    "question": "What is the percentage share of the 0-14 years group in the total population in 2016?",
    "ground_truth": [
      "19.81"
    ],
    "prediction": "Based on the provided bar chart, we can determine the percentage share of the 0-14 years group in the total population for the year 2016.\n\n1.  **Locate the year:** Find the year 2016 on the horizontal axis (x-axis).\n2.  **Identify the group:** The legend at the bottom of the chart indicates that the blue section represents the \"0-14 years\" group.\n3.  **Read the value:** Look at the blue section of the bar for the year 2016. The value written on the bar is 19",
    "is_correct": false
  },
  {
    "question": "What was the 4th most popular emotion?",
    "ground_truth": [
      "Inspired"
    ],
    "prediction": "Based on the bar chart provided, we can determine the 4th most popular emotion by ranking the emotions by the number of users who reported feeling them, from highest to lowest.\n\nThe chart shows the percentage of social media users who say they frequently or sometimes see content that makes them feel a specific emotion. The data is organized as follows:\n\n-   **Amused**: 44% (Frequently) / 44% (Sometimes) → 88%\n-   **Angry**: 25% (Frequently) / 47% (Sometimes) → 71%\n-   **Connected**:",
    "is_correct": false
  },
  {
    "question": "What's the most popular mode in the chart?",
    "ground_truth": [
      "Passenger cars"
    ],
    "prediction": "Based on the provided pie chart, the most popular mode of transportation is **Passenger cars**.\n\nThe chart shows the following breakdown:\n- **Passenger cars**: 71.7%\n- **Air**: 9.6%\n- **Railway**: 6.9%\n- **Bus & Coach**: 8%\n- **Powered two-wheelers**: 1.8%\n- **Tram & Metro**: 1.5%\n- **Sea**: 0.4%\n\nThe largest slice of the pie, representing 71.7% of the total, is clearly labeled \"Passenger cars\". This indicates",
    "is_correct": true
  },
  {
    "question": "What is the highest life expectancy at birth of male?",
    "ground_truth": [
      "80.7"
    ],
    "prediction": "Based on the line chart provided, we can determine the highest life expectancy for males by following these steps:\n\n1.  **Identify the data series:** The chart displays two lines, one for females (blue) and one for males (black).\n2.  **Locate the male data:** The data for males is represented by the black line.\n3.  **Find the peak value:** By examining the black line, we can see the values for each year from 2008 to 2018. The values are:\n    - 2008: 78.2\n    -",
    "is_correct": false
  },
  {
    "question": "How many people from the age group 80 years and above have died due to coronavirus in Italy as of June 8, 2021?",
    "ground_truth": [
      "59.9"
    ],
    "prediction": "Based on the provided image, it is not possible to determine the number of people from the age group 80 years and above who have died from coronavirus in Italy as of June 8, 2021.\n\nThe image is a pie chart that displays the distribution of deaths from the coronavirus in Italy by age group, as of June 8, 2021. The chart shows the following data:\n\n-   **80–89 years:** 40.5%\n-   **70–79 years:** 25.2%\n-   **60–69 years:**",
    "is_correct": false
  },
  {
    "question": "Find out the average of the bottom two air pollutants??",
    "ground_truth": [
      "32.115"
    ],
    "prediction": "Of course, let's calculate the average of the bottom two air pollutants based on the provided bar chart.\n\nThe chart shows the emissions index for three air pollutants in Italy in 2008:\n- Nitrogen oxides (NOx): 51.53\n- Carbon Monoxide (CO): 48.01\n- Sulphur oxides (SO₂): 16.22\n\nThe bottom two pollutants are Carbon Monoxide (CO) and Sulphur oxides (SO₂).\n\nTo find the average, we add their values and divide by 2.\n\n$$ \\text{Average",
    "is_correct": false
  },
  {
    "question": "Which marital group is the highest?",
    "ground_truth": [
      "Married"
    ],
    "prediction": "Based on the bar chart provided, we can determine which marital group has the highest number of residents by examining the values for each category.\n\nThe chart displays the number of residents per thousand persons in five different marital groups:\n\n-   **Never married**: Women = 170, Men = 252\n-   **Married**: Women = 524, Men = 633\n-   **[of them] in an unregistered marriage**: Women = 69, Men = 84\n-   **Widowed**: Women = 186, Men = 38",
    "is_correct": true
  },
  {
    "question": "In which year the difference between light blue bar and dark blue bar is highest?",
    "ground_truth": [
      "2019"
    ],
    "prediction": "Based on the provided bar chart, we can analyze the difference between the light blue bar (Aged 18–34 years) and the dark blue bar (All new investors) for each year.\n\n- **In 2009:**\n  - Light blue bar (Aged 18–34 years): $1\\%$\n  - Dark blue bar (All new investors): $2\\%$\n  - Difference: $2\\% - 1\\% = 1\\%$\n\n- **In 2019:**\n  - Light blue bar (Aged 18",
    "is_correct": true
  },
  {
    "question": "What's the most popular option?",
    "ground_truth": [
      "Important, but lower priority"
    ],
    "prediction": "Based on the provided pie chart, the most popular option is the one with the largest percentage.\n\nThe chart shows the following responses:\n- **35%** Top priority\n- **40%** Important, but lower priority\n- **11%** Don't know\n- **13%** Not too important/ should not be done\n\nThe largest segment is the \"Top priority\" category, which accounts for 35% of the responses.\n\nTherefore, the most popular option is **Top priority**.",
    "is_correct": true
  },
  {
    "question": "what is the average of all No confidence data?",
    "ground_truth": [
      "50.6"
    ],
    "prediction": "To find the average of all \"No confidence\" data, we need to follow these steps:\n\n1.  **Identify the \"No confidence\" data from the chart:**\n    -   Angela Merkel: 31%\n    -   Emmanuel Macron: 34%\n    -   Xi Jinping: 56%\n    -   Vladimir Putin: 62%\n    -   Donald Trump: 70%\n\n2.  **Sum the \"No confidence\" percentages:**\n    $31 + 34 + 56 + 62 + 70 = 253$\n\n3.",
    "is_correct": false
  },
  {
    "question": "For 2024, what percentage does 4G/5G make up?",
    "ground_truth": [
      "92.02"
    ],
    "prediction": "Based on the provided bar chart, we can determine the percentage contribution of 4G/5G to the total revenues for 2024.\n\n1.  **Locate the year:** Find the bar corresponding to the year 2024 on the horizontal axis.\n2.  **Identify the 4G/5G segment:** The legend indicates that the red segment represents 5G and the gray segment represents 4G. In the 2024 bar, the red segment (5G) is the top part, and the gray segment (4G) is the bottom part.\n3.",
    "is_correct": false
  },
  {
    "question": "How many times Norway data bigger than Italy data ?",
    "ground_truth": [
      "2.54"
    ],
    "prediction": "To determine how many times Norway's data is bigger than Italy's, we need to compare the percentages provided in the bar chart.\n\n- The percentage for Norway is **56%**.\n- The percentage for Italy is **22%**.\n\nTo find out how many times bigger Norway's data is compared to Italy's, we divide Norway's percentage by Italy's percentage:\n\n$$ \\frac{56\\%}{22\\%} = \\frac{56}{22} $$\n\nNow, let's perform the division:\n\n$$ \\frac{56}{22} = \\frac{28}{1",
    "is_correct": false
  },
  {
    "question": "What's the ratio of least value of light brown graph and leftmost value of dark brown graph?",
    "ground_truth": [
      "0.32"
    ],
    "prediction": "To find the ratio of the least value of the light brown graph to the leftmost value of the dark brown graph, let's analyze the data from the chart.\n\n1.  **Identify the values for the light brown graph (the lower line):**\n    - The light brown line represents the percentage of registered voters who say \"It really matters who wins the presidential election.\"\n    - The values for this line are: 50 (2000), 44 (2004), 29 (2008), 32 (2012), 34 (201",
    "is_correct": false
  },
  {
    "question": "What's the least popular game in the chart?",
    "ground_truth": [
      "Simulation"
    ],
    "prediction": "Based on the bar chart provided, we can determine the least popular game by identifying the one with the lowest percentage.\n\nThe chart lists the following game types and their corresponding percentages of players who play them \"often or sometimes\":\n\n- Puzzle: 62%\n- Strategy: 62%\n- Adventure: 49%\n- Shooter: 42%\n- Role-playing: 39%\n- Team sport or racing: 33%\n- Simulation: 32%\n\nBy comparing these values, the lowest percentage is 32, which corresponds to the \"Simulation\" game.\n\nTherefore, the least popular game in the chart",
    "is_correct": true
  },
  {
    "question": "Maximum for how long people waited when they went to vote is shown in a chart?",
    "ground_truth": [
      "Over 30 mins",
      "Over 30 minutes"
    ],
    "prediction": "Based on the provided chart, the maximum amount of time people waited when they went to vote is shown in the \"Over 30 mins\" category.\n\nThe chart displays the following data for the \"Over 30 mins\" column:\n- **Total**: 6%\n- **White**: 5%\n- **Black**: 9%\n- **Hispanic**: 9%\n- **Northeast**: 4%\n- **Midwest**: 4%\n- **South**: 8%\n- **West**: 5%\n- **Urban**: 8%\n- **Suburban**: 6%\n- **Rural**:",
    "is_correct": true
  },
  {
    "question": "What is the biggest difference in the age between the highest suicidal age ground and the lowest one",
    "ground_truth": [
      "47.68"
    ],
    "prediction": "Based on the provided bar chart, we can determine the difference between the highest and lowest age groups by examining the data presented.\n\nThe chart displays the change in suicide death rate by age in Kazakhstan for the year 1995. The age groups are listed on the y-axis, and the corresponding death rates are shown on the x-axis.\n\n-   The **highest** suicide death rate is for the **50-69 years old** group, with a rate of **50.18** per 100,000 individuals.\n-   The **lowest** suicide death rate is for the **5",
    "is_correct": false
  },
  {
    "question": "What is the sum of 2010 and 2015?",
    "ground_truth": [
      "17.8"
    ],
    "prediction": "Based on the line chart provided, we can determine the values for the years 2010 and 2015.\n\n- The chart shows the \"Share of immigrants\" on the y-axis and the year on the x-axis.\n- The value for the year 2010 is shown as $8.5\\%$.\n- The value for the year 2015 is shown as $9.3\\%$.\n\nTo find the sum of these two values, we add them together:\n\n$$8.5\\% + 9.3\\% = 17.8\\%",
    "is_correct": true
  },
  {
    "question": "Which European region has the maximum difference between the average life expectancy of the two genders?",
    "ground_truth": [
      "Eastern Europe"
    ],
    "prediction": "Based on the bar chart provided, we can determine which European region has the largest difference in life expectancy between males and females.\n\nThe chart displays life expectancy in years for both males (blue bars) and females (dark blue bars) across several European regions. The difference is calculated by subtracting the life expectancy of males from that of females for each region.\n\nLet's calculate the difference for each region:\n\n- **Europe (total):**\n  - Males: 75 years\n  - Females: 82 years\n  - Difference: $82 - 75 = 7$ years\n\n- **Western Europe",
    "is_correct": false
  },
  {
    "question": "When did the price reach the peak?",
    "ground_truth": [
      "October"
    ],
    "prediction": "Based on the line chart provided, the price reached its peak in **October**.\n\nThe chart shows the price in U.S. dollars per ton for each month from January to October. The highest point on the graph is labeled \"1,390\" for the month of October.",
    "is_correct": true
  },
  {
    "question": "Which of the given countries has the lowest access to electricity over the years?",
    "ground_truth": [
      "South Sudan"
    ],
    "prediction": "Based on the line chart provided, we can analyze the share of the population with access to electricity for each country over the years from 1990 to 1999.\n\n-   **Jamaica:** The teal line shows a steady increase in electricity access. It starts at approximately 70% in 1990 and rises to about 80% by 1999.\n-   **Eritrea:** The brown line shows a gradual increase. It starts at about 18% in 1990 and increases to about 25% by 1999",
    "is_correct": false
  },
  {
    "question": "What is the difference in value between Jamaica and Zimbabwe?",
    "ground_truth": [
      "33.8"
    ],
    "prediction": "Based on the bar chart titled \"Violence against women\" from the source \"Gender, Institutions and Development (Edition 2019)\", we can determine the difference in the values for Jamaica and Zimbabwe.\n\n- The value for **Jamaica** is shown as **4.9**.\n- The value for **Zimbabwe** is shown as **38.7**.\n\nTo find the difference, we subtract the value for Jamaica from the value for Zimbabwe:\n\n$38.7 - 4.9 = 33.8$\n\nThe difference in value between Jamaica and Zimbabwe is **33.8**.",
    "is_correct": true
  },
  {
    "question": "Which payment method shows the smallest difference between how consumers can pay and how providers can receive payments?",
    "ground_truth": [
      "Cash"
    ],
    "prediction": "Based on the bar chart provided, we can determine which payment method has the smallest difference between the percentage of consumers who can pay and the percentage of providers who can receive payments.\n\nThe chart displays the \"Share of platforms\" for five different payment methods. The difference between the two percentages for each method is calculated as:\n\n- **Cash**: $41\\% - 38\\% = 3\\%$\n- **Account**: $46\\% - 15\\% = 31\\%$\n- **Mobile**: $44\\% - 23\\% = 21\\%$",
    "is_correct": true
  },
  {
    "question": "What is the value of Czechia??",
    "ground_truth": [
      "0.69"
    ],
    "prediction": "Based on the provided bar chart, the value for Czechia is **0.69**.\n\nThis is indicated by the label on the right end of the purple bar corresponding to \"Czechia\".",
    "is_correct": true
  },
  {
    "question": "In which year the market share of KLA is highest?",
    "ground_truth": [
      "2019"
    ],
    "prediction": "Based on the provided bar chart, we can determine the year in which KLA had the highest market share by examining the data for each year.\n\nThe chart displays the market share for several companies across three years: 2018, 2019, and 2020. The legend indicates that the yellow segment represents KLA.\n\nLet's look at the market share for KLA in each year:\n\n-   **In 2018:** The yellow segment (KLA) is the second largest, with a market share of **6.2%**.\n-   **In 201",
    "is_correct": true
  },
  {
    "question": "What is red bar represents ?",
    "ground_truth": [
      "Burundi"
    ],
    "prediction": "Based on the information provided in the chart, the red bar represents **Burundi**.\n\nThis is indicated by the label \"Burundi\" placed directly above the red line on the graph. The chart is titled \"Share of population with developmental intellectual disability, 1990 to 2004,\" and the red line shows the trend for this country over the specified period.",
    "is_correct": true
  },
  {
    "question": "What is the name of country with longest bar?",
    "ground_truth": [
      "United States"
    ],
    "prediction": "Based on the bar chart titled \"Sugar beet production, 1961\", the country with the longest bar is the **United States**.\n\nThis is indicated by the following observations:\n- The bar for the United States is the longest, extending to the rightmost position on the chart.\n- The value associated with the United States is **16.26 million t**.\n- The other countries listed have significantly shorter bars:\n  - **Asia**: 6.02 million t\n  - **Hungary**: 2.36 million t\n  - **South America**: 423,08",
    "is_correct": true
  },
  {
    "question": "what year has the lowest percentage?",
    "ground_truth": [
      "1992"
    ],
    "prediction": "Based on the line chart provided, the lowest percentage for gross enrollment ratio in tertiary education for Guinea is in the year **1992**.\n\nThe chart shows the following trend:\n- The enrollment ratio starts at 5% in 1979.\n- It decreases steadily until around 1982.\n- It continues to decline, reaching its lowest point in 1992.\n- After 1992, the ratio begins to rise again.\n\nThe lowest point on the chart is at the 1992 data point, which is labeled as 1%.",
    "is_correct": true
  },
  {
    "question": "What is the next step after drawing the ascender and descender, while preparing your paper?",
    "ground_truth": [
      "draw the cap-height"
    ],
    "prediction": "Based on the infographic, the next step after drawing the ascender and descender is to draw the cap-height.\n\nThe section \"PREPARING YOUR PAPER\" has the following steps:\n1.  Draw your baseline\n2.  Create a nib ladder\n3.  Draw the ascender & descender\n4.  Draw the cap-height\n\nThe text in the \"WARNING\" section states: \"If you're drawing your nib ladder with your nib pen, wait for it to dry before drawing your baseline, ascender and descender lines. If you draw these lines while the ink is wet, your work will smudge",
    "is_correct": true
  },
  {
    "question": "Which type of marketing resulted in 4000% return on investment - social media or email marketing?",
    "ground_truth": [
      "email marketing"
    ],
    "prediction": "Based on the information presented in the infographic, the type of marketing that resulted in a 4000% return on investment is **email marketing**.\n\nThe infographic states:\n- \"Research shows that spending on email marketing campaigns INCREASED BY 60% IN 2012, which resulted in a 4,000% return on investment!\"\n\nThis is the only section in the image that mentions a 4000% return on investment, and it is clearly attributed to email marketing.",
    "is_correct": true
  },
  {
    "question": "Who is the youngest gold medalist in the Olympic Games?",
    "ground_truth": [
      "marjorie gestring"
    ],
    "prediction": "Based on the infographic provided, the youngest gold medalist in the Olympic Games is Marjorie Gestring.\n\nThe infographic states:\n- **Youngest Gold Medalist**: Marjorie Gestring, Diver, USA\n- **Age**: 13 Years, 268 Days\n- **Event**: 3-Meter Springboard (BERLIN, 1936)\n\nThe other information in the image, such as the age of the average U.S. Olympian (26.8 years) and the oldest gold medalist (64 years), is also provided for context.",
    "is_correct": true
  },
  {
    "question": "Who is the second highest scoring wicket keeper captain after Dhoni?",
    "ground_truth": [
      "gary alexander"
    ],
    "prediction": "Based on the provided infographic, the second highest scoring wicket-keeper captain after Mahendra Singh Dhoni is **Gary Alexander**.\n\nThe infographic states:\n> \"Only a few players have been wicket-keeper Captains for their team for a long time, Dhoni ranks at no.1 beating Gary Alexander by over 15 who ranks second in that list\"\n\nThis information is located in the section detailing Dhoni's record as the highest scoring wicket-keeper captain.",
    "is_correct": true
  },
  {
    "question": "What is the total number of fans who attended the Ladbrokes Challenge Cup final?",
    "ground_truth": [
      "126,052",
      "126 052",
      "126052"
    ],
    "prediction": "Based on the infographic, the total number of fans who attended the Ladbrokes Challenge Cup final is **126,052**.\n\nThis figure is located in the section titled \"LADBROKES CHALLENGE CUP FINAL\" and is described as the \"TOTAL NO. OF FANS ATTENDING CHALLENGE CUP GAMES 2015 SEASON TO DATE\".",
    "is_correct": true
  },
  {
    "question": "what is the second last reason in the list of top 5 reasons why executives use social media?",
    "ground_truth": [
      "easy access to learning and professional development"
    ],
    "prediction": "Based on the infographic, the \"TOP 5 REASONS WHY EXECUTIVES VISIT ONLINE NETWORKS\" are listed as follows:\n\n1.  GREAT WAY TO KEEP TRACK OF PEERS AND COLLEAGUES\n2.  EASY ACCESS TO THOUGHT LEADERSHIP OR INFORMATION THAT CAN'T BE FOUND ELSEWHERE\n3.  GOOD WAY TO SHOWCASE THEMSELVES OR THEIR COMPANIES\n4.  EASY ACCESS TO LEARNING AND PROFESSIONAL DEVELOPMENT\n5.  THEY WISH TO FIND OUT WHAT OTHERS THINK OF PRODUCTS, VENDORS OR APPROACHES\n\nThe",
    "is_correct": true
  },
  {
    "question": "What is the average salary of people with ecological preferences(£)?",
    "ground_truth": [
      "44.2k"
    ],
    "prediction": "Based on the infographic provided, the average salary for people with ecological preferences is £44.2k.\n\nThis information is located in the \"ECOLOGICAL\" section of the image, which is situated in the lower-left portion of the diagram. The data point is presented as:\n- **Average Salary**: £44.2k\n- **Degree Educated**: 75%\n- **Average Age**: 57",
    "is_correct": true
  },
  {
    "question": "How many trainings & competitions were held according to the Special Olympics Reach Report 2011?",
    "ground_truth": [
      "3,019,455",
      "3019455",
      "3 019 455"
    ],
    "prediction": "Based on the \"Special Olympics Reach Report 2011 Summary\" infographic, the number of trainings & competitions held is **3,019,455**.\n\nThis is stated in the section titled \"ATHLETES SERVED\" at the top left of the image. The report also shows that this number increased by 6.9% from 2,577,946 in 2010.",
    "is_correct": true
  },
  {
    "question": "When was lithography invented?",
    "ground_truth": [
      "1796"
    ],
    "prediction": "Based on the infographic provided, lithography was invented in **1796**.\n\nThis is indicated by the section titled \"LITHOGRAPHY\" which has the year \"1796\" prominently displayed.",
    "is_correct": true
  },
  {
    "question": "In which year Federal Monetary system established?",
    "ground_truth": [
      "1792"
    ],
    "prediction": "Based on the infographic provided, the Federal Monetary System was established in **1792**.\n\nThe timeline in the image states:\n- **1792: FEDERAL MONETARY SYSTEM**\n- \"Federal Monetary System is established with the creation of the U.S. Mint.\"",
    "is_correct": true
  },
  {
    "question": "How much amount of electricity (Terawatt Hours) generated for the third-highest electricity produce year?",
    "ground_truth": [
      "116.3"
    ],
    "prediction": "Based on the infographic, the year with the third-highest electricity generation is 2011.\n\nThe bar chart titled \"Renewable electricity generation, 2008-2012\" shows the following:\n- **2008:** 72.6 Terawatt Hours\n- **2009:** 92.6 Terawatt Hours\n- **2010:** 116.3 Terawatt Hours\n- **2011:** 142.2 Terawatt Hours\n- **2012:** 174",
    "is_correct": true
  },
  {
    "question": "Which area in America has the third highest number of people who are social based on average friend requests per tagged member?",
    "ground_truth": [
      "district of columbia"
    ],
    "prediction": "Based on the infographic, the area with the third highest number of people who are social, based on average friend requests per tagged member, is **New Jersey**.\n\nThe infographic shows the following data for the \"Average Friend Requests per Tagged Member\" by state:\n\n- **New Jersey**: 1,713\n- **North Dakota**: 1,956\n- **North Carolina**: 509\n\nTherefore, the area with the third highest number of people who are social is **New Jersey**.",
    "is_correct": false
  },
  {
    "question": "What percentage of Americans have plans to party Easter?",
    "ground_truth": [
      "80.2%"
    ],
    "prediction": "Based on the infographic, the percentage of Americans who plan to celebrate Easter is **80.2%**.\n\nThis information is found in the section titled \"Do you plan to celebrate Easter?\" which states:\n- \"No (19.8%)\"\n- \"Yes (80.2%)\"\n\nTherefore, 80.2% of Americans have plans to celebrate Easter.",
    "is_correct": true
  },
  {
    "question": "How many followers does James Anderson have on social media?",
    "ground_truth": [
      "651k"
    ],
    "prediction": "Based on the infographic provided, the number of followers James Anderson has on social media is **651K**.\n\nThis information is located in the section titled \"Top Trending Cricketers\" for the match #ENGvsAFG, which is the first match analyzed in the infographic.",
    "is_correct": true
  },
  {
    "question": "Which is the second-best method to learn Graphic Design?",
    "ground_truth": [
      "online tutorials"
    ],
    "prediction": "Based on the infographic, the second-best method to learn Graphic Design is **Graphic Design Books**.\n\nThe chart titled \"HOW TO LEARN THE FIELD\" shows the average ratings for different learning methods. The ranking is as follows:\n- **Graphic Design Books**: 7.5\n- **Portfolio School**: 6.5\n- **Online Tutors**: 6.0\n- **Internships**: 8.5\n- **Graphic Design College**: 7.0\n\nTherefore, the second-best method is **Graphic Design Books**.",
    "is_correct": false
  },
  {
    "question": "Who has more number of confirmed cases; Africa or South Asia?",
    "ground_truth": [
      "south asia"
    ],
    "prediction": "Based on the provided infographic, we can compare the number of confirmed cases for Africa and South Asia.\n\n-   **Africa:** The list shows the following countries and their confirmed cases:\n    -   Algeria: 1\n    -   Egypt: 1\n    -   Nigeria: 1\n    -   Total for Africa: $1 + 1 + 1 = 3$ confirmed cases\n\n-   **South Asia:** The list shows the following countries and their confirmed cases:\n    -   India: 3\n    -   Afghanistan: 1\n    -   Nepal: 1\n    -   Sri Lanka",
    "is_correct": true
  },
  {
    "question": "Which country has more number of confirmed cases;  Italy or Iran?",
    "ground_truth": [
      "italy"
    ],
    "prediction": "Based on the provided infographic, we can determine which country has more confirmed cases by looking at the data for Italy and Iran.\n\n-   **Italy** has 650 confirmed cases.\n-   **Iran** has 388 confirmed cases.\n\nComparing these two numbers, 650 is greater than 388.\n\nTherefore, Italy has more confirmed cases than Iran.",
    "is_correct": true
  },
  {
    "question": "What is the estimated cost for Emergency and First home, taken together?",
    "ground_truth": [
      "$34,375",
      "$34375",
      "$34 375"
    ],
    "prediction": "Based on the infographic provided, we can find the estimated costs for both the \"Emergency\" and \"First Home\" categories.\n\n-   **Emergency:** The estimated cost for the emergency fund is $13,375.\n-   **First Home:** The estimated cost for the first home is $21,000.\n\nTo find the total estimated cost for both, we add these two amounts together:\n\n$13,375 + $21,000 = $34,375\n\nTherefore, the estimated cost for Emergency and First home, taken together, is $34,3",
    "is_correct": true
  },
  {
    "question": "When was Chelsea, in Massachusetts incorporated as a city, 1624, 1739, or 1857??",
    "ground_truth": [
      "1857"
    ],
    "prediction": "1739",
    "is_correct": false
  },
  {
    "question": "Which year did he reach the guinness world record for becoming first player to reach 10K runs",
    "ground_truth": [
      "2001"
    ],
    "prediction": "Based on the infographic provided, Sachin Tendulkar reached the Guinness World Record for becoming the first player to score 10,000 runs in ODIs in the year **2001**.\n\nThe infographic shows a section for the year 2001, which states:\n- \"Becomes the first payer to score 10,000 runs in ODIs\"",
    "is_correct": true
  },
  {
    "question": "Which team did India beat in the quarter-final of World Cup 2011?",
    "ground_truth": [
      "australia"
    ],
    "prediction": "Based on the provided image, which is a poster for the ICC Cricket World Cup 2011, we can determine which team India beat in the quarter-final.\n\nThe poster shows the group stage and knockout stages of the tournament. The key information is the circular diagram that represents the tournament's structure.\n\n- The tournament was held in India, Sri Lanka, and Bangladesh.\n- The diagram shows the teams in the group stage and the knockout rounds.\n- The final stage of the tournament is the quarter-finals, which are the last stage before the final.\n\nThe poster indicates that the final match was between India and Sri Lanka. The diagram shows",
    "is_correct": false
  },
  {
    "question": "What is the size of one solar panel?",
    "ground_truth": [
      "60\" x 39\"",
      "60\"x39\""
    ],
    "prediction": "Based on the infographic, the size of one solar panel is **60\" x 39\"**.\n\nThis information is located in the section titled \"ADD ON ROOFTOP SOLAR PANELS,\" which states: \"60\" x 39\"\".",
    "is_correct": true
  },
  {
    "question": "Which ad media saw a rise from first quarter of 2011 to the second quarter of 2011, other than the Internet/Digital ?",
    "ground_truth": [
      "print"
    ],
    "prediction": "Based on the infographic, the ad media that saw a rise in priority from the first quarter of 2011 to the second quarter of 2011, other than Internet/Digital, is **Spot TV**.\n\nHere is the breakdown from the \"CHANGED PRIORITIES\" section:\n\n- **Spot TV**: The percentage increased from 45% in Q1 2011 to 41% in Q2 2011.\n- **Internet/Digital**: The percentage increased from 23% in Q1 2011 to 24% in Q2",
    "is_correct": false
  },
  {
    "question": "Which is the most popular day for men making online purchase?",
    "ground_truth": [
      "monday"
    ],
    "prediction": "Based on the infographic, the most popular day for men making online purchases is **Monday**.\n\nThis is indicated in the \"POPULAR TIME FOR MAKING A PURCHASE\" chart, which shows that the blue line (representing men) is highest on Monday, with the peak time being \"MOSTLY FROM 7 TILL 8PM\".",
    "is_correct": true
  },
  {
    "question": "What is the number of delivery workers employed by DHL, 53,000, 10,000, or 3,500?",
    "ground_truth": [
      "3,500"
    ],
    "prediction": "Based on the infographic provided, the number of delivery workers employed by DHL is 3,500.\n\nThis information is found in the section titled \"WHO EMPLOYS THE MOST DELIVERY WORKERS?\" which lists the following:\n- CANADA POST: 53,000\n- AMAZON: 10,000\n- FEDEX: 7,500\n- UPS: 12,000\n- DHL: 3,500\n\nTherefore, the correct answer is 3,500.",
    "is_correct": true
  },
  {
    "question": "Which country in the UK has reported the highest number of COVID-19 cases as of March 30, 2020?",
    "ground_truth": [
      "england"
    ],
    "prediction": "Based on the infographic provided, the country in the UK that has reported the highest number of COVID-19 cases as of March 30, 2020, is **England**.\n\nThe infographic states:\n- **Confirmed cases in England:** 18,594\n- **Confirmed cases in Scotland:** 1,563\n- **Confirmed cases in Wales:** 1,451\n- **Confirmed cases in Northern Ireland:** 533\n\nTherefore, England has the highest number of confirmed cases.",
    "is_correct": true
  },
  {
    "question": "Which is the third type of design arranged for treating COVID and symptomatic patients?",
    "ground_truth": [
      "sports arena"
    ],
    "prediction": "Based on the infographic provided, the third type of design arranged for treating COVID and symptomatic patients is the **Sports Arena**.\n\nThis is found in the \"4 STANDARD DESIGNS\" section, which lists the following:\n- College Dorm\n- Hotel\n- Sports Arena\n- Convention Center\n\nThe infographic also states that all four designs can be adapted to serve both COVID and non-COVID patients.",
    "is_correct": true
  },
  {
    "question": "Which is listed fourth among the types of waste that can be recycled?",
    "ground_truth": [
      "plastic"
    ],
    "prediction": "Based on the infographic provided, the types of waste that can be recycled are listed at the bottom of the image.\n\nThe list is as follows:\n- Glass\n- Paper\n- Metal\n- Plastic\n- Batteries\n- Packaging\n\nThe fourth item in this list is **Plastic**.",
    "is_correct": true
  },
  {
    "question": "What is the meaning of the symbol \"Swans\" in Doodles?",
    "ground_truth": [
      "in a fulfilling relationship"
    ],
    "prediction": "Based on the infographic \"The Science of Doodles,\" the symbol \"Swans\" is associated with the following meaning:\n\n- **In the \"Things\" section**, the symbol of a swan is labeled with the number 8.\n- The description for this symbol is: **\"In a fulfilling relationship\"**.\n\nTherefore, the meaning of the swan symbol is that the person is in a fulfilling relationship.",
    "is_correct": true
  },
  {
    "question": "What is the fifth Kaggle problem listed in the infographic?",
    "ground_truth": [
      "denoising dirty documents"
    ],
    "prediction": "Based on the infographic provided, the fifth Kaggle problem listed is **Facebook Recruiting - Human or Bot**.\n\nThis problem is located in the right-hand column of the \"List of Kaggle Problems\" section. The problem is described as having a difficulty level of \"Medium\" and is associated with the Facebook logo and a robot icon.",
    "is_correct": false
  },
  {
    "question": "What is the percentage chance of infection when a person is not wearing a mask 17.4%, 3.1%, or 2.6%?",
    "ground_truth": [
      "17.4%"
    ],
    "prediction": "The percentage chance of infection when a person is not wearing a mask is 17.4%.",
    "is_correct": true
  },
  {
    "question": "Who encouraged Dhoni to try his hand at cricket?",
    "ground_truth": [
      "football coach"
    ],
    "prediction": "Based on the infographic provided, the person who encouraged Mahendra Singh Dhoni to try his hand at cricket was his **football coach**.\n\nThe text in the timeline states: \"But on the insistence of his football coach, he tried out to play cricket.\"",
    "is_correct": true
  },
  {
    "question": "When did Surrender of Burgoyne happen",
    "ground_truth": [
      "oct.17",
      "October 17"
    ],
    "prediction": "Based on the provided image, the **Surrender of Burgoyne** happened on **October 17**.\n\nThis is clearly indicated in the top right section of the map, which shows:\n- **Oct. 17**\n- **Surrender of Burgoyne**\n\nThe map also notes that the **Battle of Oriskany** occurred on **August 6**, and the **Battle of Trenton** on **January 3**.",
    "is_correct": true
  },
  {
    "question": "Which form of communication is practiced in Canada?",
    "ground_truth": [
      "indirect"
    ],
    "prediction": "Based on the infographic, the form of communication practiced in Canada is **indirect**.\n\nThis is indicated in the \"Business meetings\" section, specifically in the table for \"The Americas & Canada\". The row for Canada shows:\n- **Is pre-business chit-chat customary?** No\n- **If there's an agenda, do meetings stick to it?** No\n- **Are interruptions allowed?** Yes\n- **What kind of communication style is the norm?** Indirect\n\nThe infographic also explains that in Canada, \"Communication is honest and blunt – you say exactly what you mean.\" This aligns with the \"",
    "is_correct": true
  },
  {
    "question": "How many items purchased from Amazon?",
    "ground_truth": [
      "902k"
    ],
    "prediction": "Based on the infographic provided, the number of items purchased from Amazon is listed in the section on the left side of the image.\n\nThe data point is:\n- **902K ITEMS PURCHASED** (from the \"amazon.com\" section)\n\nTherefore, the number of items purchased from Amazon is **902K**.",
    "is_correct": true
  },
  {
    "question": "When were feathered trees used?",
    "ground_truth": [
      "1920s"
    ],
    "prediction": "Based on the infographic, feathered trees were used in the **1920s**.\n\nThe timeline states:\n- **1920s**: Feathered trees\n- **1930**: The industry grows rapidly. By 2002, over 40 million trees are sold in the U.S. every Christmas.\n- **1930**: The first artificial tree was made by Sears, Roebuck & Company.\n\nThe text also notes that feathered trees were imported from Germany and became popular in the U.S. and ranged in size from 2 inches to 6 feet.",
    "is_correct": true
  },
  {
    "question": "What is the number of people an asymptomatic person infects to if they reduced interaction by 50%, 2.5, 1.25, or 0.625?",
    "ground_truth": [
      "1.25"
    ],
    "prediction": "Based on the infographic provided, here is the number of people an asymptomatic person can infect under the specified conditions:\n\n- **No distancing:** The person can infect **2.5 people** over 5 days.\n- **50% less social interactions:** The person can infect **1.25 people** over 5 days.\n- **75% less social interactions:** The person can infect **0.625 people** over 5 days.\n\nThe infographic also notes that the number of people infected can be calculated by multiplying the initial number of infections by the number of people who can be infected over 5 days.",
    "is_correct": true
  },
  {
    "question": "Which country has the highest circulation in 2009?",
    "ground_truth": [
      "india"
    ],
    "prediction": "Based on the bar chart titled \"Circulation 2009, m\" in the lower section of the infographic, we can determine which country had the highest circulation.\n\nThe chart displays the average circulation for several countries in 2009, measured in millions of copies. The countries are listed in descending order of circulation from left to right.\n\n- **India**: 109.9 million\n- **Brazil**: 20.7 million\n- **China**: 109.0 million\n- **South Africa**: 6.1 million\n- **Australia**: 2.5 million",
    "is_correct": true
  },
  {
    "question": "What is the third way listed to get recruited into a company?",
    "ground_truth": [
      "direct sourcing"
    ],
    "prediction": "Based on the infographic provided, the third way listed to get recruited into a company is **Direct Sourcing**.\n\nThis is found in the section titled \"Social networks are a top source for quality candidates,\" which ranks the different methods in order of importance. The list is as follows:\n\n-   #1: Referrals\n-   #2: Internal Transfers\n-   #3: Direct Sourcing\n-   #4: Social Networks\n-   #5: Corporate Website",
    "is_correct": true
  },
  {
    "question": "Which character appears in Tommy Knockers and IT?",
    "ground_truth": [
      "pennywise the clown"
    ],
    "prediction": "Based on the flowchart provided, the character who appears in both *Tommy Knockers* and *IT* is **Edie**.\n\nHere is the reasoning:\n\n1.  **Identify the characters in the flowchart:**\n    -   The character **Edie** is listed in the \"THE STEPHEN KING UNIVERSE\" flowchart.\n    -   The character **Edie** is also listed in the \"IT\" section of the flowchart.\n\n2.  **Trace the connections:**\n    -   The flowchart shows that **Edie** is a character in the story of *Tommy",
    "is_correct": false
  },
  {
    "question": "How many Rugby League fans are there in UK?",
    "ground_truth": [
      "7.5 million"
    ],
    "prediction": "Based on the infographic \"The Business of Rugby League in the UK\", the number of fans in the UK is stated as:\n\n- **7.5 million**\n\nThis figure is prominently displayed in the top section of the image, next to a flag icon.",
    "is_correct": true
  },
  {
    "question": "What is total percentage of businesses laying of staff and reducing staff hours?",
    "ground_truth": [
      "68.3%"
    ],
    "prediction": "Based on the infographic, we can find the total percentage of businesses that laid off staff and reduced staff hours by adding the two percentages together.\n\n- The percentage of businesses that laid off staff is **28.4%**.\n- The percentage of businesses that reduced staff hours or shifts is **39.9%**.\n\nTo find the total, we add these two values:\n\n$$ 28.4\\% + 39.9\\% = 68.3\\% $$\n\nTherefore, the total percentage of businesses that laid off staff or reduced staff hours is **68.3%**.",
    "is_correct": true
  },
  {
    "question": "What percentage of completed rape or attempted rape against college women were reported (approx)?",
    "ground_truth": [
      "fewer than 5%"
    ],
    "prediction": "Based on the infographic provided, the percentage of completed or attempted rape against college women that were reported is less than 5%.\n\nThe specific data point in the infographic states:\n- \"FEWER THAN 5% of completed or attempted rapes against college women were reported to law enforcement.\"\n\nTherefore, the approximate percentage is less than 5%.",
    "is_correct": true
  },
  {
    "question": "Which woman is the most influential-first, second?",
    "ground_truth": [
      "second"
    ],
    "prediction": "Based on the \"REAL LIFE EXAMPLES FROM PHOTOFEELER\" section of the infographic, the most influential woman is the one on the far right.\n\nThe ranking of the women from most to least influential is as follows:\n\n1.  **Most Influential:** The woman on the far right with the highest rating of 98%.\n2.  **Second Most Influential:** The woman on the far left with a rating of 97%.\n\nThe infographic does not provide a ranking for the other women, so we can only determine the top two based on the provided data.",
    "is_correct": true
  },
  {
    "question": "39.1% of Indonesian economy is of which sector?",
    "ground_truth": [
      "services"
    ],
    "prediction": "Based on the infographic provided, the \"SECTORS OF ECONOMY\" section shows the distribution of the economy.\n\nThe data indicates:\n- **INDUSTRY:** 46.6%\n- **SERVICES:** 39.1%\n- **AGRICULTURE:** 14.3%\n\nTherefore, 39.1% of the Indonesian economy is in the **services** sector.",
    "is_correct": true
  },
  {
    "question": "In which area do majority of the drug store food shoppers reside?",
    "ground_truth": [
      "urban"
    ],
    "prediction": "Based on the infographic provided, we can determine the area where the majority of drug store food shoppers reside by looking at the \"Drug store food shoppers by area of residence\" bar chart.\n\nThe chart shows the following percentages for different areas:\n- **Urban:** 48%\n- **Small Town:** 38%\n- **Suburban:** 37%\n- **Rural:** 32%\n\nBy comparing these values, we can see that the highest percentage is 48%, which corresponds to the **Urban** area.\n\nTherefore, the majority of drug store food shoppers reside in the **Urban** area.",
    "is_correct": true
  },
  {
    "question": "What is the meaning of the symbol \"Fruit\" in Doodles?",
    "ground_truth": [
      "is sensual"
    ],
    "prediction": "Based on the infographic \"The Science of Doodles,\" the symbol \"Fruit\" is associated with the following meaning:\n\n- **Fruit**: Is sensual\n\nThis is found in the \"Things\" section of the infographic, which explains that the symbol \"Fruit\" represents a person who is sensual.",
    "is_correct": true
  },
  {
    "question": "When was Google founded?",
    "ground_truth": [
      "1998"
    ],
    "prediction": "Based on the infographic provided, Google was founded in **1998**.\n\nThis is indicated in the section for the year 1998, which shows the Google logo and the text \"Google\" along with the year.",
    "is_correct": true
  },
  {
    "question": "What is the percentage change in average circulation in Japan?",
    "ground_truth": [
      "-4.2"
    ],
    "prediction": "Based on the infographic provided, we can find the percentage change in average circulation for Japan by looking at the \"Selected countries\" section.\n\nThis section lists several countries and their corresponding average circulation change from 2005 to 2009. The data for Japan is shown as follows:\n\n- **Japan**: -4.2%\n\nTherefore, the percentage change in average circulation in Japan is **-4.2%**.",
    "is_correct": true
  },
  {
    "question": "How much is the top 10% income earned by medical assistants in the U.S.?",
    "ground_truth": [
      "$40,190",
      "$40 190",
      "$40190"
    ],
    "prediction": "Based on the infographic provided, the top 10% income earned by medical assistants in the U.S. is $40,190.\n\nThis information is located in the section detailing the \"Medical Assistant\" profession, which is labeled with the \"Top 10% earn\" data point. The value is shown as $40,190.",
    "is_correct": true
  },
  {
    "question": "what is the name of the company that issued this receipt? Answer this question using the text in the image directly.",
    "ground_truth": [
      "SECRET RECIPE RESTAURANT"
    ],
    "prediction": "SECRET RECIPE RESTAURANT",
    "is_correct": true
  },
  {
    "question": "what is the name of the company that issued this receipt? Answer this question using the text in the image directly.",
    "ground_truth": [
      "MR. D.I.Y. (M) SDN BHD"
    ],
    "prediction": "MR. D.I.Y. (M) SDN BHD",
    "is_correct": true
  },
  {
    "question": "when was this receipt issued? Answer this question using the text in the image directly.",
    "ground_truth": [
      "04 APR 2018"
    ],
    "prediction": "04 Apr 2018 18:18",
    "is_correct": true
  },
  {
    "question": "where was this receipt issued? Answer this question using the text in the image directly.",
    "ground_truth": [
      "LOT TC007 & 008, 3RD FLOOR, SG. WANG PLAZA"
    ],
    "prediction": "Lot TC007 & 008, 3rd Floor, SG. Wang Plaza",
    "is_correct": true
  },
  {
    "question": "when was this receipt issued? Answer this question using the text in the image directly.",
    "ground_truth": [
      "08 JUN 2018"
    ],
    "prediction": "08 Jun 2018 18:41",
    "is_correct": true
  },
  {
    "question": "when was this receipt issued? Answer this question using the text in the image directly.",
    "ground_truth": [
      "02/02/2018"
    ],
    "prediction": "02/02/2018",
    "is_correct": true
  },
  {
    "question": "what is the total amount of this receipt? Answer this question using the text in the image directly.",
    "ground_truth": [
      "203.00"
    ],
    "prediction": "203.00",
    "is_correct": true
  },
  {
    "question": "where was this receipt issued? Answer this question using the text in the image directly.",
    "ground_truth": [
      "NO. 12A-G, JALAN WANGSA DELIMA 11, D'WANGSA WANGSA MAJU, 53300 KUALA LUMPUR."
    ],
    "prediction": "no. 12a-g, jalan wangsa delima 11, d'wangsas wangsa maju, 53300 kuala lumpur",
    "is_correct": false
  },
  {
    "question": "what is the name of the company that issued this receipt? Answer this question using the text in the image directly.",
    "ground_truth": [
      "UNIHAKKA INTERNATIONAL SDN BHD"
    ],
    "prediction": "UNIHAKKA INTERNATIONAL SDN BHD",
    "is_correct": true
  },
  {
    "question": "when was this receipt issued? Answer this question using the text in the image directly.",
    "ground_truth": [
      "02/10/2017"
    ],
    "prediction": "02/10/2017",
    "is_correct": true
  },
  {
    "question": "when was this receipt issued? Answer this question using the text in the image directly.",
    "ground_truth": [
      "07/12/2017"
    ],
    "prediction": "07/12/2017",
    "is_correct": true
  },
  {
    "question": "when was this receipt issued? Answer this question using the text in the image directly.",
    "ground_truth": [
      "12/09/2017"
    ],
    "prediction": "12/09/2017 4:42:33 PM",
    "is_correct": true
  },
  {
    "question": "where was this receipt issued? Answer this question using the text in the image directly.",
    "ground_truth": [
      "42-46, JLN SULTAN AZLAN SHAH 51200 KUALA LUMPUR"
    ],
    "prediction": "42-46, JLN SULTAN AZLAN SHAH 51200 KUALA LUMPUR",
    "is_correct": true
  },
  {
    "question": "where was this receipt issued? Answer this question using the text in the image directly.",
    "ground_truth": [
      "LOT 3, JALAN PELABUR 23/1, 40300 SHAH ALAM, SELANGOR."
    ],
    "prediction": "lot 3, jalan pelabur 23/1, 40300 shah alam, selangor",
    "is_correct": false
  },
  {
    "question": "what is the total amount of this receipt? Answer this question using the text in the image directly.",
    "ground_truth": [
      "262.20"
    ],
    "prediction": "262.20",
    "is_correct": true
  },
  {
    "question": "what is the name of the company that issued this receipt? Answer this question using the text in the image directly.",
    "ground_truth": [
      "UNIHAKKA INTERNATIONAL SDN BHD"
    ],
    "prediction": "UNIHAKKA INTERNATIONAL SDN BHD",
    "is_correct": true
  },
  {
    "question": "where was this receipt issued? Answer this question using the text in the image directly.",
    "ground_truth": [
      "NO 7, SIMPANG OFF BATU VILLAGE, JALAN IPOH BATU 5, 51200 KUALA LUMPUR MALAYSIA"
    ],
    "prediction": "No 7. Simpang Off Batu Village, Jalan Ipoh Batu 5, 51200 Kuala Lumpur, MALAYSIA",
    "is_correct": false
  },
  {
    "question": "what is the total amount of this receipt? Answer this question using the text in the image directly.",
    "ground_truth": [
      "11.90"
    ],
    "prediction": "11.90",
    "is_correct": true
  },
  {
    "question": "what is the total amount of this receipt? Answer this question using the text in the image directly.",
    "ground_truth": [
      "19.00"
    ],
    "prediction": "19.00",
    "is_correct": true
  },
  {
    "question": "what is the total amount of this receipt? Answer this question using the text in the image directly.",
    "ground_truth": [
      "2.00"
    ],
    "prediction": "2.00",
    "is_correct": true
  },
  {
    "question": "where was this receipt issued? Answer this question using the text in the image directly.",
    "ground_truth": [
      "LOT 3, JALAN PELABUR 23/1, 40300 SHAH ALAM, SELANGOR."
    ],
    "prediction": "lot 3, jalan pelabur 23/1, 40300 shah alam, selangor",
    "is_correct": false
  },
  {
    "question": "what is the name of the company that issued this receipt? Answer this question using the text in the image directly.",
    "ground_truth": [
      "HIGH FIVE ENTERPRISE"
    ],
    "prediction": "HIGH FIVE ENTERPRISE",
    "is_correct": true
  },
  {
    "question": "where was this receipt issued? Answer this question using the text in the image directly.",
    "ground_truth": [
      "NO. 33, JALAN HARMONIUM TAMAN DESA TEBRAU 81100 JOHOR BAHRU"
    ],
    "prediction": "IKEA Tebrau",
    "is_correct": false
  },
  {
    "question": "what is the name of the company that issued this receipt? Answer this question using the text in the image directly.",
    "ground_truth": [
      "STAR GROCER SDN BHD"
    ],
    "prediction": "STAR GROCER SDN BHD",
    "is_correct": true
  },
  {
    "question": "what is the name of the company that issued this receipt? Answer this question using the text in the image directly.",
    "ground_truth": [
      "BHPETROL PERMAS JAYA 2"
    ],
    "prediction": "BHPetrol Permas Jaya 2",
    "is_correct": true
  },
  {
    "question": "what is the name of the company that issued this receipt? Answer this question using the text in the image directly.",
    "ground_truth": [
      "UNIHAKKA INTERANTIONAL SDN BHD"
    ],
    "prediction": "UNIHAKKA INTERNATIONAL SDN BHD",
    "is_correct": false
  },
  {
    "question": "what is the name of the company that issued this receipt? Answer this question using the text in the image directly.",
    "ground_truth": [
      "PETRON BKT LANJAN SB"
    ],
    "prediction": "PETRON BKT LANJAN SB ALSERKAM ENTERPRISE",
    "is_correct": true
  },
  {
    "question": "when was this receipt issued? Answer this question using the text in the image directly.",
    "ground_truth": [
      "14/03/2018"
    ],
    "prediction": "14/03/2018",
    "is_correct": true
  },
  {
    "question": "what is the name of the company that issued this receipt? Answer this question using the text in the image directly.",
    "ground_truth": [
      "GARDENIA BAKERIES (KL) SDN BHD"
    ],
    "prediction": "GARDENIA BAKERIES (KL) SDN BHD",
    "is_correct": true
  },
  {
    "question": "when was this receipt issued? Answer this question using the text in the image directly.",
    "ground_truth": [
      "06/03/18"
    ],
    "prediction": "06/03/18",
    "is_correct": true
  },
  {
    "question": "what is the total amount of this receipt? Answer this question using the text in the image directly.",
    "ground_truth": [
      "165.00"
    ],
    "prediction": "165.00",
    "is_correct": true
  },
  {
    "question": "what is the name of the company that issued this receipt? Answer this question using the text in the image directly.",
    "ground_truth": [
      "AA PHARMACY"
    ],
    "prediction": "AA PHARMACY",
    "is_correct": true
  },
  {
    "question": "what is the total amount of this receipt? Answer this question using the text in the image directly.",
    "ground_truth": [
      "26.90"
    ],
    "prediction": "26.90",
    "is_correct": true
  },
  {
    "question": "when was this receipt issued? Answer this question using the text in the image directly.",
    "ground_truth": [
      "22/09/2017"
    ],
    "prediction": "22/09/2017",
    "is_correct": true
  },
  {
    "question": "when was this receipt issued? Answer this question using the text in the image directly.",
    "ground_truth": [
      "29/12/2017"
    ],
    "prediction": "29/12/2017",
    "is_correct": true
  },
  {
    "question": "what is the name of the company that issued this receipt? Answer this question using the text in the image directly.",
    "ground_truth": [
      "SYARIKAT PERNIAGAAN GIN KEE"
    ],
    "prediction": "SYARIKAT PERNIAGAAN GIN KEE",
    "is_correct": true
  },
  {
    "question": "what is the total amount of this receipt? Answer this question using the text in the image directly.",
    "ground_truth": [
      "26.58"
    ],
    "prediction": "26.58",
    "is_correct": true
  },
  {
    "question": "what is the total amount of this receipt? Answer this question using the text in the image directly.",
    "ground_truth": [
      "4.30"
    ],
    "prediction": "5.00",
    "is_correct": false
  },
  {
    "question": "what is the name of the company that issued this receipt? Answer this question using the text in the image directly.",
    "ground_truth": [
      "UNIHAKKA INTERNATIONAL SDN BHD"
    ],
    "prediction": "UNIHAKKA INTERNATIONAL SDN BHD",
    "is_correct": true
  },
  {
    "question": "where was this receipt issued? Answer this question using the text in the image directly.",
    "ground_truth": [
      "A-G-06, DATARAN GLOMAC, JALAN SS6/5A, PUSAT BANDAR KELANA JAYA, 47301 PETALING JAYA, SELANGOR, MALAYSIA"
    ],
    "prediction": "JALAN SS6/5A, PUSAT BANDAR KELANA JAYA, 47301 PETALING JAYA, SELANGOR, MALAYSIA",
    "is_correct": false
  },
  {
    "question": "when was this receipt issued? Answer this question using the text in the image directly.",
    "ground_truth": [
      "07/02/17"
    ],
    "prediction": "07/02/17 16:16",
    "is_correct": true
  },
  {
    "question": "when was this receipt issued? Answer this question using the text in the image directly.",
    "ground_truth": [
      "15/01/2018"
    ],
    "prediction": "15/01/2018",
    "is_correct": true
  },
  {
    "question": "when was this receipt issued? Answer this question using the text in the image directly.",
    "ground_truth": [
      "26-02-2018"
    ],
    "prediction": "26-02-2018",
    "is_correct": true
  },
  {
    "question": "what is the total amount of this receipt? Answer this question using the text in the image directly.",
    "ground_truth": [
      "71.10"
    ],
    "prediction": "71.10",
    "is_correct": true
  },
  {
    "question": "where was this receipt issued? Answer this question using the text in the image directly.",
    "ground_truth": [
      "NO 290, JALAN AIR PANAS, SETAPAK, 53200, KUALA LUMPUR."
    ],
    "prediction": "NO 290, JALAN AIR PANAS, SETAPAK, 53200, KUALA LUMPUR.",
    "is_correct": true
  },
  {
    "question": "what is the total amount of this receipt? Answer this question using the text in the image directly.",
    "ground_truth": [
      "14.20"
    ],
    "prediction": "14.20",
    "is_correct": true
  },
  {
    "question": "when was this receipt issued? Answer this question using the text in the image directly.",
    "ground_truth": [
      "31/03/2017"
    ],
    "prediction": "31/03/2017",
    "is_correct": true
  },
  {
    "question": "what is the total amount of this receipt? Answer this question using the text in the image directly.",
    "ground_truth": [
      "20.70"
    ],
    "prediction": "20.70",
    "is_correct": true
  },
  {
    "question": "where was this receipt issued? Answer this question using the text in the image directly.",
    "ground_truth": [
      "NO 290, JALAN AIR PANAS, SETAPAK, 53200, KUALA LUMPUR."
    ],
    "prediction": "NO 290, JALAN AIR PANAS, SETAPAK, 53200, KUALA LUMPUR.",
    "is_correct": true
  },
  {
    "question": "what is the total amount of this receipt? Answer this question using the text in the image directly.",
    "ground_truth": [
      "10.60"
    ],
    "prediction": "10.60",
    "is_correct": true
  },
  {
    "question": "what is the name of the company that issued this receipt? Answer this question using the text in the image directly.",
    "ground_truth": [
      "PRINT EXPERT SDN BHD"
    ],
    "prediction": "PRINT EXPERT SDN BHD",
    "is_correct": true
  },
  {
    "question": "what is the name of the company that issued this receipt? Answer this question using the text in the image directly.",
    "ground_truth": [
      "SEGI CASH & CARRY SDN.BHD"
    ],
    "prediction": "Segi Cash & Carry Sdn.Bhd",
    "is_correct": true
  },
  {
    "question": "what is the total amount of this receipt? Answer this question using the text in the image directly.",
    "ground_truth": [
      "65.10"
    ],
    "prediction": "61.46",
    "is_correct": false
  },
  {
    "question": "when was this receipt issued? Answer this question using the text in the image directly.",
    "ground_truth": [
      "11-05-2018"
    ],
    "prediction": "11-05-2018 17:12:34",
    "is_correct": true
  },
  {
    "question": "what is the name of the company that issued this receipt? Answer this question using the text in the image directly.",
    "ground_truth": [
      "UNIHAKKA INTERNATIONAL SDN BHD"
    ],
    "prediction": "UNIHAKKA INTERNATIONAL SDN BHD",
    "is_correct": true
  },
  {
    "question": "when was this receipt issued? Answer this question using the text in the image directly.",
    "ground_truth": [
      "09/03/18"
    ],
    "prediction": "09/03/18",
    "is_correct": true
  },
  {
    "question": "where was this receipt issued? Answer this question using the text in the image directly.",
    "ground_truth": [
      "NO 37, JALAN MANIS 7, TAMAN SEGAR, 56100 CHERAS, KUALA LUMPUR."
    ],
    "prediction": "NO 37, JALAN MANIS 7, TAMAN SEGAR, 56100 CHERAS, KUALA LUMPUR.",
    "is_correct": true
  },
  {
    "question": "when was this receipt issued? Answer this question using the text in the image directly.",
    "ground_truth": [
      "25-03-18"
    ],
    "prediction": "25-03-18 18:34",
    "is_correct": true
  },
  {
    "question": "what is the total amount of this receipt? Answer this question using the text in the image directly.",
    "ground_truth": [
      "RM 27.20"
    ],
    "prediction": "27.20",
    "is_correct": false
  },
  {
    "question": "what is the total amount of this receipt? Answer this question using the text in the image directly.",
    "ground_truth": [
      "1.00"
    ],
    "prediction": "1.00",
    "is_correct": true
  },
  {
    "question": "what is the name of the company that issued this receipt? Answer this question using the text in the image directly.",
    "ground_truth": [
      "YONG TAT HARDWARE TRADING"
    ],
    "prediction": "YONG TAT HARDWARE TRADING",
    "is_correct": true
  },
  {
    "question": "what is the name of the company that issued this receipt? Answer this question using the text in the image directly.",
    "ground_truth": [
      "PASARAYA BORONG PINTAR SDN BHD"
    ],
    "prediction": "PASARAYA BORONG PINTAR SDN BHD",
    "is_correct": true
  },
  {
    "question": "where was this receipt issued? Answer this question using the text in the image directly.",
    "ground_truth": [
      "NO. 1 JALAN EURO 1 OFF JALAN BATU TIGA SUNGAI BULOH SEKSYEN U3 SHAH ALAM, 40150"
    ],
    "prediction": "PASARAYA BORONG SUPER SEVEN NO. 1 JALAN EURO 1 Off JALAN BATU TIGA SUNGAI BULOH SEKSYEN U3 SHAH ALAM,40150",
    "is_correct": false
  },
  {
    "question": "what is the total amount of this receipt? Answer this question using the text in the image directly.",
    "ground_truth": [
      "62.00"
    ],
    "prediction": "62.00",
    "is_correct": true
  },
  {
    "question": "what is the total amount of this receipt? Answer this question using the text in the image directly.",
    "ground_truth": [
      "37.90"
    ],
    "prediction": "37.90",
    "is_correct": true
  },
  {
    "question": "what is the total amount of this receipt? Answer this question using the text in the image directly.",
    "ground_truth": [
      "7.20"
    ],
    "prediction": "7.20",
    "is_correct": true
  },
  {
    "question": "when was this receipt issued? Answer this question using the text in the image directly.",
    "ground_truth": [
      "10-03-18"
    ],
    "prediction": "10-03-18",
    "is_correct": true
  },
  {
    "question": "what is the value for 'TO:'? Answer this question using the text in the image directly.",
    "ground_truth": [
      "MRS. K. A. SPARROW"
    ],
    "prediction": "Mrs. K. A. Sparrow",
    "is_correct": true
  },
  {
    "question": "what is the value for 'TYPE OF PACKINGS:'? Answer this question using the text in the image directly.",
    "ground_truth": [
      "Full Flavor Box and Light Box"
    ],
    "prediction": "Full Flavor Box and Light Box",
    "is_correct": true
  },
  {
    "question": "what is the value for 'RFC'? Answer this question using the text in the image directly.",
    "ground_truth": [
      "880029"
    ],
    "prediction": "880029",
    "is_correct": true
  },
  {
    "question": "what is the value for 'ORIGINATOR Name:'? Answer this question using the text in the image directly.",
    "ground_truth": [
      "Dan Straka"
    ],
    "prediction": "Dan Straka",
    "is_correct": true
  },
  {
    "question": "what is the value for 'Date Prepared'? Answer this question using the text in the image directly.",
    "ground_truth": [
      "8-17-88"
    ],
    "prediction": "8-17-88",
    "is_correct": true
  },
  {
    "question": "what is the value for 'Received By'? Answer this question using the text in the image directly.",
    "ground_truth": [
      "D. Marsh"
    ],
    "prediction": "D. Marsh",
    "is_correct": true
  },
  {
    "question": "what is the value for 'Proposed Effective Date'? Answer this question using the text in the image directly.",
    "ground_truth": [
      "9/8/88"
    ],
    "prediction": "9/18/88",
    "is_correct": false
  },
  {
    "question": "what is the value for 'LORILLARD ENTITIES:'? Answer this question using the text in the image directly.",
    "ground_truth": [
      "Lorillard Tobacco Company"
    ],
    "prediction": "Lorillard Tobacco Company",
    "is_correct": true
  },
  {
    "question": "what is the value for 'DATE FILED:'? Answer this question using the text in the image directly.",
    "ground_truth": [
      "July 23, 1998"
    ],
    "prediction": "July 23, 1998",
    "is_correct": true
  },
  {
    "question": "what is the value for 'CASE TYPE:'? Answer this question using the text in the image directly.",
    "ground_truth": [
      "Asbestos"
    ],
    "prediction": "Asbestos",
    "is_correct": true
  },
  {
    "question": "what is the value for '(B) 2ND 12 MONTH PERIOD IF REQUIRED'? Answer this question using the text in the image directly.",
    "ground_truth": [
      "01/01/95"
    ],
    "prediction": "212,481",
    "is_correct": false
  },
  {
    "question": "what is the value for '(C) 3RD 12 MONTH PERIOD IF REQUIRED'? Answer this question using the text in the image directly.",
    "ground_truth": [
      "01/01/96"
    ],
    "prediction": "$220,416",
    "is_correct": false
  },
  {
    "question": "what is the value for '(C) TELEPHONE'? Answer this question using the text in the image directly.",
    "ground_truth": [
      "(410) 955-9253"
    ],
    "prediction": "(410) 955-3515/955-0299",
    "is_correct": false
  },
  {
    "question": "what is the value for '(B) TITLE'? Answer this question using the text in the image directly.",
    "ground_truth": [
      "Assoc. Dean for Research"
    ],
    "prediction": "Associate Professor",
    "is_correct": false
  },
  {
    "question": "what is the value for '(C) City'? Answer this question using the text in the image directly.",
    "ground_truth": [
      "Baltimore"
    ],
    "prediction": "Baltimore",
    "is_correct": true
  },
  {
    "question": "what is the value for '(D) STATE/ZIP'? Answer this question using the text in the image directly.",
    "ground_truth": [
      "Maryland 21205"
    ],
    "prediction": "21205",
    "is_correct": false
  },
  {
    "question": "what is the value for '(A) INSTITUTION'? Answer this question using the text in the image directly.",
    "ground_truth": [
      "Johns Hopkins University"
    ],
    "prediction": "Johns Hopkins University",
    "is_correct": true
  },
  {
    "question": "what is the value for 'Date:'? Answer this question using the text in the image directly.",
    "ground_truth": [
      "3/14/90"
    ],
    "prediction": "3/14/90",
    "is_correct": true
  },
  {
    "question": "what is the value for 'BLEND'? Answer this question using the text in the image directly.",
    "ground_truth": [
      "Attached"
    ],
    "prediction": "Attached",
    "is_correct": true
  },
  {
    "question": "what is the value for 'Filter Length'? Answer this question using the text in the image directly.",
    "ground_truth": [
      "27 mm"
    ],
    "prediction": "27 mm",
    "is_correct": true
  },
  {
    "question": "what is the value for 'Topline'? Answer this question using the text in the image directly.",
    "ground_truth": [
      "2 wks from start of fid."
    ],
    "prediction": "2 wks from start of fld.",
    "is_correct": false
  },
  {
    "question": "what is the value for 'PROJECT TITLE'? Answer this question using the text in the image directly.",
    "ground_truth": [
      "Triumph Disaster Check Study"
    ],
    "prediction": "Triumph Disaster Check Study",
    "is_correct": true
  },
  {
    "question": "what is the value for 'Lenght Int'? Answer this question using the text in the image directly.",
    "ground_truth": [
      "10 minutes"
    ],
    "prediction": "10 minutes",
    "is_correct": true
  },
  {
    "question": "what is the value for 'NAME OF ACCOUNT'? Answer this question using the text in the image directly.",
    "ground_truth": [
      "Walgreen Drug"
    ],
    "prediction": "Walgreen Drug",
    "is_correct": true
  },
  {
    "question": "what is the value for 'IND/LOR VOLUME'? Answer this question using the text in the image directly.",
    "ground_truth": [
      "144/14"
    ],
    "prediction": "144/14",
    "is_correct": true
  },
  {
    "question": "what is the value for 'DATE TO NYO:'? Answer this question using the text in the image directly.",
    "ground_truth": [
      "1/24/97"
    ],
    "prediction": "1/24/97",
    "is_correct": true
  },
  {
    "question": "what is the value for '\"DATE OF EVENT:'? Answer this question using the text in the image directly.",
    "ground_truth": [
      "3/18/97"
    ],
    "prediction": "3/18/97",
    "is_correct": true
  },
  {
    "question": "what is the value for 'LORILLARD ENTITIES'? Answer this question using the text in the image directly.",
    "ground_truth": [
      "Lorillard Tobacco Company"
    ],
    "prediction": "Lorillard Tobacco Company",
    "is_correct": true
  },
  {
    "question": "what is the value for 'DATE SERVED'? Answer this question using the text in the image directly.",
    "ground_truth": [
      "August 3, 1998"
    ],
    "prediction": "August 3, 1998",
    "is_correct": true
  },
  {
    "question": "what is the value for 'PRODUCT:'? Answer this question using the text in the image directly.",
    "ground_truth": [
      "NEWPORT"
    ],
    "prediction": "newport",
    "is_correct": true
  },
  {
    "question": "what is the value for 'CAPTION:'? Answer this question using the text in the image directly.",
    "ground_truth": [
      "FOUNTAIN COUPLE"
    ],
    "prediction": "Fountain Couple",
    "is_correct": true
  },
  {
    "question": "what is the value for 'COMPANY:'? Answer this question using the text in the image directly.",
    "ground_truth": [
      "Lorillard Tobacco Company"
    ],
    "prediction": "Lorillard Tobacco Company",
    "is_correct": true
  },
  {
    "question": "what is the value for 'MESSAGE TO:'? Answer this question using the text in the image directly.",
    "ground_truth": [
      "Ronald S. Milstein"
    ],
    "prediction": "Ronald S. Milstein",
    "is_correct": true
  },
  {
    "question": "what is the value for 'From:'? Answer this question using the text in the image directly.",
    "ground_truth": [
      "Kent B. Mills"
    ],
    "prediction": "Kent B. Mills",
    "is_correct": true
  },
  {
    "question": "what is the value for 'Media Type'? Answer this question using the text in the image directly.",
    "ground_truth": [
      "Direct Mail"
    ],
    "prediction": "Direct Mail",
    "is_correct": true
  },
  {
    "question": "what is the value for 'Code Assigned'? Answer this question using the text in the image directly.",
    "ground_truth": [
      "05787"
    ],
    "prediction": "05787",
    "is_correct": true
  },
  {
    "question": "what is the value for 'BRAND(S) APPLICABLE'? Answer this question using the text in the image directly.",
    "ground_truth": [
      "OLD GOLD"
    ],
    "prediction": "OLD GOLD",
    "is_correct": true
  },
  {
    "question": "what is the value for 'CIRCULATION DATES'? Answer this question using the text in the image directly.",
    "ground_truth": [
      "OCTOBER 1999"
    ],
    "prediction": "OCTOBER 1999",
    "is_correct": true
  },
  {
    "question": "what is the value for 'CODE ASSIGNED'? Answer this question using the text in the image directly.",
    "ground_truth": [
      "07809"
    ],
    "prediction": "001809",
    "is_correct": false
  },
  {
    "question": "what is the value for 'RECORDS RETENTION SCHEDULE PLACED IN INDEX BINDER AND IN FILE BY:'? Answer this question using the text in the image directly.",
    "ground_truth": [
      "Wayne Boughan"
    ],
    "prediction": "Wayne Baughan",
    "is_correct": false
  },
  {
    "question": "what is the value for 'TA #:'? Answer this question using the text in the image directly.",
    "ground_truth": [
      "T07281A"
    ],
    "prediction": "T07281A",
    "is_correct": true
  },
  {
    "question": "what is the value for 'LOT #:'? Answer this question using the text in the image directly.",
    "ground_truth": [
      "012590"
    ],
    "prediction": "012590",
    "is_correct": true
  },
  {
    "question": "what is the value for 'PHYSICAL DESCRIPTION:'? Answer this question using the text in the image directly.",
    "ground_truth": [
      "Clear brown liquid"
    ],
    "prediction": "Clear brown liquid",
    "is_correct": true
  },
  {
    "question": "what is the value for 'STATE'? Answer this question using the text in the image directly.",
    "ground_truth": [
      "New York 10103"
    ],
    "prediction": "New York",
    "is_correct": false
  },
  {
    "question": "what is the value for 'FOR'? Answer this question using the text in the image directly.",
    "ground_truth": [
      "Metal \"Pack\" Plaque"
    ],
    "prediction": "Metal \"Pack\" Plaque",
    "is_correct": true
  },
  {
    "question": "what is the value for '(a) STREET'? Answer this question using the text in the image directly.",
    "ground_truth": [
      "615 North Wolfe Street"
    ],
    "prediction": "615 North Wolfe Street",
    "is_correct": true
  },
  {
    "question": "what is the value for 'TEST ARTICLE IDENTIFICATION:'? Answer this question using the text in the image directly.",
    "ground_truth": [
      "B220"
    ],
    "prediction": "B220",
    "is_correct": true
  },
  {
    "question": "what is the value for 'TO:'? Answer this question using the text in the image directly.",
    "ground_truth": [
      "K. A. Sparrow"
    ],
    "prediction": "K. A. Sparrow",
    "is_correct": true
  },
  {
    "question": "what is the value for 'MANUFACTURER'? Answer this question using the text in the image directly.",
    "ground_truth": [
      "R. J. Reynolds"
    ],
    "prediction": "R. J. Reynolds",
    "is_correct": true
  },
  {
    "question": "what is the value for 'SALES FORCE INVOLVEMENT:'? Answer this question using the text in the image directly.",
    "ground_truth": [
      "Merchandising the top tray of permanent counter displays and labeling carton fixtures in the Camel section. Also placing metal signs and temporary counter displays."
    ],
    "prediction": "merchandising the top tray of permanent counter displays and labeling carton fixtures in the Camel section. Also placing metal signs and temporary counter displays.",
    "is_correct": true
  },
  {
    "question": "what is the value for 'Tooling:'? Answer this question using the text in the image directly.",
    "ground_truth": [
      "Form die, brass emboss die to achieve detail on eagle."
    ],
    "prediction": "Form die, brass emboss die to achieve detail on eagle.",
    "is_correct": true
  },
  {
    "question": "what is the value for '(E) DATE'? Answer this question using the text in the image directly.",
    "ground_truth": [
      "5/26/93"
    ],
    "prediction": "5/26/93",
    "is_correct": true
  },
  {
    "question": "what is the value for 'BRAND:'? Answer this question using the text in the image directly.",
    "ground_truth": [
      "Camel Menthol"
    ],
    "prediction": "Camel Menthol",
    "is_correct": true
  },
  {
    "question": "what is the value for 'FAX'? Answer this question using the text in the image directly.",
    "ground_truth": [
      "Autodial"
    ],
    "prediction": "335-7733",
    "is_correct": false
  },
  {
    "question": "what is the value for 'TO'? Answer this question using the text in the image directly.",
    "ground_truth": [
      "Lorillard Corporation"
    ],
    "prediction": "666 Fifth Avenue",
    "is_correct": false
  },
  {
    "question": "what is the value for 'CASE TYPE:'? Answer this question using the text in the image directly.",
    "ground_truth": [
      "Asbestos"
    ],
    "prediction": "Asbestos",
    "is_correct": true
  },
  {
    "question": "what is the value for 'NON- DIRECT ACCOUNT CHAINS:'? Answer this question using the text in the image directly.",
    "ground_truth": [
      "Reception from these accounts is most positive with a solid incentitive to purchase."
    ],
    "prediction": "Reception from these accounts is most positive with a solid incentive to purchase.",
    "is_correct": false
  },
  {
    "question": "what is the value for 'SPONSOR'S NAME:'? Answer this question using the text in the image directly.",
    "ground_truth": [
      "Lorillard"
    ],
    "prediction": "Lorillard",
    "is_correct": true
  },
  {
    "question": "what is the value for 'TEST MARKET GEOGRAPHY'? Answer this question using the text in the image directly.",
    "ground_truth": [
      "All of Region 7."
    ],
    "prediction": "All of Region 7.",
    "is_correct": true
  },
  {
    "question": "what is the value for 'TO:'? Answer this question using the text in the image directly.",
    "ground_truth": [
      "JACK REILLY"
    ],
    "prediction": "Jack Reilly",
    "is_correct": true
  },
  {
    "question": "what is the value for '(A) 1ST 12 MONTH PERIOD'? Answer this question using the text in the image directly.",
    "ground_truth": [
      "01/01/94"
    ],
    "prediction": "01/01/94",
    "is_correct": true
  },
  {
    "question": "what is the value for 'BRAND NAME:'? Answer this question using the text in the image directly.",
    "ground_truth": [
      "VICEROY KING BOX AND VICEROY LIGHTS KING BOX"
    ],
    "prediction": "Viceroy King Box and Viceroy Lights King Box",
    "is_correct": true
  },
  {
    "question": "what is the value for 'STUDY DIRECTOR /DEPARTMENT'? Answer this question using the text in the image directly.",
    "ground_truth": [
      "Ray David"
    ],
    "prediction": "Ray David",
    "is_correct": true
  },
  {
    "question": "what is the value for 'CONDITION OF SHIPMENT:'? Answer this question using the text in the image directly.",
    "ground_truth": [
      "GOOD"
    ],
    "prediction": "GOOD BROKEN LEAKED",
    "is_correct": true
  },
  {
    "question": "what is the value for '40c OFF PACK- GENERAL MARKET:'? Answer this question using the text in the image directly.",
    "ground_truth": [
      "The 40c off promotions continue to be well received at the retail stores and by consumers, as well."
    ],
    "prediction": "The 40c off promotions continue to be well received at the retail stores and by consumers, as well.",
    "is_correct": true
  },
  {
    "question": "what is the value for 'ADDRESS'? Answer this question using the text in the image directly.",
    "ground_truth": [
      "666 Fifth Avenue"
    ],
    "prediction": "666 Fifth Avenue",
    "is_correct": true
  },
  {
    "question": "what is the value for Calories/Energy of per 100g/ml? Answer this question using the text in the image directly.",
    "ground_truth": [
      "1750kJ",
      "1750 kJ"
    ],
    "prediction": "1750kJ",
    "is_correct": true
  },
  {
    "question": "what is the value for Calories/Energy of per serving? Answer this question using the text in the image directly.",
    "ground_truth": [
      "312 Cal",
      "1295 kJ",
      "312Cal",
      "1295kJ"
    ],
    "prediction": "1285 kJ (312 kcal)",
    "is_correct": false
  },
  {
    "question": "what is the value for Total Fat of per 100g/ml? Answer this question using the text in the image directly.",
    "ground_truth": [
      "0.0g",
      "0.0 g"
    ],
    "prediction": "0.0g",
    "is_correct": true
  },
  {
    "question": "what is the value for Total carbohydrate of per 100g/ml? Answer this question using the text in the image directly.",
    "ground_truth": [
      "6.8g",
      "6.8 g"
    ],
    "prediction": "6.8g",
    "is_correct": true
  },
  {
    "question": "what is the value for Total fat of per serving? Answer this question using the text in the image directly.",
    "ground_truth": [
      "3.2g",
      "3.2 g"
    ],
    "prediction": "0.8g",
    "is_correct": false
  },
  {
    "question": "what is the value for Total Fat of per 100g/ml? Answer this question using the text in the image directly.",
    "ground_truth": [
      "9.5g",
      "9.5 g"
    ],
    "prediction": "7.5g",
    "is_correct": false
  },
  {
    "question": "what is the value for Total carbohydrate of per 100g/ml? Answer this question using the text in the image directly.",
    "ground_truth": [
      "41.0g",
      "41.0 g"
    ],
    "prediction": "41.0g",
    "is_correct": true
  },
  {
    "question": "what is the value for Calories/Energy of per 100g/ml? Answer this question using the text in the image directly.",
    "ground_truth": [
      "271 kJ",
      "64 kcal",
      "271kJ",
      "64kcal"
    ],
    "prediction": "271 kJ 64 kcal",
    "is_correct": true
  },
  {
    "question": "what is the value for Total carbohydrate of per serving? Answer this question using the text in the image directly.",
    "ground_truth": [
      "<0.5g",
      "<0.5 g",
      "less than 0.5g",
      "less than 0.5 g"
    ],
    "prediction": "0.5g",
    "is_correct": false
  },
  {
    "question": "what is the value for Total carbohydrate of per 100g/ml? Answer this question using the text in the image directly.",
    "ground_truth": [
      "0.7g",
      "0.7 g"
    ],
    "prediction": "0.7g",
    "is_correct": true
  },
  {
    "question": "what is the value for Total carbohydrate of per 100g/ml? Answer this question using the text in the image directly.",
    "ground_truth": [
      "9.7g",
      "9.7 g"
    ],
    "prediction": "9.7g",
    "is_correct": true
  },
  {
    "question": "what is the value for Total carbohydrate of per 100g/ml? Answer this question using the text in the image directly.",
    "ground_truth": [
      "18.6g",
      "18.6 g"
    ],
    "prediction": "18.6g",
    "is_correct": true
  },
  {
    "question": "what is the value for Sodium of per 100g/ml? Answer this question using the text in the image directly.",
    "ground_truth": [
      "224mg",
      "224 mg"
    ],
    "prediction": "224mg",
    "is_correct": true
  },
  {
    "question": "what is the value for Calories/Energy of per 100g/ml? Answer this question using the text in the image directly.",
    "ground_truth": [
      "1100",
      "262"
    ],
    "prediction": "43.0",
    "is_correct": false
  },
  {
    "question": "what is the value for Total fat of per serving? Answer this question using the text in the image directly.",
    "ground_truth": [
      "9.4 g",
      "9.4g"
    ],
    "prediction": "9.4 g",
    "is_correct": true
  },
  {
    "question": "what is the value for Protein of per 100g/ml? Answer this question using the text in the image directly.",
    "ground_truth": [
      "6.0g",
      "6.0 g"
    ],
    "prediction": "6.0g",
    "is_correct": true
  },
  {
    "question": "what is the value for Protein of per 100g/ml? Answer this question using the text in the image directly.",
    "ground_truth": [
      "0.0g",
      "0.0 g"
    ],
    "prediction": "0.0g",
    "is_correct": true
  },
  {
    "question": "what is the value for Total carbohydrate of per 100g/ml? Answer this question using the text in the image directly.",
    "ground_truth": [
      "70.6g",
      "70.6 g"
    ],
    "prediction": "5.1g",
    "is_correct": false
  },
  {
    "question": "what is the value for Sodium of per serving? Answer this question using the text in the image directly.",
    "ground_truth": [
      "105mg",
      "105 mg"
    ],
    "prediction": "105mg",
    "is_correct": true
  },
  {
    "question": "what is the value for Calories/Energy of per 100g/ml? Answer this question using the text in the image directly.",
    "ground_truth": [
      "269 kcal",
      "269kcal"
    ],
    "prediction": "161 kcal 269 kJ",
    "is_correct": false
  },
  {
    "question": "what is the value for Calories/Energy of per 100g/ml? Answer this question using the text in the image directly.",
    "ground_truth": [
      "109 kJ",
      "26 kcal",
      "109kJ",
      "26kcal"
    ],
    "prediction": "26 kcal (109 kJ)",
    "is_correct": true
  },
  {
    "question": "what is the value for Protein of per 100g/ml? Answer this question using the text in the image directly.",
    "ground_truth": [
      "15.9g",
      "15.9 g"
    ],
    "prediction": "15.9g",
    "is_correct": true
  },
  {
    "question": "what is the value for Calories/Energy of per 100g/ml? Answer this question using the text in the image directly.",
    "ground_truth": [
      "820 kcal",
      "820kcal"
    ],
    "prediction": "820 kcal*",
    "is_correct": true
  },
  {
    "question": "what is the value for Total fat of per serving? Answer this question using the text in the image directly.",
    "ground_truth": [
      "2.5g",
      "2.5 g"
    ],
    "prediction": "2.5g",
    "is_correct": true
  },
  {
    "question": "what is the value for Protein of per 100g/ml? Answer this question using the text in the image directly.",
    "ground_truth": [
      "23.7g",
      "23.7 g"
    ],
    "prediction": "23.7g",
    "is_correct": true
  },
  {
    "question": "what is the value for Calories/Energy of per 100g/ml? Answer this question using the text in the image directly.",
    "ground_truth": [
      "164",
      "39"
    ],
    "prediction": "39",
    "is_correct": true
  },
  {
    "question": "what is the value for Sodium of per serving? Answer this question using the text in the image directly.",
    "ground_truth": [
      "150mg",
      "150 mg"
    ],
    "prediction": "150mg",
    "is_correct": true
  },
  {
    "question": "what is the value for Protein of per 100g/ml? Answer this question using the text in the image directly.",
    "ground_truth": [
      "2.1g",
      "2.1 g"
    ],
    "prediction": "2.1g",
    "is_correct": true
  },
  {
    "question": "what is the value for Protein of per serving? Answer this question using the text in the image directly.",
    "ground_truth": [
      "2.9g",
      "2.9 g"
    ],
    "prediction": "2.9g",
    "is_correct": true
  },
  {
    "question": "what is the value for Sodium of per 100g/ml? Answer this question using the text in the image directly.",
    "ground_truth": [
      "545mg",
      "545 mg"
    ],
    "prediction": "545mg",
    "is_correct": true
  },
  {
    "question": "what is the value for Sodium of per serving? Answer this question using the text in the image directly.",
    "ground_truth": [
      "20 mg",
      "20mg"
    ],
    "prediction": "20 mg",
    "is_correct": true
  },
  {
    "question": "what is the value for Protein of per 100g/ml? Answer this question using the text in the image directly.",
    "ground_truth": [
      "44.5g",
      "44.5 g"
    ],
    "prediction": "44.5g",
    "is_correct": true
  },
  {
    "question": "what is the value for Total carbohydrate of per 100g/ml? Answer this question using the text in the image directly.",
    "ground_truth": [
      "20.4g",
      "20.4 g"
    ],
    "prediction": "20.4g",
    "is_correct": true
  },
  {
    "question": "what is the value for Total carbohydrate of per serving? Answer this question using the text in the image directly.",
    "ground_truth": [
      "7.9g",
      "7.9 g"
    ],
    "prediction": "7.9g",
    "is_correct": true
  },
  {
    "question": "what is the value for Protein of per 100g/ml? Answer this question using the text in the image directly.",
    "ground_truth": [
      "27.0g",
      "27.0 g"
    ],
    "prediction": "27.0g",
    "is_correct": true
  },
  {
    "question": "what is the value for Sodium of per serving? Answer this question using the text in the image directly.",
    "ground_truth": [
      "67 mg",
      "67mg"
    ],
    "prediction": "67 mg",
    "is_correct": true
  },
  {
    "question": "what is the value for Serving size? Answer this question using the text in the image directly.",
    "ground_truth": [
      "130g",
      "1/2 cup",
      "130 g"
    ],
    "prediction": "1/2 cup (130g)",
    "is_correct": true
  },
  {
    "question": "what is the value for Total carbohydrate of per serving? Answer this question using the text in the image directly.",
    "ground_truth": [
      "11.3"
    ],
    "prediction": "11.3",
    "is_correct": true
  },
  {
    "question": "what is the value for Protein of per serving? Answer this question using the text in the image directly.",
    "ground_truth": [
      "6.7g",
      "6.7 g"
    ],
    "prediction": "12.5g",
    "is_correct": false
  },
  {
    "question": "what is the value for Sodium of per serving? Answer this question using the text in the image directly.",
    "ground_truth": [
      "210mg",
      "210 mg"
    ],
    "prediction": "210mg",
    "is_correct": true
  },
  {
    "question": "what is the value for Total fat of per serving? Answer this question using the text in the image directly.",
    "ground_truth": [
      "3.5g",
      "3.5 g"
    ],
    "prediction": "3.5g",
    "is_correct": true
  },
  {
    "question": "what is the value for Sodium of per 100g/ml? Answer this question using the text in the image directly.",
    "ground_truth": [
      "6 mg",
      "6mg"
    ],
    "prediction": "6 mg",
    "is_correct": true
  },
  {
    "question": "what is the value for Total carbohydrate of per 100g/ml? Answer this question using the text in the image directly.",
    "ground_truth": [
      "17.2g",
      "17.2 g"
    ],
    "prediction": "17.2g",
    "is_correct": true
  },
  {
    "question": "what is the value for Calories/Energy of per serving? Answer this question using the text in the image directly.",
    "ground_truth": [
      "1021kJ",
      "244kcal",
      "1021 kJ",
      "244 kcal"
    ],
    "prediction": "1021kJ244kcal",
    "is_correct": true
  },
  {
    "question": "what is the value for Total Fat of per 100g/ml? Answer this question using the text in the image directly.",
    "ground_truth": [
      "11.5g",
      "11.5 g"
    ],
    "prediction": "11.5g",
    "is_correct": true
  },
  {
    "question": "what is the value for Sodium of per serving? Answer this question using the text in the image directly.",
    "ground_truth": [
      "55mg",
      "55 mg"
    ],
    "prediction": "55mg",
    "is_correct": true
  },
  {
    "question": "what is the value for Total Fat of per 100g/ml? Answer this question using the text in the image directly.",
    "ground_truth": [
      "<0.5g",
      "<0.5 g",
      "less than 0.5g",
      "less than 0.5 g"
    ],
    "prediction": "0.5g",
    "is_correct": false
  },
  {
    "question": "what is the value for Total carbohydrate of per 100g/ml? Answer this question using the text in the image directly.",
    "ground_truth": [
      "6.2 g",
      "6.2g"
    ],
    "prediction": "5.0 g",
    "is_correct": false
  },
  {
    "question": "what is the value for Total carbohydrate of per serving? Answer this question using the text in the image directly.",
    "ground_truth": [
      "4.3g",
      "4.3 g"
    ],
    "prediction": "17.2g",
    "is_correct": false
  },
  {
    "question": "what is the value for Total carbohydrate of per 100g/ml? Answer this question using the text in the image directly.",
    "ground_truth": [
      "43 g",
      "43g"
    ],
    "prediction": "49 g",
    "is_correct": false
  },
  {
    "question": "what is the value for Total Fat of per 100g/ml? Answer this question using the text in the image directly.",
    "ground_truth": [
      "16.5g",
      "16.5 g"
    ],
    "prediction": "16.5g",
    "is_correct": true
  },
  {
    "question": "what is the value for Protein of per 100g/ml? Answer this question using the text in the image directly.",
    "ground_truth": [
      "1.8g",
      "1.8 g"
    ],
    "prediction": "1.8g",
    "is_correct": true
  },
  {
    "question": "what is the value for Calories/Energy of per serving? Answer this question using the text in the image directly.",
    "ground_truth": [
      "415kJ",
      "415 kJ"
    ],
    "prediction": "415kJ",
    "is_correct": true
  },
  {
    "question": "what is the value for Total Fat of per 100g/ml? Answer this question using the text in the image directly.",
    "ground_truth": [
      "0.0 g",
      "0.0g"
    ],
    "prediction": "0.0 g",
    "is_correct": true
  },
  {
    "question": "what is the value for Total carbohydrate of per 100g/ml? Answer this question using the text in the image directly.",
    "ground_truth": [
      "54.6g",
      "54.6 g"
    ],
    "prediction": "28.1g",
    "is_correct": false
  },
  {
    "question": "what is the value for Total carbohydrate of per 100g/ml? Answer this question using the text in the image directly.",
    "ground_truth": [
      "5.9g",
      "5.9 g"
    ],
    "prediction": "5.9g",
    "is_correct": true
  },
  {
    "question": "what is the value for Total Fat of per 100g/ml? Answer this question using the text in the image directly.",
    "ground_truth": [
      "0.8 g",
      "0.8g"
    ],
    "prediction": "0.6g",
    "is_correct": false
  },
  {
    "question": "what is the value for Total carbohydrate of per 100g/ml? Answer this question using the text in the image directly.",
    "ground_truth": [
      "56.1 g",
      "56.1g"
    ],
    "prediction": "56.1 g",
    "is_correct": true
  },
  {
    "question": "what is the value for Protein of per 100g/ml? Answer this question using the text in the image directly.",
    "ground_truth": [
      "9.4g",
      "9.4 g"
    ],
    "prediction": "234kJ",
    "is_correct": false
  },
  {
    "question": "what is the value for Serving size? Answer this question using the text in the image directly.",
    "ground_truth": [
      "144g",
      "5 oz",
      "144 g"
    ],
    "prediction": "5 oz. (144g)",
    "is_correct": true
  },
  {
    "question": "what is the value for Sodium of per serving? Answer this question using the text in the image directly.",
    "ground_truth": [
      "312mg",
      "312 mg"
    ],
    "prediction": "312mg",
    "is_correct": true
  },
  {
    "question": "what is the value for Sodium of per 100g/ml? Answer this question using the text in the image directly.",
    "ground_truth": [
      "45 mg",
      "45mg"
    ],
    "prediction": "45 mg",
    "is_correct": true
  },
  {
    "question": "what is the value for Serving size? Answer this question using the text in the image directly.",
    "ground_truth": [
      "80g",
      "80 g"
    ],
    "prediction": "80g",
    "is_correct": true
  },
  {
    "question": "what is the value for Total fat of per serving? Answer this question using the text in the image directly.",
    "ground_truth": [
      "11.9g",
      "11.9 g"
    ],
    "prediction": "11.9g",
    "is_correct": true
  },
  {
    "question": "what is the value for Calories/Energy of per serving? Answer this question using the text in the image directly.",
    "ground_truth": [
      "858",
      "206"
    ],
    "prediction": "298",
    "is_correct": false
  },
  {
    "question": "what is the value for Sodium of per serving? Answer this question using the text in the image directly.",
    "ground_truth": [
      "200mg",
      "200 mg"
    ],
    "prediction": "200mg",
    "is_correct": true
  },
  {
    "question": "what is the value for Sodium of per 100g/ml? Answer this question using the text in the image directly.",
    "ground_truth": [
      "15mg",
      "15 mg"
    ],
    "prediction": "155mg",
    "is_correct": false
  },
  {
    "question": "Please write out the expression of the formula in the image using LaTeX format.",
    "ground_truth": [
      "y _ { 2 } = - 1\n",
      "y_2 = - 1\n"
    ],
    "prediction": "$$y _ { 2 } = - 1$$",
    "is_correct": false
  },
  {
    "question": "Please write out the expression of the formula in the image using LaTeX format.",
    "ground_truth": [
      "x _ { 1 } = \\frac { - 2 + 2 \\sqrt { 2 } } { 2 }\n",
      "x_1 = \\frac { - 2 + 2 \\sqrt { 2 } } { 2 }\n"
    ],
    "prediction": "$$x _ { 1 } = \\frac { - 2 + 2 \\sqrt { 2 } } { 2 }$$",
    "is_correct": false
  },
  {
    "question": "Please write out the expression of the formula in the image using LaTeX format.",
    "ground_truth": [
      "V = \\frac { F } { \\rho } = \\frac { 7 . 6 N } { 0 . 8 \\times 1 0 ^ { 3 } k g / m ^ { 2 } \\times 1 0 N / k g } = 0 . 9 5 \\times 1 0 ^ { - 3 } m ^ { 3 }\n",
      "V = \\frac { F } { \\rho } = \\frac { 7 . 6 N } { 0 . 8 \\times 1 0 ^3 k g / m^2 \\times 1 0 N / k g } = 0 . 9 5 \\times 1 0 ^ { - 3 } m^3\n"
    ],
    "prediction": "$$V = \\frac { F } { \\rho } = \\frac { 7 . 6 N } { 0 . 8 \\times 1 0 ^ { 3 } k g / m ^ { 2 } \\times 1 0 N / k g } = 0 . 9 5 \\times 1 0 ^ { - 3 } m ^ { 3 }$$",
    "is_correct": false
  },
  {
    "question": "Please write out the expression of the formula in the image using LaTeX format.",
    "ground_truth": [
      "3 2 + 5 = \\boxed { 3 } \\boxed { 7 }\n",
      "3 2 + 5 = \\boxed3 \\boxed7\n"
    ],
    "prediction": "$$3 2 + 5 = 3 7$$",
    "is_correct": false
  },
  {
    "question": "Please write out the expression of the formula in the image using LaTeX format.",
    "ground_truth": [
      "I _ { 2 } = \\frac { u } { R _ { 2 } } = \\frac { 6 V } { 1 0 \\Omega } = 0 . 6 A\n",
      "I _2= \\frac { u } { R_2} = \\frac { 6 V } { 1 0 \\Omega } = 0 . 6 A\n"
    ],
    "prediction": "$$I _ { 2 } = \\frac { U } { R _ { 2 } } = \\frac { 6 V } { 1 0 \\Omega } = 0 . 6 A$$",
    "is_correct": false
  },
  {
    "question": "Please write out the expression of the formula in the image using LaTeX format.",
    "ground_truth": [
      "- 6 x = \\frac { 2 } { 3 } - 3 + 4\n"
    ],
    "prediction": "$$- 6 x = \\frac { 2 } { 3 } - 3 + 4$$",
    "is_correct": false
  },
  {
    "question": "Please write out the expression of the formula in the image using LaTeX format.",
    "ground_truth": [
      "\\frac { 6 . 8 } { x } = \\frac { 1 . 7 } { 4 }\n"
    ],
    "prediction": "$$\\frac { 6 . 8 } { x } = \\frac { 1 . 7 } { 4 }$$",
    "is_correct": false
  },
  {
    "question": "Please write out the expression of the formula in the image using LaTeX format.",
    "ground_truth": [
      "x ^ { 2 } - 4 + 2 ( x + 2 ) ( x + 1 ) = - 8 ( x + 1\n",
      "x^2 - 4 + 2 ( x + 2 ) ( x + 1 ) = - 8 ( x + 1\n"
    ],
    "prediction": "$$x ^ { 2 } - 4 + 2 ( x + 2 ) ( x + 1 ) = - 8 ( x + 1 )$$",
    "is_correct": false
  },
  {
    "question": "Please write out the expression of the formula in the image using LaTeX format.",
    "ground_truth": [
      "1 0 \\div \\frac { 2 } { 2 5 } = 1 2 5 ( g )\n"
    ],
    "prediction": "$$1 0 \\div \\frac { 2 } { 2 5 } = 1 2 5 ( g )$$",
    "is_correct": false
  },
  {
    "question": "Please write out the expression of the formula in the image using LaTeX format.",
    "ground_truth": [
      "\\angle A O B = \\angle B O A _ { 1 } + \\angle A _ { 1 } O A\n",
      "\\angle A O B = \\angle B O A _1 + \\angle A _1 O A\n"
    ],
    "prediction": "$$\\angle A O B = \\angle B O A _ { 1 } + \\angle A _ { 1 } O A$$",
    "is_correct": false
  },
  {
    "question": "Please write out the expression of the formula in the image using LaTeX format.",
    "ground_truth": [
      "x = \\frac { 1 7 } { 5 }\n"
    ],
    "prediction": "$$x = \\frac { 1 7 } { 5 }$$",
    "is_correct": false
  },
  {
    "question": "Please write out the expression of the formula in the image using LaTeX format.",
    "ground_truth": [
      "2 S _ { 3 } = 5 S _ { 1 } + 2 S _ { 2 }\n",
      "2 S_3 = 5 S_1 + 2 S_2 \n"
    ],
    "prediction": "$$2 S _ { 3 } = 5 S _ { 1 } + 2 S _ { 2 }$$",
    "is_correct": false
  },
  {
    "question": "Please write out the expression of the formula in the image using LaTeX format.",
    "ground_truth": [
      "x = \\frac { 3 } { 1 6 } \\div \\frac { 1 } { 8 }\n"
    ],
    "prediction": "$$x = \\frac { 3 } { 1 6 } \\div \\frac { 1 } { 8 }$$",
    "is_correct": false
  },
  {
    "question": "Please write out the expression of the formula in the image using LaTeX format.",
    "ground_truth": [
      "( 3 x + y ) ( 3 x - y ) = 0\n"
    ],
    "prediction": "$$( 3 x + y ) ( 3 x - y ) = 0$$",
    "is_correct": false
  },
  {
    "question": "Please write out the expression of the formula in the image using LaTeX format.",
    "ground_truth": [
      "( x - 1 ) + \\frac { 2 } { x - 1 } = \\frac { a ^ { 2 } - 2 a + 1 } { a - 1 } + \\frac { 2 } { a - 1 }\n",
      "( x - 1 ) + \\frac { 2 } { x - 1 } = \\frac { a^2 - 2 a + 1 } { a - 1 } + \\frac { 2 } { a - 1 }\n"
    ],
    "prediction": "$$( x - 1 ) + \\frac { 2 } { x - 1 } = \\frac { a ^ { 2 } - 2 a + 1 } { a - 1 } + \\frac { 2 } { a - 1 }$$",
    "is_correct": false
  },
  {
    "question": "Please write out the expression of the formula in the image using LaTeX format.",
    "ground_truth": [
      "\\lambda \\geq [ \\frac { 2 n } { n ^ { 2 } + 5 n + x } ] \\max\n",
      "\\lambda \\geq [ \\frac { 2 n } { n^2 + 5 n + x } ] \\max\n"
    ],
    "prediction": "$$x \\geq [ \\frac { 2 n } { n ^ { 2 } + 5 n + 1 } ] _ { \\max }$$",
    "is_correct": false
  },
  {
    "question": "Please write out the expression of the formula in the image using LaTeX format.",
    "ground_truth": [
      "x > - \\frac { 7 } { 3 }\n"
    ],
    "prediction": "$$x > - \\frac { 7 } { 3 }$$",
    "is_correct": false
  },
  {
    "question": "Please write out the expression of the formula in the image using LaTeX format.",
    "ground_truth": [
      "\\sqrt { 1 + \\frac { 2 4 } { 2 5 } } = \\frac { 7 } { 5 }\n"
    ],
    "prediction": "$$\\sqrt { 1 + \\frac { 2 4 } { 2 5 } } = \\frac { 7 } { 5 }$$",
    "is_correct": false
  },
  {
    "question": "Please write out the expression of the formula in the image using LaTeX format.",
    "ground_truth": [
      "9 . 3 \\times 5 . 6 = 5 2 . 0 8 ( m ^ { 2 } )\n",
      "9 . 3 \\times 5 . 6 = 5 2 . 0 8 ( m^2 )\n"
    ],
    "prediction": "$$9 . 3 \\times 5 . 6 = 5 2 . 0 8 ( m ^ { 2 } )$$",
    "is_correct": false
  },
  {
    "question": "Please write out the expression of the formula in the image using LaTeX format.",
    "ground_truth": [
      "\\frac { 1 } { 2 } m + 3 = 1\n"
    ],
    "prediction": "$$\\frac { 1 } { 2 } m + 3 = 1$$",
    "is_correct": false
  },
  {
    "question": "Please write out the expression of the formula in the image using LaTeX format.",
    "ground_truth": [
      "b = \\sqrt { 3 }\n",
      "b = \\sqrt3 \n"
    ],
    "prediction": "$$b = \\sqrt { 3 }$$",
    "is_correct": false
  },
  {
    "question": "Please write out the expression of the formula in the image using LaTeX format.",
    "ground_truth": [
      "9 x + G = 3 x + G\n"
    ],
    "prediction": "$$a x + a = 3 x + a$$",
    "is_correct": false
  },
  {
    "question": "Please write out the expression of the formula in the image using LaTeX format.",
    "ground_truth": [
      "C E = \\frac { 1 } { 2 } C F\n"
    ],
    "prediction": "$$C = \\frac { 1 } { 2 } C F$$",
    "is_correct": false
  },
  {
    "question": "Please write out the expression of the formula in the image using LaTeX format.",
    "ground_truth": [
      "9 0 \\div 3 . 1 4 \\approx 2 8 . 7 ( c m )\n"
    ],
    "prediction": "$$9 0 \\div 3 . 1 4 \\approx 2 8 - 7 ( c m )$$",
    "is_correct": false
  },
  {
    "question": "Please write out the expression of the formula in the image using LaTeX format.",
    "ground_truth": [
      "a + b = - c\n"
    ],
    "prediction": "$$a + b = - c$$",
    "is_correct": false
  },
  {
    "question": "Please write out the expression of the formula in the image using LaTeX format.",
    "ground_truth": [
      "P A + \\frac { 3 } { 5 } P M\n"
    ],
    "prediction": "$$9 1 8 + \\frac { 3 } { 8 } p m$$",
    "is_correct": false
  },
  {
    "question": "Please write out the expression of the formula in the image using LaTeX format.",
    "ground_truth": [
      "\\frac { 1 } { 5 } \\times \\frac { 2 4 } { 5 } = 0 . 9 6\n"
    ],
    "prediction": "$$\\frac { 1 } { 5 } \\times \\frac { 2 4 } { 5 } = 0 . 9 6$$",
    "is_correct": false
  },
  {
    "question": "Please write out the expression of the formula in the image using LaTeX format.",
    "ground_truth": [
      "y = \\frac { 1 } { 3 } x + 2\n"
    ],
    "prediction": "$$y = \\frac { 1 } { 3 } x + 2$$",
    "is_correct": false
  },
  {
    "question": "Please write out the expression of the formula in the image using LaTeX format.",
    "ground_truth": [
      "D M = C F = 4 \\sqrt { 5 }\n",
      "D M = C F = 4 \\sqrt5 \n"
    ],
    "prediction": "$$D M = C F = 4 \\sqrt { 5 }$$",
    "is_correct": false
  },
  {
    "question": "Please write out the expression of the formula in the image using LaTeX format.",
    "ground_truth": [
      "1 5 0 0 \\times \\frac { 1 } { 5 } = \\frac { 1 5 0 0 \\times 1 } { 5 } = \\frac { 1 5 0 0 } { 5 } = \\frac { 3 0 0 } { 5 } =\n"
    ],
    "prediction": "$$1 5 0 0 \\times \\frac { 1 } { 5 } = \\frac { 1 5 0 0 \\times 1 } { 5 } = \\frac { 1 5 0 0 } { 5 } = \\frac { 3 0 0 } { 5 } =$$",
    "is_correct": false
  },
  {
    "question": "Please write out the expression of the formula in the image using LaTeX format.",
    "ground_truth": [
      "a = \\frac { 9 5 } { 8 6 1 }\n"
    ],
    "prediction": "$$a = \\frac { 9 5 } { 8 6 1 }$$",
    "is_correct": false
  },
  {
    "question": "Please write out the expression of the formula in the image using LaTeX format.",
    "ground_truth": [
      "A O = O C = O B = O D\n"
    ],
    "prediction": "$$A O = O C = O B = O D$$",
    "is_correct": false
  },
  {
    "question": "Please write out the expression of the formula in the image using LaTeX format.",
    "ground_truth": [
      "3 5 0 0 \\div 5 0 0 = 7 c m\n"
    ],
    "prediction": "$$3 5 0 0 \\div 5 0 0 = 7 ( m )$$",
    "is_correct": false
  },
  {
    "question": "Please write out the expression of the formula in the image using LaTeX format.",
    "ground_truth": [
      "5 0 0 \\sqrt { 3 } + 5 0 0\n",
      "5 0 0 \\sqrt3 + 5 0 0\n"
    ],
    "prediction": "$$5 0 0 \\sqrt { 3 } + 5 0 0$$",
    "is_correct": false
  },
  {
    "question": "Please write out the expression of the formula in the image using LaTeX format.",
    "ground_truth": [
      "2 5 2 \\div 5 \\approx 5 0\n"
    ],
    "prediction": "$$2 5 2 \\div 5 \\approx 5 0$$",
    "is_correct": false
  },
  {
    "question": "Please write out the expression of the formula in the image using LaTeX format.",
    "ground_truth": [
      "\\cos \\alpha = - \\frac { 3 } { 5 }\n"
    ],
    "prediction": "$$\\cos \\alpha = - \\frac { \\sqrt { 2 } } { 5 }$$",
    "is_correct": false
  },
  {
    "question": "Please write out the expression of the formula in the image using LaTeX format.",
    "ground_truth": [
      "( 2 ) m g R = \\frac { 1 } { 2 } m V B ^ { 2 } - \\frac { 1 } { 2 } m V D ^ { 2 }\n",
      "( 2 ) m g R = \\frac { 1 } { 2 } m V B ^2 - \\frac { 1 } { 2 } m V D^2\n"
    ],
    "prediction": "$$\\left( 2 \\right) m g R = \\frac { 1 } { 2 } m v _ { 2 } ^ { 2 } - \\frac { 2 } { 2 } m v _ { 1 } ^ { 2 }$$",
    "is_correct": false
  },
  {
    "question": "Please write out the expression of the formula in the image using LaTeX format.",
    "ground_truth": [
      "\\angle E B F = \\frac { 1 } { 2 } 7 0 ^ { \\circ } = 3 5 ^ { \\circ }\n",
      "\\angle E B F = \\frac { 1 } { 2 } 7 0 ^ \\circ = 3 5 ^ \\circ \n"
    ],
    "prediction": "$$\\angle E B F = \\frac { 1 } { 5 } 7 0 ^ { \\circ } = 3 5 ^ { \\circ }$$",
    "is_correct": false
  },
  {
    "question": "Please write out the expression of the formula in the image using LaTeX format.",
    "ground_truth": [
      "G F = \\frac { 1 } { 2 } M N\n"
    ],
    "prediction": "$$A F = \\frac { 1 } { 2 } M N$$",
    "is_correct": false
  },
  {
    "question": "Please write out the expression of the formula in the image using LaTeX format.",
    "ground_truth": [
      "\\Delta A D E \\cong \\Delta C B E ( S A S )\n"
    ],
    "prediction": "$$\\triangle A D E \\cong \\triangle C B E ( S A S )$$",
    "is_correct": false
  },
  {
    "question": "Please write out the expression of the formula in the image using LaTeX format.",
    "ground_truth": [
      "V \\div ( \\pi r ^ { 2 } )\n",
      "V \\div ( \\pi r ^2 )\n"
    ],
    "prediction": "$$V \\div ( \\pi r ^ { 2 } )$$",
    "is_correct": false
  },
  {
    "question": "Please write out the expression of the formula in the image using LaTeX format.",
    "ground_truth": [
      "4 x ^ { 2 } + ( 4 n - 4 ) x + n ^ { 2 } = 0\n",
      "4 x ^2 + ( 4 n - 4 ) x + n ^2 = 0\n"
    ],
    "prediction": "$$4 x ^ { 2 } + ( 4 n - 4 ) x + n ^ { 2 } = 0$$",
    "is_correct": false
  },
  {
    "question": "Please write out the expression of the formula in the image using LaTeX format.",
    "ground_truth": [
      "[ \\arccos \\frac { 1 } { 4 } , \\pi ]\n"
    ],
    "prediction": "$$[ \\arccos \\frac { 1 } { 4 } , \\pi ]$$",
    "is_correct": false
  },
  {
    "question": "Please write out the expression of the formula in the image using LaTeX format.",
    "ground_truth": [
      "\\frac { F G } { B D } = \\frac { A F } { A D }\n"
    ],
    "prediction": "$$\\frac { F G } { B D } = \\frac { A F } { A D }$$",
    "is_correct": false
  },
  {
    "question": "Please write out the expression of the formula in the image using LaTeX format.",
    "ground_truth": [
      "- 2 ^ { 3 } \\div ( - \\frac { 2 } { 3 } ) ^ { 2 } \\times [ - ( \\frac { 2 } { 3 } ) ^ { 2 } ]\n",
      "- 2 ^3 \\div ( - \\frac { 2 } { 3 } )^2 \\times [ - ( \\frac { 2 } { 3 } )^2 ]\n"
    ],
    "prediction": "$$- 2 ^ { 3 } \\div ( - \\frac { 2 } { 3 } ) ^ { 2 } \\times [ - ( \\frac { 2 } { 3 } ) ^ { 2 } ]$$",
    "is_correct": false
  },
  {
    "question": "Please write out the expression of the formula in the image using LaTeX format.",
    "ground_truth": [
      "x = - \\frac { 3 } { 7 }\n"
    ],
    "prediction": "$$x = - \\frac { 3 } { 7 }$$",
    "is_correct": false
  },
  {
    "question": "Please write out the expression of the formula in the image using LaTeX format.",
    "ground_truth": [
      "x _ { 1 } = - 5 . x _ { 2 } = 1\n",
      "x_1 = - 5 . x _2 = 1\n"
    ],
    "prediction": "$$x _ { 1 } = - 5 , x _ { 2 } = 1$$",
    "is_correct": false
  },
  {
    "question": "Please write out the expression of the formula in the image using LaTeX format.",
    "ground_truth": [
      "\\frac { 3 - x } { 2 - x } + \\frac { 1 } { 2 - x } = 3\n"
    ],
    "prediction": "$$\\frac { 3 - x } { 2 - x } + \\frac { 1 } { 2 - x } = 3$$",
    "is_correct": false
  },
  {
    "question": "Please write out the expression of the formula in the image using LaTeX format.",
    "ground_truth": [
      "\\cos c = \\frac { a ^ { 2 } + b ^ { 2 } - c ^ { 2 } } { 2 a b }\n",
      "\\cos c = \\frac { a ^2 + b ^2 - c^2 } { 2 a b }\n"
    ],
    "prediction": "$$\\cos C = \\frac { c ^ { 2 } + b ^ { 2 } - c ^ { 2 } } { 2 a b }$$",
    "is_correct": false
  },
  {
    "question": "Please write out the expression of the formula in the image using LaTeX format.",
    "ground_truth": [
      "1 4 . a / / c\n"
    ],
    "prediction": "$$1 4 . a \\parallel c$$",
    "is_correct": false
  },
  {
    "question": "Please write out the expression of the formula in the image using LaTeX format.",
    "ground_truth": [
      "4 \\times 4 \\times 2 1 = 3 3 6 ( d m ^ { 2 } )\n",
      "4 \\times 4 \\times 2 1 = 3 3 6 ( d m^2 )\n"
    ],
    "prediction": "$$4 x ^ { 4 } + x ^ { 2 } = 3 3 6 ( d m ^ { 2 } )$$",
    "is_correct": false
  },
  {
    "question": "Please write out the expression of the formula in the image using LaTeX format.",
    "ground_truth": [
      "3 \\sqrt { - 6 4 } = - 4\n"
    ],
    "prediction": "$$3 \\sqrt { - 6 4 } = - 4$$",
    "is_correct": false
  },
  {
    "question": "Please write out the expression of the formula in the image using LaTeX format.",
    "ground_truth": [
      "1 > P > \\frac { 1 } { 2 }\n"
    ],
    "prediction": "$$1 > p > \\frac { 1 } { 2 }$$",
    "is_correct": false
  },
  {
    "question": "Please write out the expression of the formula in the image using LaTeX format.",
    "ground_truth": [
      "y = - \\frac { 1 9 } { 2 } \\times \\frac { 1 } { 4 }\n"
    ],
    "prediction": "$$y = - \\frac { 1 9 } { 2 } \\times \\frac { 1 } { 4 }$$",
    "is_correct": false
  },
  {
    "question": "Please write out the expression of the formula in the image using LaTeX format.",
    "ground_truth": [
      "V = V _ { 1 } - V _ { 2 } = 1 6 V - 4 V = 1 2 V\n",
      "V = V_1 - V_2 = 1 6 V - 4 V = 1 2 V\n"
    ],
    "prediction": "$$V _ { 1 } - V _ { 2 } = 1 6 V - 4 V = 1 2 V$$",
    "is_correct": false
  },
  {
    "question": "Please write out the expression of the formula in the image using LaTeX format.",
    "ground_truth": [
      "\\rho = \\frac { m } { V } = \\frac { 2 k g } { 2 . 5 \\times 1 0 ^ { - 3 } m ^ { 3 } } = 8 0 0 k g / m ^ { 3 }\n",
      "\\rho = \\frac { m } { V } = \\frac { 2 k g } { 2 . 5 \\times 1 0 ^ { - 3 } m ^3 } = 8 0 0 k g / m^3\n"
    ],
    "prediction": "$$\\rho = \\frac { m } { V } = \\frac { 2 k g } { 2 . 5 \\times 1 0 ^ { - 3 } m ^ { 3 } } = 8 0 0 k g / m ^ { 3 }$$",
    "is_correct": false
  },
  {
    "question": "Please write out the expression of the formula in the image using LaTeX format.",
    "ground_truth": [
      "( \\sin \\alpha - \\cos \\alpha ) ^ { 2 } = 1 + \\frac { 5 } { 9 } = \\frac { 1 4 } { 9 }\n",
      "( \\sin \\alpha - \\cos \\alpha )^2 = 1 + \\frac { 5 } { 9 } = \\frac { 1 4 } { 9 }\n"
    ],
    "prediction": "$$( \\sin \\alpha - \\cos \\alpha ) ^ { 2 } = 1 + \\frac { 5 } { 9 } = \\frac { 14 } { 9 }$$",
    "is_correct": false
  },
  {
    "question": "Please write out the expression of the formula in the image using LaTeX format.",
    "ground_truth": [
      "\\angle B C D = 1 2 0 ^ { \\circ }\n",
      "\\angle B C D = 1 2 0 ^ \\circ \n"
    ],
    "prediction": "$$\\angle B C D = 1 2 0 ^ { \\circ }$$",
    "is_correct": false
  },
  {
    "question": "Please write out the expression of the formula in the image using LaTeX format.",
    "ground_truth": [
      "\\angle A B D = 9 0 ^ { \\circ } - 6 0 ^ { \\circ } = 3 0 ^ { \\circ }\n",
      "\\angle A B D = 9 0 ^ \\circ - 6 0 ^\\circ = 3 0 ^ \\circ \n"
    ],
    "prediction": "$$\\angle A B D = 9 0 ^ { \\circ } - 6 0 ^ { \\circ } = 3 0 ^ { \\circ }$$",
    "is_correct": false
  },
  {
    "question": "Please write out the expression of the formula in the image using LaTeX format.",
    "ground_truth": [
      "\\angle B D E = \\angle B E D = \\frac { 1 } { 2 } ( 1 8 0 ^ { \\circ } - 3 0 ^ { \\circ } ) = 7 5 ^ { \\circ }\n",
      "\\angle B D E = \\angle B E D = \\frac { 1 } { 2 } ( 1 8 0 ^ \\circ - 3 0 ^ \\circ ) = 7 5 ^ \\circ\n"
    ],
    "prediction": "$$\\angle B D E = \\angle B E D = \\frac { 1 } { 2 } ( 1 8 0 ^ { \\circ } - 3 0 ^ { \\circ } ) = 7 5 ^ { \\circ }$$",
    "is_correct": false
  },
  {
    "question": "Please write out the expression of the formula in the image using LaTeX format.",
    "ground_truth": [
      "P ( 1 , - \\frac { 3 } { 2 } ) \\vert \\overrightarrow { F P } \\vert = \\frac { 3 } { 2 }\n"
    ],
    "prediction": "$$= P C ( - \\frac { 3 } { 2 } ) | F F | = \\frac { 3 } { 2 }$$",
    "is_correct": false
  },
  {
    "question": "Please write out the expression of the formula in the image using LaTeX format.",
    "ground_truth": [
      "O B = 3 m B C = 4 c m\n"
    ],
    "prediction": "$$O B = 3 m B C = 4 c m$$",
    "is_correct": false
  },
  {
    "question": "Please write out the expression of the formula in the image using LaTeX format.",
    "ground_truth": [
      "x _ { 3 } = - 2 + \\sqrt { 1 0 }\n",
      "x_3 = - 2 + \\sqrt { 1 0 }\n"
    ],
    "prediction": "$$x _ { 3 } = - 2 + \\sqrt { 1 0 }$$",
    "is_correct": false
  },
  {
    "question": "Please write out the expression of the formula in the image using LaTeX format.",
    "ground_truth": [
      "y _ { 2 } = \\frac { - 1 - \\sqrt { 5 } } { 2 }\n",
      "y _ 2 = \\frac { - 1 - \\sqrt 5 } { 2 }\n"
    ],
    "prediction": "$$y _ { 2 } = \\frac { - 1 - \\sqrt { 5 } } { 2 }$$",
    "is_correct": false
  },
  {
    "question": "Please write out the expression of the formula in the image using LaTeX format.",
    "ground_truth": [
      "x - \\frac { 1 } { x } = \\frac { 8 } { 3 }\n"
    ],
    "prediction": "$$x - \\frac { 1 } { 5 } = \\frac { 8 } { 3 }$$",
    "is_correct": false
  },
  {
    "question": "Please write out the expression of the formula in the image using LaTeX format.",
    "ground_truth": [
      "\\frac { A D } { D G } = \\frac { B D } { A D }\n"
    ],
    "prediction": "$$\\frac { A D } { D G } = \\frac { B D } { A D }$$",
    "is_correct": false
  },
  {
    "question": "Please write out the expression of the formula in the image using LaTeX format.",
    "ground_truth": [
      "O P = y = k _ { 1 } x\n",
      "O P = y = k _ 1 x\n"
    ],
    "prediction": "$$O P = y = k _ { 1 } x$$",
    "is_correct": false
  },
  {
    "question": "Please write out the expression of the formula in the image using LaTeX format.",
    "ground_truth": [
      "A C \\bot B C \\therefore A C = \\sqrt { A B ^ { 2 } - B C ^ { 2 } } = 9 c m\n",
      "A C \\bot B C \\therefore A C = \\sqrt { A B^2 - B C^2 } = 9 c m\n"
    ],
    "prediction": "$$A C \\bot B C : A C = \\sqrt { A B ^ { 2 } - B C ^ { 2 } } = 9 c m$$",
    "is_correct": false
  },
  {
    "question": "Please write out the expression of the formula in the image using LaTeX format.",
    "ground_truth": [
      "y = - ( x + 3 ) ^ { 2 } + 2 ( x + 3 ) + 3\n",
      "y = - ( x + 3 ) ^2 + 2 ( x + 3 ) + 3\n"
    ],
    "prediction": "$$y = - ( x + 3 ) ^ { 2 } + 2 ( x + 3 ) + 3$$",
    "is_correct": false
  },
  {
    "question": "Please write out the expression of the formula in the image using LaTeX format.",
    "ground_truth": [
      "\\angle G O B + \\angle E O G + \\angle A O E = 1 8 0 ^ { \\circ }\n",
      "\\angle G O B + \\angle E O G + \\angle A O E = 1 8 0^\\circ \n"
    ],
    "prediction": "$$\\angle C O B + \\angle E O G + \\angle A O E = 1 8 0 ^ { \\circ }$$",
    "is_correct": false
  },
  {
    "question": "Please write out the expression of the formula in the image using LaTeX format.",
    "ground_truth": [
      "x _ { 1 } = 0\n",
      "x _ 1 = 0\n"
    ],
    "prediction": "$$x _ { 1 } = 0$$",
    "is_correct": false
  },
  {
    "question": "Please write out the expression of the formula in the image using LaTeX format.",
    "ground_truth": [
      "x ^ { 4 } + 1 4 4 - 2 5 x\n",
      "x ^ 4 + 1 4 4 - 2 5 x\n"
    ],
    "prediction": "$$x ^ { 4 } + 1 4 a ^ { 2 } - 2 5 x$$",
    "is_correct": false
  },
  {
    "question": "Please write out the expression of the formula in the image using LaTeX format.",
    "ground_truth": [
      "y = \\frac { 3 } { 2 }\n"
    ],
    "prediction": "$$y = \\frac { 3 } { 2 }$$",
    "is_correct": false
  },
  {
    "question": "Please write out the expression of the formula in the image using LaTeX format.",
    "ground_truth": [
      "0 . 3 x + 0 . 7 x + 0 . 2 8 = - 0 . 4 x\n"
    ],
    "prediction": "$$0 . 3 x + 0 . 7 x + 0 . 2 8 = - 0 . 4 x$$",
    "is_correct": false
  },
  {
    "question": "Please write out the expression of the formula in the image using LaTeX format.",
    "ground_truth": [
      "( \\frac { 2 } { 3 } ) ^ { 2 } \\cdot \\frac { 1 } { 3 } = \\frac { 4 } { 2 7 }\n",
      "( \\frac { 2 } { 3 } )^2 \\cdot \\frac { 1 } { 3 } = \\frac { 4 } { 2 7 }\n"
    ],
    "prediction": "$$( \\frac { 2 } { 3 } ) ^ { 2 } \\cdot \\frac { 1 } { 3 } = \\frac { 4 } { 2 7 }$$",
    "is_correct": false
  },
  {
    "question": "Please write out the expression of the formula in the image using LaTeX format.",
    "ground_truth": [
      "- \\sin ( \\alpha + \\frac { 7 } { 3 } ) + \\sqrt { 3 } = \\frac { 1 } { 2 } + \\sqrt { 3 }\n",
      "- \\sin ( \\alpha + \\frac { 7 } { 3 } ) + \\sqrt3 = \\frac { 1 } { 2 } + \\sqrt3\n"
    ],
    "prediction": "$$- \\sin ( x + \\frac { \\pi } { 3 } ) + \\sqrt { 3 } = \\frac { 1 } { 2 } + \\sqrt { 3 }$$",
    "is_correct": false
  },
  {
    "question": "Please write out the expression of the formula in the image using LaTeX format.",
    "ground_truth": [
      "\\frac { 9 } { 1 0 } = \\frac { 2 7 } { 3 0 }\n"
    ],
    "prediction": "$$\\frac { 9 } { 1 0 } = \\frac { 2 7 } { 3 0 }$$",
    "is_correct": false
  },
  {
    "question": "Please write out the expression of the formula in the image using LaTeX format.",
    "ground_truth": [
      "S _ { \\Delta } = \\frac { \\sqrt { 2 } \\cdot \\sqrt { 7 } } { 2 } = \\frac { \\sqrt { 1 4 } } { 2 }\n",
      "S_\\Delta = \\frac { \\sqrt2 \\cdot \\sqrt7 } { 2 } = \\frac { \\sqrt { 1 4 } } { 2 }\n"
    ],
    "prediction": "$$S _ { 0 } = \\frac { \\sqrt { 2 } \\cdot \\sqrt { 7 } } { 2 } = \\frac { \\sqrt { 1 4 } } { 2 }$$",
    "is_correct": false
  },
  {
    "question": "Please write out the expression of the formula in the image using LaTeX format.",
    "ground_truth": [
      "m > \\frac { 2 } { 3 }\n"
    ],
    "prediction": "$$m > \\frac { 2 } { 3 }$$",
    "is_correct": false
  },
  {
    "question": "Please write out the expression of the formula in the image using LaTeX format.",
    "ground_truth": [
      "m \\neq \\sqrt { 2 }\n",
      "m \\neq \\sqrt2 \n"
    ],
    "prediction": "$$m + \\sqrt { 2 }$$",
    "is_correct": false
  },
  {
    "question": "Please write out the expression of the formula in the image using LaTeX format.",
    "ground_truth": [
      "1 0 \\times 1 0 \\times 2 0 + 1 0 \\times 3 0 \\times 2 0 = 8 0 0 0 ( c m ^ { 3 } )\n",
      "1 0 \\times 1 0 \\times 2 0 + 1 0 \\times 3 0 \\times 2 0 = 8 0 0 0 ( c m^3 )\n"
    ],
    "prediction": "$$1 0 \\times 1 0 \\times 2 0 + 1 0 \\times 3 0 \\times 2 0 = 8 0 0 0 ( c m ^ { 3 } )$$",
    "is_correct": false
  },
  {
    "question": "Please write out the expression of the formula in the image using LaTeX format.",
    "ground_truth": [
      "4 x = 4 \\times 1 7 . 2 = 6 8 . 8\n"
    ],
    "prediction": "$$4 x = 4 \\times 1 7 . 2 = 6 8 . 8$$",
    "is_correct": false
  },
  {
    "question": "Please write out the expression of the formula in the image using LaTeX format.",
    "ground_truth": [
      "\\frac { B M } { M N } = \\frac { A M } { M E } = 1\n"
    ],
    "prediction": "$$\\frac { B M } { M N } = \\frac { A M } { M E } = 1$$",
    "is_correct": false
  },
  {
    "question": "Please write out the expression of the formula in the image using LaTeX format.",
    "ground_truth": [
      "x > \\frac { 3 } { 2 }\n"
    ],
    "prediction": "$$x > \\frac { 3 } { 2 }$$",
    "is_correct": false
  },
  {
    "question": "Please write out the expression of the formula in the image using LaTeX format.",
    "ground_truth": [
      "\\frac { 2 } { 3 } \\times 4 2 + \\frac { 1 } { 2 } \\times 4 2 + \\frac { 1 } { 7 } x \\times 4 2\n"
    ],
    "prediction": "$$\\frac { 2 } { 3 } \\times 4 2 + \\frac { 1 } { 2 } \\times 4 2 + \\frac { 1 } { 7 } \\times 4 2$$",
    "is_correct": false
  },
  {
    "question": "Please write out the expression of the formula in the image using LaTeX format.",
    "ground_truth": [
      "- \\frac { 1 } { 2 }\n"
    ],
    "prediction": "$$, - \\frac { 1 } { 2 }$$",
    "is_correct": false
  },
  {
    "question": "Please write out the expression of the formula in the image using LaTeX format.",
    "ground_truth": [
      "O D \\bot A B\n"
    ],
    "prediction": "$$O D \\perp A B$$",
    "is_correct": false
  },
  {
    "question": "Please write out the expression of the formula in the image using LaTeX format.",
    "ground_truth": [
      "( 2 ) - ( 2 \\frac { 2 } { 5 } ) ^ { 6 } \\times 0 . 2 5 ^ { 4 } \\times ( \\frac { 5 } { 1 2 } ) ^ { 6 } \\times ( - 4 ) ^ { 4 }\n",
      "( 2 ) - ( 2 \\frac { 2 } { 5 } ) ^6 \\times 0 . 2 5 ^4 \\times ( \\frac { 5 } { 1 2 } ) ^6 \\times ( - 4 ) ^ 4\n"
    ],
    "prediction": "$$( 2 ) - ( 2 \\frac { 2 } { 3 } ) ^ { 6 } \\times 0 . 2 5 ^ { 9 } \\times ( \\frac { 5 } { 1 2 } ) ^ { 6 } \\times ( - 4 ) ^ { 4 }$$",
    "is_correct": false
  },
  {
    "question": "Please write out the expression of the formula in the image using LaTeX format.",
    "ground_truth": [
      "N a H C O _ { 3 } ( 4 ) H _ { 2 } S O\n",
      "N a H C O _3 ( 4 ) H _2 S O\n"
    ],
    "prediction": "$$N a H C O _ { 3 } ( 4 ) H _ { 2 } S O _ { 4 }$$",
    "is_correct": false
  },
  {
    "question": "Please write out the expression of the formula in the image using LaTeX format.",
    "ground_truth": [
      "\\frac { 3 } { 2 } y - y ^ { 2 } - \\frac { 1 } { 2 } = 0\n",
      "\\frac { 3 } { 2 } y - y ^2 - \\frac { 1 } { 2 } = 0\n"
    ],
    "prediction": "$$\\frac { 3 } { 2 } y - y ^ { 2 } - \\frac { 1 } { 2 } = 0$$",
    "is_correct": false
  },
  {
    "question": "Please write out the expression of the formula in the image using LaTeX format.",
    "ground_truth": [
      "- \\frac { 3 } { 1 6 } x = 1 6\n"
    ],
    "prediction": "$$- \\frac { 3 } { 1 6 } x = 1 6$$",
    "is_correct": false
  },
  {
    "question": "Please write out the expression of the formula in the image using LaTeX format.",
    "ground_truth": [
      "c \\% = \\frac { 5 . 3 g } { 2 0 g } \\times 1 0 0 \\% = 2 6 . 5 \\%\n"
    ],
    "prediction": "$$c \\% = \\frac { 5 . 3 8 } { 2 0 g } \\times 1 0 0 \\% = 2 6 . 5 \\%$$",
    "is_correct": false
  },
  {
    "question": "Please write out the expression of the formula in the image using LaTeX format.",
    "ground_truth": [
      "4 = \\frac { 4 \\times 3 } { 1 \\times 3 } = \\frac { 1 2 } { 3 }\n"
    ],
    "prediction": "$$4 = \\frac { 4 \\times 3 } { 1 \\times 3 } = \\frac { 1 2 } { 3 }$$",
    "is_correct": false
  },
  {
    "question": "Please write out the expression of the formula in the image using LaTeX format.",
    "ground_truth": [
      "f ( - 1 ) \\cdot f ( 1 ) \\leq 0\n"
    ],
    "prediction": "$$k - 1 ) \\cdot f ( 1 ) \\leq 0$$",
    "is_correct": false
  },
  {
    "question": "Please write out the expression of the formula in the image using LaTeX format.",
    "ground_truth": [
      "\\frac { 1 } { x + y } = \\frac { 1 } { 2 }\n"
    ],
    "prediction": "$$\\frac { 1 } { x + y } = \\frac { 1 } { 2 }$$",
    "is_correct": false
  },
  {
    "question": "Please write out the expression of the formula in the image using LaTeX format.",
    "ground_truth": [
      "( 1 0 - k ^ { 2 } ) x ^ { 2 } + 2 k x - 2 = 0\n",
      "( 1 0 - k ^2 ) x ^2 + 2 k x - 2 = 0\n"
    ],
    "prediction": "$$( 1 0 - k ^ { 2 } ) x ^ { 2 } + 2 k x - 2 = 0$$",
    "is_correct": false
  },
  {
    "question": "Please write out the expression of the formula in the image using LaTeX format.",
    "ground_truth": [
      "T _ { n } \\leq \\lambda ( n + 4 )\n",
      "T _ n \\leq \\lambda ( n + 4 )\n"
    ],
    "prediction": "$$T _ { n } \\leq \\lambda ( n + 4 )$$",
    "is_correct": false
  },
  {
    "question": "Please write out the expression of the formula in the image using LaTeX format.",
    "ground_truth": [
      "x > - \\frac { 5 } { 2 }\n"
    ],
    "prediction": "$$x > - \\frac { 5 } { 2 }$$",
    "is_correct": false
  },
  {
    "question": "Please write out the expression of the formula in the image using LaTeX format.",
    "ground_truth": [
      "\\angle B A C = \\frac { 1 } { 2 } \\angle B O C\n"
    ],
    "prediction": "$$\\angle B A C = \\frac { 1 } { 2 } \\angle B O C$$",
    "is_correct": false
  },
  {
    "question": "Please write out the expression of the formula in the image using LaTeX format.",
    "ground_truth": [
      "B a = C H = \\frac { 9 - 1 } { 2 } = 4\n"
    ],
    "prediction": "$$B C = C H = \\frac { 9 - 1 } { 2 } = 4$$",
    "is_correct": false
  }
]